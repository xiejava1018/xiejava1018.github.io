<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>XieJava&#39;s blog</title>
  
  <subtitle>记录最好的自己</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xiejava.gitee.io/"/>
  <updated>2022-04-01T12:40:33.555Z</updated>
  <id>https://xiejava.gitee.io/</id>
  
  <author>
    <name>XieJava</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>网络信息系统安全的发展演变</title>
    <link href="https://xiejava.gitee.io/posts/cb0f48b6/"/>
    <id>https://xiejava.gitee.io/posts/cb0f48b6/</id>
    <published>2022-04-01T12:38:17.000Z</published>
    <updated>2022-04-01T12:40:33.555Z</updated>
    
    <content type="html"><![CDATA[<p>随着通信技术和信息技术的发展，极大的改变了人们处理信息的方式和效率。计算机网络尤其是互联网的出现是信息技术发展中一个里程碑事件。计算机网络将通信技术和计算机技术结合起来。信息在计算机上产生、处理，并在网络中传输。网络信息系统安全是通信安全和信息系统安全的综合，网络信息安全已经覆盖了信息资产的生成、处理、传输和存储等各个阶段。包括信息自身的安全、信息应用的安全、计算机信息系统安全、通信网络安全。</p><table> <tr><td rowspan="2">信息安全</td><td>信息应用安全</td></tr> <tr><td> 信息自身安全</td></tr> <tr><td rowspan="2">信息基础设施安全</td><td>计算机系统安全</td></tr> <tr> <td>通信网络安全</td></tr></table><p>网络信息系统安全随着通信技术和信息技术的发展，大致经历了通信保密年代、计算机系统安全年代、信息系统网络安全年代、网络空间安全年代。<br><img src="https://img-blog.csdnimg.cn/2a9ebb72f181496c96ce55884fba64f7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="网络信息系统安全的发展演变"></p><h2 id="一、通信保密年代"><a href="#一、通信保密年代" class="headerlink" title="一、通信保密年代"></a>一、通信保密年代</h2><p>1906年，美国物理学家费森登( Fessenden )成功地研究出无线电广播。法国人克拉维尔建立了英法第一条商用无线电线路，推动了无线电技术的进一步发展。<br>进入20世纪，尤其是在“二战”时期，军事和外交方面的巨大需求，使得无线通信技术得到飞速发展，被广泛用来传递军事情报、作战指令、外交政策等各种关键信息。21世纪，通信技术突飞猛进的发展，移动通信和数字通信成为通信技术的主流，现代世界中通信技术成为支撑整个社会的命脉和根本。<br>在通信保密年代，网络信息安全面临的主要威胁是攻击者对通信内容的窃取:有线通信容易被搭线窃听、无线通信由于电磁波在空间传播易被监听。保密成为通信安全阶段的核心安全需求。这阶段主要通过密码技术对通信的内容进行加密，保证数据的保密性和完整性，而破译成为攻击者对这种安全措施的反制。</p><h2 id="二、计算机系统安全年代"><a href="#二、计算机系统安全年代" class="headerlink" title="二、计算机系统安全年代"></a>二、计算机系统安全年代</h2><p>计算机经历了电子计算机、晶体管计算机、集成电路计算机等几个阶段。尤其是在进入20世纪70年代后,随着个人计算机的普及，各行各业都迅速采用计算机处理各种业务。计算机在处理、存储信息数据等方面的应用越来越广泛。美国国家标准局公布了《数据加密标准》( Data Encryption Standard,DES )，标志着信息安全由通信保密阶段进人计算机安全阶段。这个时期，计算机网络尚未大规模普及，相对于电话电报，计算机对信息的处理和存储能力强大，但数据长距离、大容量的传输方式较单一，功能相对较弱(主要通过软盘等形式传输)。因此，计算机阶段主要威胁来自于非授权用户对计算资源的非法使用、对信息的修改和破坏。<br>20世纪80年代计算机安全的概念开始成熟。计算机安全的主要目的是采取措施和控制以确保信息系统资产(包括硬件、软件、固件和通信、存储和处理的信息)的保密性、完整性和可用性。典型代表措施是通过操作系统的访问控制手段来防止非授权用户的访问。</p><h2 id="三、信息系统网络安全年代"><a href="#三、信息系统网络安全年代" class="headerlink" title="三、信息系统网络安全年代"></a>三、信息系统网络安全年代</h2><p>计算机网络尤其是互联网的出现是信息技术发展中一个里程碑事件。计算机网络将通信技术和计算机技术结合起来。信息在计算机上产生、处理，并在网络中传输。信息技术由此进人网络阶段，网络阶段利用通信技术将分布的计算机连接在一起，形成覆盖整个组织机构甚至整个世界的信息系统。信息系统安全是通信安全和计算机安全的综合，信息安全需求已经全面覆盖了信息资产的生成、处理、传输和存储等各阶段,确保信息系统的保密性、完整性和可用性。信息系统安全也曾被称为网络安全，主要是保护信息在存储、处理和传输过程中免受非授权的访问，防止授权用户的拒绝服务，同时检测、记录和对抗此类威胁。为了抵御这些威胁，人们开始使用防火墙、防病毒、PKI、 VPN等安全产品。此阶段的主要标志是发布了《信息技术安全性评估通用准则》，此准则即通常所说的通用准则( Common Criteria,CC)，后转变为国际标准ISO/IEC 15408,我国等同采纳此国际标准为国家标准GB/T 18336。</p><h2 id="四、网络空间安全年代"><a href="#四、网络空间安全年代" class="headerlink" title="四、网络空间安全年代"></a>四、网络空间安全年代</h2><p>随着互联网的不断发展，越来越多的设备被接人并融合，技术的融合将传统的虚拟世界与物理世界相互连接，共同构成了一个新的IT世界。互联网成为个人生活、组织机构甚至国家运行不可或缺的一部分，网络空间随之诞生，信息化发展进人网络空间阶段。网络空间作为新兴的第五空间，已经成为新的国家竞争领域,威胁来源从个人上升到犯罪组织，甚至上升到国家力量的层面。<br>“网络空间( Cyberspace)”一词，由加拿大作家威廉●吉布森在其短篇科幻小说《燃烧的铬》中创造出来，原意指由计算机创建的虚拟信息空间，体现了Cyberspace 不仅是信息的简单聚合体，也包含了信息对人类思想认知的影响。此后，随着信息技术的快速发展和互联网的广泛应用，Cyberspace 的概念不断丰富和演化。<br>随着信息化的不断深人，信息系统成为组织机构工作和生活不可或缺的一部分，信息安全威胁来源从个人上升到犯罪组织，甚至国家力量。在这个阶段，人们认识到信息安全保障不能仅仅依赖于技术措施，开始意识到管理的重要性和信息系统的动态发展性，信息安全保障的概念逐渐形成和成熟。<br>信息安全保障把信息系统安全从技术扩展到管理，从静态扩展到动态，通过各种安全保障技术和安全保障管理措施的综合融合至信息化中，形成对信息、信息系统乃至业务以及使命的保障。信息安全保障时代，其主要标志是《信息保障技术框架》（IATF）。如果说对信息的保护，主要还是处于从传统安全理念到信息化安全理念的转变过程中，那么面向业务的安全保障，就完全是从信息化的角度来考虑信息的安全了。体系性的安全保障理念，不仅是关注系统的漏洞，而且是从业务的生命周期着手，对业务流程进行分析，找出流程中的关键控制点，从安全事件出现的前、中、后三个阶段进行安全保障。面向业务的安全保障不是只建立防护屏障，而是建立一个“深度防御体系”，通过更多的技术手段把安全管理与技术防护联系起来，不再是被动地保护自己，而是主动地防御攻击。也就是说，面向业务的安全防护已经从被动走向主动，安全保障理念从风险承受模式走向安全保障模式。信息安全阶段也转化为从整体角度考虑其体系建设的信息安全保障时代。<br>2009年5月29日，美国发布《网络空间政策评估:确保信息和通信系统的可靠性和韧性》报告。云计算、虚拟化、物联网、移动互联网、大数据、人工智能等新技术的出现，使得网络空间安全的问题无比复杂。<br>2016年12月，我国发布了《国家网络空间安全战略》，明确了网络空间是国家安全的新疆域，已经成为与陆地、海洋、天空、太空同等重要的人类活动新领域，国家主权拓展延伸到网络空间，网络空间主权成为国家主权的重要组成部分。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;随着通信技术和信息技术的发展，极大的改变了人们处理信息的方式和效率。计算机网络尤其是互联网的出现是信息技术发展中一个里程碑事件。计算机网络将通信技术和计算机技术结合起来。信息在计算机上产生、处理，并在网络中传输。网络信息系统安全是通信安全和信息系统安全的综合，网络信息安全已
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客加入51LA网站流量统计</title>
    <link href="https://xiejava.gitee.io/posts/f571f2b1/"/>
    <id>https://xiejava.gitee.io/posts/f571f2b1/</id>
    <published>2022-04-01T04:42:04.000Z</published>
    <updated>2022-04-01T04:44:01.474Z</updated>
    
    <content type="html"><![CDATA[<p>自建hexo博客xiejava.ishareread.com一直在用CNZZ的网站流量统计，每天登陆到CNZZ的网站流量统计后台看博客的访问量成了建站以来的习惯。3月23日以后突然发现CNZZ的统计没有数据了，查了半天才知道CNZZ的U-Web统计分析产品停服了，计划要收费了。最开始用百度统计也是的，原来用得好好的，突然也是要收费了才开始转向用CNZZ的，现在CNZZ也要开始收费了。看来互联网公司日子比较难过了，免费时代已经一去不复返了。对于个人博客网站来说要付费买个网站流量统计又有点划不来。本来流量就很少，每年域名要付费、主机要付费，再弄个流量统计也要付费实在是有点承受不了。但是没有网站流量统计，不能看到自己的站点的访问量，对于个人自建网站来讲失去了大部分的乐趣。<br>所以这几天一直在寻找其他的网站流量统计的工具，只到找到了51LA。以前只知道百度和CNZZ的网站流量统计工具，最近才了解到51LA统计，它是15年老牌网站统计工具，是互联网上最早基于ASP编写的网站数据统计工具，拥有一大批忠实老站长，后来历经改造，推出新版51LA统计目前是网站统计V6，界面较以往有了较大的改动更加友好直观。<br>51LA网站统计V6的产品链接是 <a href="https://v6.51.la/" target="_blank" rel="noopener">https://v6.51.la/</a><br><img src="https://img-blog.csdnimg.cn/e24590a008154f04a807efaa7703eef1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="我要啦网站统计V6"></p><p>看到”<strong>免费使用</strong>“几个大字的时候我的眼睛已经发光了。迫不及待的点击“注册”，进行使用。</p><h2 id="一、注册登录"><a href="#一、注册登录" class="headerlink" title="一、注册登录"></a>一、注册登录</h2><p>注册流程很简单，要注册的信息很少，基本上就是手机号和登录密码。<br><img src="https://img-blog.csdnimg.cn/64f5b814778248c2a99e6635d51c5410.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_10,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="注册"></p><p>注册过程很友好，注册完就可以登录了。</p><h2 id="二、添加应用"><a href="#二、添加应用" class="headerlink" title="二、添加应用"></a>二、添加应用</h2><p>在正式使用网站统计服务之前要添加应用。也就是要将要统计的站点域名登记到应用里，生成统计代码。<br>点击“添加应用”按钮。要填的信息也就是你要统计的站点域名，可以是多个域名。我的hexo博客除了用到xiejava.ishareread.com外还在github和gited上都生成了。所以把这几个访问的域名都加上。<br><img src="https://img-blog.csdnimg.cn/79491c98a91942639de92f88eb5e975b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="添加应用"></p><h2 id="三、加入网站流量统计代码"><a href="#三、加入网站流量统计代码" class="headerlink" title="三、加入网站流量统计代码"></a>三、加入网站流量统计代码</h2><p>添加应用后下一步就是生成统计代码，将统计代码加入到自己的hexo站点。<br><img src="https://img-blog.csdnimg.cn/1308b239146f486e9aa5db9f631c9f5d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="生成统计代码"><br>标签页后面还有“图标引用”、“数据挂件”的代码，如果有需要也可以加入。<br>找到自己的hexo站点的文件目录的<code>footer.swig</code>文件，具体在<code>themes\hexo-theme-next\layout\_partials</code>目录下。编辑footer.swig文件，加入统计代码，根据需要加入图标引用、数据挂件的代码。<br><img src="https://img-blog.csdnimg.cn/4987b4462e464d31b2d0ce8197aa3a53.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="加入统计代码"></p><h2 id="四、查看统计效果"><a href="#四、查看统计效果" class="headerlink" title="四、查看统计效果"></a>四、查看统计效果</h2><p>加入统计代码、图标引用、数据挂件代码后，大约5分钟刷新hexo站点，就可以在网站底部看到图标和数据挂件。<br><img src="https://img-blog.csdnimg.cn/322ef4197bdb47e6a2c7ff8420c923be.png#pic_center" alt="网站底部统计显示"></p><p>登录到<a href="https://v6.51.la/user/application" target="_blank" rel="noopener">https://v6.51.la/user/application</a> 的管理后台，可以看到代码安装状态为“安装成功”<br><img src="https://img-blog.csdnimg.cn/477087d995c9428bba3acacce0a70754.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="应用列表"></p><p>点击“查看报表”可以查看网站的流量统计分析信息。各种统计图表直观易懂，数据详实，感觉比CNZZ 及百度统计更加实用和方便。<br><img src="https://img-blog.csdnimg.cn/00ce0abe369941b7a35ba0094710e844.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="管理后台"><br>51LA可免费添加应用30个，每日应用统计总PV在3000000，对于个人站点或小型企业足足够用了。</p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;自建hexo博客xiejava.ishareread.com一直在用CNZZ的网站流量统计，每天登陆到CNZZ的网站流量统计后台看博客的访问量成了建站以来的习惯。3月23日以后突然发现CNZZ的统计没有数据了，查了半天才知道CNZZ的U-Web统计分析产品停服了，计划要收费
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Hexo" scheme="https://xiejava.gitee.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>网络信息安全之纵深防御</title>
    <link href="https://xiejava.gitee.io/posts/e2fd4a90/"/>
    <id>https://xiejava.gitee.io/posts/e2fd4a90/</id>
    <published>2022-03-30T10:30:28.000Z</published>
    <updated>2022-03-30T10:33:14.656Z</updated>
    
    <content type="html"><![CDATA[<p>什么是“纵深防御”？很多人和资料都有不同的解释，有许多资料将“纵深防御”和“分层防护”等同起来，<br>上次文章介绍了“<a href="https://xiejava.blog.csdn.net/article/details/123794343" target="_blank" rel="noopener">分层防护</a>”，分层防护是根据网络的应用现状情况和网络的结构，将安全防范体系的层次划分为物理层安全、系统层安全、网络层安全、应用层安全和安全管理等各个层级，在每个层级实施相应的防护策略和手段。“纵深防御”与“分层防护”既有区别又有联系。</p><p>“纵深防御”实际上并不是一个网络安全领域的专属名词，早在二十世纪初，前苏联元帅米·尼·图哈切夫斯基就在对第一次世界大战以及国内战争经验的基础上，提出了一种名为“大纵深作战理论”的思想。由于网络安全的本质就是黑客与开发者之间的攻防战，所以信息安全领域中的“纵深防御”概念确与战争学上的思想有着共通之处，其核心都是多点布防、以点带面、多面成体，以形成一个多层次的、立体的全方位防御体系来挫伤敌人、保障自身的整体安全。</p><p>根据《信息安全工程师教程（第2版）》的描述，<strong>纵深防御模型的基本思路就是将信息网络安全防护措施有机组合起来，针对保护对象，部署合适的安全措施，形成多道保护线，各安全防护措施能够相互支持和补救，尽可能地阻断攻击者的威胁</strong>。目前，安全业界认为网络需要建立四道防线：安全保护是网络的第一道防线，能够阻止对网络的入侵和危害；安全监测是网络的第二道防线，可以及时发现入侵和破坏；实施响应是网络的第三道防线，当攻击发生时维持网络”打不垮”；恢复是网络的第四道防线，使网络在遭受攻击后能够以最快的速度“起死回升”，最大限度地降低安全事件带来的损失。看描述基本上是对应美国国防部提出的PDRR模型，即（Protection防护、Detection检测、Recovery恢复、Response响应）。PDRR改进了传统的只有防护的单一安全防御思想，强调信息安全保障的四个重要环节。<br>保护（Protection）的内容主要有加密机制、数据签名机制、访问控制机制、认证机制、信息隐藏、防火墙技术等。<br>检测（Detection）的内容主要有入侵检测、系统脆弱性检测、数据完整性检测、攻击性检测等。<br>恢复（Recovery）的内容主要有数据备份、数据修复、系统恢复等。<br>响应（Response）的内容主要有应急策略、应急机制、应急手段、入侵过程分析及安全状态评估等。<br><img src="https://img-blog.csdnimg.cn/55be794c0ca54144b664236a49d06321.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="PDRR"></p><p>但是PPDR模型总体还是比较局限与从技术上考虑安全问题。随着信息化的发展，人们越来越意识到信息安全涉及面非常广，除了技术，管理、制度、人员和法律等方面也是信息安全必须考虑的因素，就像一个由多块木板构成的“木桶”，木桶的容量由最短的那块短板决定。在处理信息安全问题是，需要全面考虑各方面的因素。</p><p>所以美国国家安全局（NSA）发布的信息安全保障技术框架IATF（Information Assurance Technical Framework）提出了纵深防御战略思想，其3个核心要素就是人、技术和操作。信息系统安全保障依赖于人、技术和操作来共同实现组织机构的职能。<br>IATF用一句话概括起来就是：<strong>一个核心思想、三个核心要素、四个焦点领域</strong>。<br><img src="https://img-blog.csdnimg.cn/fdddd1b8b76b4be3a41e4095d08edb49.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="IATF纵深防御"></p><p><strong>一个核心思想</strong><br>一个核心思想就是”纵深防御”，<strong>纵深防御也被称为深度防护战略（Defense-in-Depth），是指网络安全需要采用一个多层次、纵深的安全措施来保障信息安全。因为网络信息的安全不是仅仅依靠一两种技术或简单的安全防御设施就能实现，必须在各个层次、不同技术框架区域中实施保障机制，才能最大程度地降低风险，应对攻击并保护信息系统的安全</strong>。在一个规范的信息系统网络中，我们可以看到在网络出口有防火墙，在DMZ区有防火墙，在服务器前端还有防火墙，这就是纵深防御思想的一个体现。需要在多个位置部署安全措施，看似重复，但是因其面对不同的业务、其安全策略有很大的差异。</p><p><strong>三个核心要素</strong><br>三个核心要素是人、技术、操作。网络安全三分靠技术、七分靠管理，三要素中的“人”指的就是加强管理。<br>人是信息系统的主题，包括信息系统的拥有者、管理者和使用者，是信息安全保障的核心；<br>技术是重要手段，需要通过技术机制来保障各项业务的安全，是一种被动防御；<br>操作也称为运行或运营安全，是一种主动防御的体系和机制，包括风险评估、监控、审计、入侵检测等。<br><img src="https://img-blog.csdnimg.cn/4ccc279ac6a94841b36f5e6c786a90a0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="三个核心要素"></p><p><strong>四个焦点领域</strong><br>网络和基础设施、区域边界、计算环境、支撑性基础设施4个焦点领域。基于这4个焦点领域，结合IATF纵深防御的思想进行信息安全防御从而形成保障框架。</p><p>1.保护网络和基础设施</p><p>网络和其他基础设施是信息系统及业务的支撑，是整个信息系统安全的基础。应采取昔施确保网络和基础设施能稳定可靠运行，不会因故障和外界影响导致服务的中断或数据延迟，确保在网络中进行传输的公共的、私人的信息能正确地被接收者获取，不会导致未受权的访问、更改等。保护网络和基础设施防护措施包括但并不限于以下方式。</p><ul><li>合理规划以确保骨干网可用性。</li><li>使用安全的技 术架构，例如在使用无线网络时考虑安全的技术架构。</li><li>使用冗余设备提高可用性。</li><li>使用虚拟专网 ( VPN)保护通信。</li></ul><p>2.保护区域边界</p><p>信息系统根据业务、管理方式和安全等级的不同，通常可以划分为多个区域，这些区或多或少都有与其他区域相连接的边界。保护区域边界关注的是如何对进出这此区域边界的数据流进行有效的控制与监视。要合理地将信息系统根据业务、管理方式和安全等级划分不同的安全区域，并明确定义不同网络区域间需要哪些数据传递。在此基础上采取措施对数据进行控制与监视。通常采取的措施包括但并不限于以下方式。</p><ul><li>在区域边界设 置身份认证和访问控制措施，例如部署防火墙对来访者进行身份认证。</li><li>在区域边 界部署人侵检测系统以发现针对安全区域内的攻击行为。</li><li>在区域边界部署防病毒网关以发现并过滤数据中的恶意代码。</li><li>使用VPN设备以确保安全的接人。</li><li>部署抗拒绝服务攻击设备以应对拒绝服务攻击。</li><li>流量管理、行为管理等其他措施。</li></ul><p>3.保护计算环境</p><p>计算环境指信息系统中的服务器、客户机及其中安装的操作系统、应用软件等。保护计算环境通常采用身份鉴别、访问控制、加密等一系列技术以确保计算环境内的数据保密性、完整性、可用性、不可否认性等。保护计算环境的措施包括但并不限于以下方式。<br>安装并使用安全的操作系统和应用软件。</p><ul><li>在服务 器上部署主机入侵检测系统、防病毒软件及其他安全防护软件。</li><li>定期对系统进行漏洞扫描或者补丁加固，以避免系统脆弱性。</li><li>定期对系统进行安全配置检查，确保最优配置。</li><li>部署或配置对文件的完整性保护。</li><li>定期对 系统和数据进行备份等。</li></ul><p>4.支撑性基础设施</p><p>支撑性基础设施是提供安全服务的基础设施及与之相关的一系列活动的综合体。IATF定义了两种类型的支撑性基础设施：密钥管理基础设施( KMI) /公钥基础设施( PKI)和检测与响应。</p><ul><li>KMI/PKI：提供支持密钥、授权和证书管理的密码基础设施并能实现使用网络服务人员确实的身份识别。</li><li>检测与响应：提供入侵检测、报告、分析、评估和响应基础设施，它能迅速检测和响应入侵、异常事件并提供运行状态的情况。</li></ul><p>IATF的4个技术焦点区域是一个逐层递进的关系，从而形成一种纵深防御系统。因此，以上4个方面的应用充分贯彻了纵深防御的思想，对整个信息系统的各个区域、各个层次，甚至在每一个层次内部都部署了信息安全设备和安全机制，保证访问者对每一个 系统组件进行访问时都受到保障机制的监视和检测，以实现系统全方位的充分防御，将系统遭受攻进行访问时都受到保障机制的监视和检测，以实现系统全方位的充分防御，将系统遭受攻击的风险降至最低,确保数据的安全和可靠。</p><p>除了纵深防御这个核心思想之外，IATF还提出了其他一些信息安全原则，包括保护多个位置、分层防护。<br>1.保护多个位置<br>保护多个位置包括保护网络和基础设施、区域边界、计算环境等,这一原则提醒我们，仅仅在信息系统的重要敏感区域设置一些保护装置 是不够的，任意一个系统漏洞都有可能导致严重的攻击和破坏后果，所以在信息系统的各个方位布置全面的防御机制，才能将风险降至最低。<br>2.分层防御<br>如果说保护多个位置原则是横向防御，那么这一原则就是纵向防御，这也是纵深防御思想的一个具体体现。分层防御即在攻击者和目标之间部署多层防御机制，每个这样的机制必须对攻击者形成一道屏障。而且每一个这样的机制还应包括保护和检测措施，以使攻击者不得不面对被检测到的风险，迫使攻击者由于高昂的攻击代价而放弃攻击行为。</p><p>可见，<strong>纵深防御是战略思想、分层防护是具体的战术实现</strong>。</p><p>资料来源：<br>《信息安全工程师教程（第2版）》<br>《CISP培训教材》</p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;什么是“纵深防御”？很多人和资料都有不同的解释，有许多资料将“纵深防御”和“分层防护”等同起来，&lt;br&gt;上次文章介绍了“&lt;a href=&quot;https://xiejava.blog.csdn.net/article/details/123794343&quot; target=&quot;_bl
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>网络安全体系之分层防护</title>
    <link href="https://xiejava.gitee.io/posts/3a099914/"/>
    <id>https://xiejava.gitee.io/posts/3a099914/</id>
    <published>2022-03-29T02:40:55.000Z</published>
    <updated>2022-03-29T02:42:20.309Z</updated>
    
    <content type="html"><![CDATA[<p>作为全方位的、整体的网络安全防范体系也是分层次的，不同层次反映了不同的安全问题，根据网络的应用现状情况和网络的结构，将安全防范体系的层次划分为物理层安全、系统层安全、网络层安全、应用层安全和安全管理。<br><img src="https://img-blog.csdnimg.cn/c3cba28b0fa34c10bb03fbd14e648e56.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="分层防护"></p><h2 id="1-物理环境的安全性-物理层安全"><a href="#1-物理环境的安全性-物理层安全" class="headerlink" title="1.物理环境的安全性(物理层安全)"></a>1.物理环境的安全性(物理层安全)</h2><p>该层次的安全包括通信线路的安全，物理设备的安全，机房的安全等。物理层的安全主要体现在通信线路的可靠性(线路备份、网管软件、传输介质)，软硬件设备安全性(替换设备、拆卸设备、增加设备)，设备的备份，防灾害能力、防干扰能力，设备的运行环境(温度、湿度、烟尘)，不间断电源保障，等等。</p><h2 id="2-操作系统的安全性-系统层安全"><a href="#2-操作系统的安全性-系统层安全" class="headerlink" title="2.操作系统的安全性(系统层安全)"></a>2.操作系统的安全性(系统层安全)</h2><p>该层次的安全问题来自网络内使用的操作系统的安全，如Windows NT，Windows 2000等。主要表现在三方面，一是操作系统本身的缺陷带来的不安全因素，主要包括身份认证、访问控制、系统漏洞等。二是对操作系统的安全配置问题。三是病毒对操作系统的威胁。</p><h2 id="3-网络的安全性-网络层安全"><a href="#3-网络的安全性-网络层安全" class="headerlink" title="3.网络的安全性(网络层安全)"></a>3.网络的安全性(网络层安全)</h2><p>该层次的安全问题主要体现在网络方面的安全性，包括网络层身份认证，网络资源的访问控制，数据传输的保密与完整性，远程接入的安全，域名系统的安全，路由系统的安全，入侵检测的手段，网络设施防病毒等。</p><h2 id="4-应用的安全性-应用层安全"><a href="#4-应用的安全性-应用层安全" class="headerlink" title="4.应用的安全性(应用层安全)"></a>4.应用的安全性(应用层安全)</h2><p>该层次的安全问题主要由提供服务所采用的应用软件和数据的安全性产生，包括Web服务、电子邮件系统、DNS等。此外，还包括病毒对系统的威胁。</p><h2 id="5-管理的安全性-管理层安全"><a href="#5-管理的安全性-管理层安全" class="headerlink" title="5.管理的安全性(管理层安全)"></a>5.管理的安全性(管理层安全)</h2><p>安全管理包括安全技术和设备的管理、安全管理制度、部门与人员的组织规则等。管理的制度化极大程度地影响着整个网络的安全，严格的安全管理制度、明确的部门安全职责划分、合理的人员角色配置都可以在很大程度上降低其它层次的安全漏洞。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;作为全方位的、整体的网络安全防范体系也是分层次的，不同层次反映了不同的安全问题，根据网络的应用现状情况和网络的结构，将安全防范体系的层次划分为物理层安全、系统层安全、网络层安全、应用层安全和安全管理。&lt;br&gt;&lt;img src=&quot;https://img-blog.csdnim
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>什么是用户实体行为分析（UEBA）</title>
    <link href="https://xiejava.gitee.io/posts/973478d/"/>
    <id>https://xiejava.gitee.io/posts/973478d/</id>
    <published>2022-03-24T07:30:47.000Z</published>
    <updated>2022-03-24T07:36:19.275Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h1><p>数字新时代正在加速全面到来，网络环境变得更加多元、人员变得更复杂、接入方式多种多样，网络边界逐渐模糊甚至消失，同时伴随着企业数据的激增。数字化转型促进组织的业务发展的同时，也带来了重大的网络安全挑战。<br>1.越来越多的外部攻击，包括被利益驱动或国家驱动的难以察觉的高级攻击；<br>2.心怀恶意的内鬼、疏忽大意的员工、失陷账号与失陷主机导致的各种内部威胁；<br>3.数字化基础设施的脆弱性和风险暴露面越来越多，业务需求多变持续加剧的问题；<br>4.安全团队人员不足或能力有限，深陷不对称的“安全战争”之中。<br>在数字化带来的巨大变化下，传统的安全威胁发现能力受到了巨大的挑战。传统安全产品、技术、方案基本上都是基于已知特征进行规则匹配来进行分析和检测，基于特征、规则和人工分析，以“特征”为核心的检测分析存在安全可见性盲区，有严重的滞后效应、无力检测未知攻击、容易被绕过，以及难以适应攻防对抗的网络现实和快速变化的企业环境、外部威胁等问题。<br><img src="https://img-blog.csdnimg.cn/a9c1f22d63554bb6a3cd729f60a0d0ea.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="特征分析与行为分析"></p><p>安全是人和人攻防对抗的游戏，一切的意图都需要通过行为表达，这是安全运营中最重要也最有价值的一块拼图，同时也是传统方式最欠缺的。针对传统方式的不足，安全行业逐步加强基于大数据驱动，机器学习、概率分析、模式识别等的以“行为”为核心的检测分析。<br>用户实体行为分析（UEBA）应运而生。</p><h1 id="二、UEBA是什么"><a href="#二、UEBA是什么" class="headerlink" title="二、UEBA是什么"></a>二、UEBA是什么</h1><p><strong>UEBA全名User and Entity Behavior Analytics ，即为用户实体行为分析。</strong><br>Gartner 对 UEBA 的定义是“UEBA 提供画像及基于各种分析方法的异常检测，通常是基本分析方法（利用签名的规则、模式匹配、简单统计、阈值等）和高级分析方法（监督和无监督的机器学习等），用打包分析来评估用户和其他实体（主机、应用程序、网络、数据库等），发现与用户或实体标准画像或行为相异常的活动所相关的潜在事件。这些活动包括受信内部或第三方人员对系统的异常访问（用户异常），或外部攻击者绕过安全控制措施的入侵（异常用户）</p><p>用户行为分析(UBA)关联了用户活动和相关实体（用户相关的应用和终端等）信息构建人物角色与群组，进一步定义这些个体与群组的合法和正常行为，把这些人物角色在群体与群体、群体与个体、个体与个体（那些远离合法和正常行为的群体与个体）维度上相互比对分析，将异常用户（失陷账号）和用户异常（非法行为）检测出来，从而达到检测业务欺诈、敏感数据泄露、内部恶意用户、有针对性攻击等高级威胁的目的。</p><h1 id="三、UEBA应用场景"><a href="#三、UEBA应用场景" class="headerlink" title="三、UEBA应用场景"></a>三、UEBA应用场景</h1><h2 id="1-账号安全"><a href="#1-账号安全" class="headerlink" title="1  账号安全"></a>1  账号安全</h2><p>内部员工特别是高权限用户，以及服务和共享类帐户是内部和外部攻击者的主要目标。通过获取他们的访问权限则能够访问最敏感的交易、数据，甚至可以创建其他新特权帐户或滥用提权操作。由于公司账号数量庞大且难以区分滥用和合法使用，组织在监控这些帐户时面临着巨大的挑战。有效监控特权帐户不仅是一项重要的合规性要求，而且还是一项关键的威胁管理功能。和专有的特权账号管理应用（PAM，Privileged Account Management），PAM类应用提供了特权账号的全生命周期管理，而对特权账号异常行为的监控、检测、分析则是PAM的一类高级功能。PAM 内置的特权账号异常检测能力相对较弱，所以一些 PAM 供应商会跟 UEBA 产品集成，将 PAM 检测到的异常事件接入 UEBA 产品的高级分析引擎中，和其他维度的数据一起做更深层次的特权账号异常事件识别。<br>细分账号安全的场景，大致有两类。一类是账号本身的操作异常，如创建、提权、删除、暂停、撤回存在异常行为，静默账号忽然出现活动。另一类通过对账号行为如登录的时间、地点、频次的异常监控，判断账号是否被盗用或被攻陷。</p><h2 id="2-内部威胁"><a href="#2-内部威胁" class="headerlink" title="2 内部威胁"></a>2 内部威胁</h2><p>相比于不受信任的外部人员，内部员工访问和获取公司重要信息的要轻松很多。一方面公司的大部分安全防护、访问控制都是针对外来的攻击者；另一方面内部人员对组织的人员、规章、制度都有一定程度的了解，从而可以利用这些便利性来躲过安全防护检测。内部威胁者通常分为两类，一类是恶意内部人员，即合法的人员利用自己的权限做非法的事情。比如，下载大量重要的客户数据贩卖获取利益。另一类是内部人员账号被攻陷后的恶意行为。内部威胁检测的场景设计比较复杂，一般会从4个维度来考虑。</p><ol><li>建立用户行为风险画像 - 将所有身份、活动和访问特征，与基线、同组以及其他已知威胁指标进行比较，确定真正的风险区域。</li><li>高权限账号监控 – 自动识别高权限账号，例如管理员、服务和共享帐户，然后监控他们与攻击相关的异常行为，确定高风险异常行为是否源于高权限用户被成功攻击。</li><li>关键应用监控 – 为所有关键应用程序和系统构建访问风险评估，以识别与其敏感数据和交易相关的所有高风险用户、访问和活动。</li><li>内部欺诈侦测 – 利用同组人员的异常行为，比较分析侦测潜在的内部欺诈行为。</li></ol><h2 id="3-数据渗漏"><a href="#3-数据渗漏" class="headerlink" title="3 数据渗漏"></a>3 数据渗漏</h2><p>一般而言，各类攻击的主要意图是窃取组织中最重要的数据资产。组织一般会部署监控数据流向的 DLP 产品，数据库安全或者应用访问类产品以保护公司的核心数据资产。这类数据防护类产品往往误报很多，每天产生的海量报警让安全团队难以真正聚焦重点。UEBA 可以对应用访问以及 DLP 日志做更深层次的多维分析，从而定位出真正的高风险数据泄漏风险。具体的场景设计可以从以下维度考虑。<br>应用系统访问监控/风险分析 – 对存储敏感数据的应用系统、文件服务器等的访问进行行为监控，通过与用户过去行为或其同组行为异常行相比较，自动识别并持续监控与此数据相关的高风险访问和活动。<br>DLP 事件评估 – 将 DLP 事件做多维度关联分析，比如说发生 DLP 事件的人，他的风险等级、是否有离职倾向、敏感数据下载/外发/打印的数量、频次、数据外流的目的地是否为竞争对手等等，从而进一步定位高风险。高风险人群的 DLP 事件优先处置，并且通过多维度分析往往也能进一步定位这些数据泄漏企图背后的动机。</p><h2 id="4-失陷主机"><a href="#4-失陷主机" class="headerlink" title="4 失陷主机"></a>4 失陷主机</h2><p>除了人员行为异常以外，重要的 IT 资产比如说各种应用服务器、重要的终端等行为异常检测对很多组织也是至关重要。例如，一个重要的应用服务器执行了一个非业务的应用或进程，打开了一个新的端口，外连了从未外连的地址/端口，忽然有长链接的 SSH 会话，系统目录下忽然出现新的可疑文件等等。这些异常行为往往是服务器被攻击的征兆，需要进一步分析与取证。<br>用 UEBA 技术定位失陷主机通常的思路是，基于相应设备和主机执行的高风险异常事件和活动，建立异常时间线，然后关联各种实体参数，包括：端点安全警报、漏洞扫描结果（常见漏洞评分系统[CVSS]）、用户或帐户的风险级别、访问的目标、请求的有效负载的数据包级别等等，从多维度检测任何异常活动或事件以确定风险评分。</p><h1 id="四、UEBA主要实现技术"><a href="#四、UEBA主要实现技术" class="headerlink" title="四、UEBA主要实现技术"></a>四、UEBA主要实现技术</h1><p>UEBA 是一个完整的系统，涉及到算法、工程等检测部分，以及用户实体风险评分排序、调查等用户交互、反馈。从架构上来看，UEBA 系统一般包含三个层次，分别是数据中心层、算法分析层、场景应用层。其中，算法分析层一般大数据计算平台之上运行实时分析、统计分析、关联分析、机器学习等分析引擎。<br><img src="https://img-blog.csdnimg.cn/40c8886fa2654532850b7134ce32b88f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="UEBA架构"></p><p>机器学习引擎实现，如基线及群组分析、异常检测、集成学习风险评分、安全知识图谱、强化学习等UEBA 核心技术。</p><h2 id="基线及群组分析"><a href="#基线及群组分析" class="headerlink" title="基线及群组分析"></a>基线及群组分析</h2><p>历史基线，是行为分析的重要部分，通过构建群组分析，可以跨越单个用户、实体的局限，看到更大的事实；通过对比群组，易于异常检测；通过概率评估可以降低误报，提升信噪比；组合基线分析、群组分析，可以构成全时空的上下文环境。</p><h2 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h2><p>异常检测关注发现统计指标异常、时序异常、序列异常、模式异常等异常信号，采用的技术包括孤立森林、K 均值聚类、时序分析、异常检测、变点检测等传统机器学习算法。现代的异常检测也利用深度学习技术，包括基于变分自编码器（VAE）的深度表征重建异常检测、基于循环神经网络（RNN）和长短时记忆网络（LSTM）的序列深度网络异常检测、图神经网络（GNN）的模式异常检测等。针对标记数据缺乏的现状，某些UEBA 系统能够采用主动学习技术（Active Learning）、自学习（Self Learning），充分发掘标记数据和无标记数据的价值。</p><h2 id="集成学习风险评分"><a href="#集成学习风险评分" class="headerlink" title="集成学习风险评分"></a>集成学习风险评分</h2><p>把安全运维从事件管理转换到用户、实体风险，极大的降低工作量、提升效率。其中，实现转换的关键在于使用集成学习进行风险评分。风险评分需要综合各种告警、异常，以及进行群组对比分析和历史趋势。同时，风险评分技术中用户间风险的传导同样重要，需要一套类似谷歌搜索使用的网页排名PageRank 算法的迭代评估机制。风险评分的好坏，将直接影响到UEBA 实施的成效，进而直接影响到安全运营的效率。</p><h2 id="安全知识图谱"><a href="#安全知识图谱" class="headerlink" title="安全知识图谱"></a>安全知识图谱</h2><p>知识图谱已经成为人工智能领域的热点方向，在网络安全中同样也有巨大的应用潜力。部分UEBA 系统已经支持一定的安全知识图谱能力，可以将从事件、告警、异常、访问中抽取出的实体及实体间关系，构建成一张网络图谱。任何一个事件、告警、异常，都可以集成到网络图谱中，直观、明晰的呈现多层关系，可以让分析抵达更远的边界，触达更隐蔽的联系，揭露出最细微的线索。结合攻击链和知识图谱的关系回放，还能够让安全分析师近似真实的复现攻击全过程，了解攻击的路径与脆弱点，评估潜在的受影响资产，从而更好的进行应急响应与处置。</p><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p>不同客户的环境数据源的多元性及差异性，以及用户对异常风险的定义各有不同， UEBA 需要具有一定的自适应性，输出更精准的异常风险。强化学习能够根据排查结果自适应地调整正负权重反馈给系统，进而得到更符合客户期望的风险评分。UEBA 给出异常信号后，结合安全管理人员的排查结果，获取反馈奖赏或惩罚，通过学习进行正负权重调整，从而让整体效果持续优化改进。</p><h1 id="五、UEBA行业发展趋势"><a href="#五、UEBA行业发展趋势" class="headerlink" title="五、UEBA行业发展趋势"></a>五、UEBA行业发展趋势</h1><p>Gartner《Market Guide for User and Entity Behavior Analytics》报告中指出：<br>终端用户在UEBA独立解决方案上的支出将呈复合式增长年增长率为48％，从2015年的5,000万美元增长到2020年的3.52亿美元。<br>UEBA解决方案供应商在2017年和2018年继续减少，主要是由于收购活动。Gartner预计该领域将继续整合，同时在其服务于相邻细分市场的产品中使用UEBA技术的厂商数量也在大幅增加。<br>到2021年，用户和实体行为分析（UEBA）市场将不再是一个独立的市场。<br>一些UEBA供应商现在将其市场战略路线聚焦于将其核心UEBA技术嵌入其他供应商的更传统的安全解决方案中。到2022年，UEBA的核心技术将嵌入80％的威胁检测和事件高级解决方案中（如SIEM）。<br>Gartner认为这一趋势将持续到2022年，届时UEBA将成为被更广泛的安全分析技术所取代。</p><p>IndustryARC《UEBA Market - Forecast(2020 - 2025)》报告：<br>到2025年，用户和实体行为分析市场预计将达到49亿美元，从2020年到2025年，复合年增长率为41.5％。<br>UEBA是一种用于检测内部风险，财务欺诈和针对性攻击的机制。该方法用于分析人类行为模式，然后使用统计分析和算法来识别差异。<br>UEBA是一种机器学习模型，可以通过检测保护异常来帮助阻止网络攻击者。UEBA使用高级分析，汇总日志和报告数据，并分析数据包，流，文件和其他类型的信息以及其他类型的威胁数据，以评估某些形式的活动和动作是否可能构成网络攻击。<br>UEBA的优势包括–内部威胁识别，防止数据泄露，识别和防止欺诈，可操作的风险信息以及IP数据的安全性。<br>UEBA逐渐成为对全面网络威胁和欺诈的最有希望的回应。软件提供商更专注于确保可靠的算法和集成分析，以及开发应用程序系统。</p><p>综合上述报告可以看出：<br>UEBA市场价值正在飞速上升，UEBA技术研究前景广阔。<br>UEBA发展方向不再是一个独立个体，而是倾向于将UEBA技术嵌入到其他高级安全解决方案中。</p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、背景&quot;&gt;&lt;a href=&quot;#一、背景&quot; class=&quot;headerlink&quot; title=&quot;一、背景&quot;&gt;&lt;/a&gt;一、背景&lt;/h1&gt;&lt;p&gt;数字新时代正在加速全面到来，网络环境变得更加多元、人员变得更复杂、接入方式多种多样，网络边界逐渐模糊甚至消失，同时伴随着企业
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>网络信息安全常用术语</title>
    <link href="https://xiejava.gitee.io/posts/78dcbe69/"/>
    <id>https://xiejava.gitee.io/posts/78dcbe69/</id>
    <published>2022-03-22T01:21:37.000Z</published>
    <updated>2022-03-22T01:24:03.516Z</updated>
    
    <content type="html"><![CDATA[<p>网络信息安全术语是获取网络安全知识和技术的重要途径，常见的网络安全术语可以分为基础技术类、风险评估技术类、防护技术类、检测技术类、响应/恢复技术类、测评技术类等。</p><p>下面主要介绍常见的网络安全技术方面的术语</p><h2 id="一、基础技术类"><a href="#一、基础技术类" class="headerlink" title="一、基础技术类"></a>一、基础技术类</h2><p>基础技术类常见的是密码及加解密相关的技术<br><strong>密码（Cipher）</strong><br>一种用于加密和解密数据的算法。</p><p><strong>密码学（Cryptography）</strong><br>编码研究。同样，使用代码/密码/数学技术来保护数据并提供实体和数据的身份验证。</p><p><strong>密钥（Secret key）</strong><br>用于加密和解密的加密密钥，使对称密钥加密方案能够运行。</p><p><strong>编码(Encode)</strong><br>使用代码将一种符号转换为另外一种符号。</p><p><strong>加密(Encryption)</strong><br>使用密码来保护信息，这使任何没有密钥对其解密的人都无法读取。</p><p><strong>解密（Decryption）</strong><br>将编码文本解密为原始原始格式的过程。</p><p><strong>证书（Certificate）</strong><br>数字证书是数字身份验证的一种形式，它允许计算机，用户或组织安全地交换信息。</p><h2 id="二、攻击技术类"><a href="#二、攻击技术类" class="headerlink" title="二、攻击技术类"></a>二、攻击技术类</h2><p><strong>拒绝服务（Denial of Service）</strong><br>是指通过向 服务器 发送大量垃圾信息或干扰信息的 方式 ，导致服务器无法向正常用户提供服务的现象。</p><p><strong>分布式拒绝服务（Distributed Denial of Service）</strong><br>指处于不同位置的多个攻击者同时向一个或数个目标发动攻击，或者一个攻击者控制了位于不同位置的多台机器并利用这些机器对受害者同时实施攻击。由于攻击的发出点是分布在不同地方的，这类攻击称为分布式拒绝服务攻击。</p><p><strong>网页篡改（Website Distortion）</strong><br>网页篡改是恶意破坏或更改网页内容，使网站无法正常工作或出现黑客插入的非正常网页内容。</p><p><strong>网页仿冒（Phishing）</strong><br>网页仿冒是通过构造与某一目标网站高度相似的页面（俗称钓鱼网站），并通常以垃圾邮件、即时聊天、手机短信或网页虚假广告等方式发送声称来自于被仿冒机构的欺骗性消息，诱骗用户访问钓鱼网站，以获取用户个人秘密信息（如银行账号和账户密码）。</p><p><strong>网页挂马（Website Malicious Code）</strong><br>网页挂马是通过在网页中嵌入恶意代码或链接，致使用户计算机在访问该页面时被植入恶意代码。</p><p><strong>域名劫持（DNS Hijack）</strong><br>域名劫持是通过拦截域名解析请求或篡改域名服务器上的数据，使得用户在访问相关域名时返回虚假IP地址或使用户的请求失败。</p><p><strong>路由劫持（Routing Hijack）</strong><br>路由劫持是通过欺骗方式更改路由信息，以导致用户无法访问正确的目标，或导致用户的访问流量绕行黑客设定的路径，以达到不正当的目的。</p><p><strong>垃圾邮件（Spam）</strong><br>垃圾邮件是将不需要的消息（通常是未经请求的广告）发送给众多收件人。包括：收件人事先没有提出要求或者同意接受的广告、电子刊物、各种形式的宣传品等宣传性的电子邮件；收件人无法拒收的电子邮件；隐藏发件人身份、地址、标题等信息的电子邮件；含有虚假的信息源、发件人、路由等信息的电子邮件。</p><p><strong>特洛伊木马（Trojan Horse）</strong><br>特洛伊木马（简称木马）是以盗取用户个人信息，甚至是远程控制用户计算机为主要目的的恶意代码。由于它像间谍一样潜入用户的电脑，与战争中的 “木马”战术十分相似，因而得名木马。按照功能，木马程序可进一步分为：盗号木马、网银木马、窃密木马、远程控制木马、流量劫持木马和其他木马六类。</p><p><strong>网络蠕虫（Network Worm）</strong><br>网络蠕虫是指能自我复制和广泛传播，以占用系统和网络资源为主要目的恶意代码。按照传播途径，蠕虫可进一步分为：邮件蠕虫、即时消息蠕虫、U盘蠕虫、漏洞利用蠕虫和其他蠕虫五类。</p><p><strong>僵尸程序（Bot）</strong><br>僵尸程序是用于构建僵尸网络以形成大规模攻击平台的恶意代码。按照使用的通信协议，僵尸程序可进一步分为：IRC僵尸程序、Http僵尸程序、P2P僵尸程序和其他僵尸程序四类。</p><p><strong>僵尸网络（Bot Net）</strong><br>僵尸网络是被黑客集中控制的计算机群，其核心特点是黑客能够通过一对多的命令与控制信道操纵感染僵尸程序的主机执行相同的恶意行为，如可同时对某目标网站进行分布式拒绝服务攻击，或发送大量的垃圾邮件等。</p><p><strong>SQL注入（SQL injection）</strong><br>一种使用代码注入来攻击由数据驱动的应用程序的策略。恶意注入的SQL代码可以执行多种操作，包括将所有数据转储到攻击者控制的位置的数据库中。通过这种攻击，恶意黑客可以欺骗身份，修改数据或篡改数据，泄露机密数据，删除和销毁数据或使其不可用。他们还可以完全控制数据库。</p><p><strong>网络钓鱼（Phishing）</strong><br>大量电子邮件要求提供敏感信息或将其推送到假网站。这些电子邮件通常没有针对性。</p><p><strong>宏病毒（Macro virus）</strong><br>一种恶意代码，使用文档应用程序的宏编程功能来执行不当行为，自我复制并在整个系统中传播。</p><p><strong>恶意代码（Malicious code）</strong><br>恶意代码是指在未经授权的情况下，在信息系统中安装、执行以达到不正当目的的程序。旨在损害信息系统的机密性，完整性或可用性。</p><p><strong>恶意广告（Malvertising）</strong><br>使用在线广告投放恶意软件。</p><p><strong>恶意软件（Malware）</strong><br>恶意软件的简称。任何可能对组织或个人造成不利影响的病毒，特洛伊木马，蠕虫，代码或内容。</p><p><strong>中间人攻击（MitM）</strong><br>网络罪犯将自己置于受害者和受害者试图访问的网站之间，以获取正在传输的信息或对其进行更改。有时缩写为MITM，MIM，MiM或MITMA。</p><p><strong>逻辑炸弹（Logic bomb）</strong><br>一段带有一组秘密指令的代码。它被插入系统并由特定操作触发。该代码通常执行恶意操作，例如删除文件。</p><p><strong>高级持久威胁（APT）</strong><br>一种网络攻击，使用复杂的技术持续对目标政府和公司进行网络间谍活动或其他恶意活动。通常由具有丰富专业知识和大量资源的对手进行-通常与民族国家参与者相关。<br>这些攻击往往来自多个入口点，并且可能使用多个攻击媒介（例如，网络攻击，物理攻击，欺骗攻击）。一旦系统遭到破坏，结束攻击可能非常困难。</p><p><strong>被动攻击（Passive attack）</strong><br>攻击者试图获取机密信息以将其提取。因为他们不尝试更改数据，所以这种类型的攻击更难检测-因此称为“被动”。</p><p><strong>密码嗅探（Password sniffing）</strong><br>通过监视或监听网络流量以检索密码数据来收集密码的技术。</p><p><strong>有效载荷（Payload）</strong><br>执行恶意操作的恶意软件元素–网络安全性等同于导弹的爆炸性电荷。通常说来是造成破坏的。</p><p><strong>勒索软件（Ransomware）</strong><br>勒索软件是一种恶意软件（恶意软件），它对PC或移动设备上的所有数据进行加密，从而阻止数据所有者对其进行访问。感染发生后，受害者会收到一条消息，告知他/她必须支付一定数量的钱（通常以比特币支付）才能获得解密密钥。通常，支付赎金也有时间限制。如果受害者支付赎金，则不能保证解密密钥会被移交。最可靠的解决方案是至少在三个不同的位置备份数据（以确保冗余），并使这些备份保持最新状态，这样您就不会失去重要的进展。</p><p><strong>社会工程学（Social engineering）</strong><br>操纵人们执行特定的动作或泄露对攻击者有用的信息。操纵策略包括谎言，心理技巧，贿赂，勒索，假冒和其他类型的威胁。社交工程通常用于提取数据并获得对信息系统的未授权访问，这些信息系统可以是单个私人用户，也可以是组织的信息系统。</p><h2 id="三、防护技术类"><a href="#三、防护技术类" class="headerlink" title="三、防护技术类"></a>三、防护技术类</h2><p><strong>访问控制（Access Control）</strong><br>访问控制是按用户身份及其所归属的某项定义组来限制用户对某些信息项的访问，或限制对某些控制功能的使用的一种技术。</p><p><strong>防火墙（Firewall）</strong><br>网络或设备周围的虚拟边界，用于保护网络或设备免受不必要的访问。可以是硬件或软件。</p><p><strong>入侵防御系统（Intrusion Prevention System）</strong><br>是一部能够监视网络或网络设备的网络资料传输行为的计算机网络安全设备，能够及时的中断、调整或隔离一些不正常或是具有伤害性的网络资料传输行为。</p><p><strong>防毒软件(Antivirus)</strong><br>防病毒软件用于监视计算机或网络，以检测从恶意代码到恶意软件的网络安全威胁。防病毒程序不仅可以警告您威胁的存在，还可以删除或消除恶意代码。</p><p><strong>蜜罐（蜜网）Honeypot (honeynet)</strong><br>诱骗系统或网络，用于吸引潜在的攻击者，通过检测攻击或使攻击发生偏转来保护实际系统。一个学习攻击方式的好工具。多个蜜罐可以组成一个蜜网。</p><p><strong>安全信息和事件管理（SIEM）</strong><br>用于监视，记录，提供警报和分析安全事件以支持威胁检测和事件响应的软件。</p><p><strong>安全监控（Security monitoring）</strong><br>从一系列安全系统中收集数据，并将这些信息与威胁情报进行关联和分析，以识别出受到威胁的迹象。</p><h2 id="四、检测技术类"><a href="#四、检测技术类" class="headerlink" title="四、检测技术类"></a>四、检测技术类</h2><p><strong>入侵检测（Instrusion Detection）</strong><br>是一种对网络传输进行即时监视，在发现可疑传输时发出警报或者采取主动反应措施的网络安全设备。</p><p><strong>漏洞扫描（Vulnerability Scanning）</strong><br>是对网络设备及应用服务的可用性、安全性与合规性等进行扫描，发现可利用漏洞的一种安全检测（渗透攻击）行为。</p><p><strong>威胁分析（Threat analysis）</strong><br>对单个威胁的特征进行详细评估。</p><h2 id="五、响应-恢复技术类"><a href="#五、响应-恢复技术类" class="headerlink" title="五、响应/恢复技术类"></a>五、响应/恢复技术类</h2><p><strong>应急响应（Emergency Response）</strong><br>应急响应通常是指一个组织为了应对各种意外事件的发生所做的准备工作以及在突发事件发生时或者发生后所采取的措施。</p><p><strong>灾难恢复（Disaster Recovery）</strong><br>灾难恢复也称灾备，指自然或人为 灾害 后，重新启用 信息系统 的 数据 、 硬件 及 软体 设备，恢复正常商业运作的过程。</p><p><strong>备份文件（Backup files）</strong><br>一种用户以后数据恢复的文件</p><p><strong>备份（Backup）</strong><br>为应付文件、数据丢失或损坏等可能出现的意外情况，将电子计算机存储设备中的数据复制到磁带等大容量存储设备中。从而在原文中独立出来单独贮存的程序或文件副本。</p><p><strong>应急预案（Contingency plan）</strong><br>一种关于备份、应急响应和灾后恢复的计划。</p><p><strong>灾难恢复计划（Disaster recovery plan）</strong><br>信息系统灾难恢复过程中所需要的任务、行动、数据和资源的文件，用于指导相关人员在预定的灾难恢复目标内恢复系统系统支持的关键业务功能。</p><h2 id="六、评测技术类"><a href="#六、评测技术类" class="headerlink" title="六、评测技术类"></a>六、评测技术类</h2><p><strong>评价方案（Evaluation scheme）</strong><br>针对一个特定的团体，由某一评价机构根据指定标准制定的行政管理的与规章制度的框架。</p><p><strong>渗透测试（Penetration testing）</strong><br>一种旨在探查和暴露信息系统中的安全性弱点以便对其进行修复的测试。</p><p><strong>质量评价（Quality evaluation）</strong><br>对实体满足规定要求程度而进行的系统性检查</p><p><strong>威胁评估（Threat assessment）</strong><br>识别或评估具有或表明可能危害生命，信息，操作和/或财产的实体，动作或事件（自然或人为）的产品或过程。</p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;网络信息安全术语是获取网络安全知识和技术的重要途径，常见的网络安全术语可以分为基础技术类、风险评估技术类、防护技术类、检测技术类、响应/恢复技术类、测评技术类等。&lt;/p&gt;
&lt;p&gt;下面主要介绍常见的网络安全技术方面的术语&lt;/p&gt;
&lt;h2 id=&quot;一、基础技术类&quot;&gt;&lt;a hre
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>网络信息安全基本属性</title>
    <link href="https://xiejava.gitee.io/posts/ec5a2543/"/>
    <id>https://xiejava.gitee.io/posts/ec5a2543/</id>
    <published>2022-03-17T11:33:32.000Z</published>
    <updated>2022-03-17T11:34:54.991Z</updated>
    
    <content type="html"><![CDATA[<p>常见的网络信息安全基本属性主要有机密性、完整性、可用性、不可抵赖性和可控性等，其中<strong>机密性（Confidentiality）、完整性（Integrity）、可用性（Availability）被称为网络信息系统核心的CIA安全属性</strong>，此外还有其他的安全属性包括：真实性、时效性、合规性、隐私性等。<br><img src="https://img-blog.csdnimg.cn/4ec5c965ed574be4b904588f50e889bf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_9,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="网络信息安全基本属性"></p><h2 id="机密性"><a href="#机密性" class="headerlink" title="机密性"></a>机密性</h2><p>机密性（Confidentiality）是指网络信息不泄露给非授权的用户、实体或程序，能够防止非授权者获取信息。这些信息不仅包括国家机密，也包括企业和社会团体的商业机密和工作机密，还包括个人信息。例如，网络信息系统上传递口令敏感信息，若一旦攻击者通过监听手段获取到，就有可能危及网络系统的整体安全。人们在应用网络时很自然地要求网络能提供保密性服务，而被保密的信息既包括在网络中传输的信息，也包括存储在计算机系统中的信息。就像电话可以被窃听一样，网络传输信息也可以被窃听，解决的办法就是对传输信息进行加密处理。存储信息的机密性主要通过访问控制来实现，不同用户对不同数据拥有不同的权限。</p><h2 id="完整性"><a href="#完整性" class="headerlink" title="完整性"></a>完整性</h2><p>完整性（Integrity）是指网络信息或系统未经授权不能进行改变的特性。即信息在存储或传输过程中保持不被修改、不被破坏和丢失的特性。数据的完整性是指保证计算机系统上的数据和信息处于一种完整和未受损害的状态，这就是说数据不会因为有意或无意的事件而被改变或丢失。除了数据本身不能被破坏外，数据的完整性还要求数据的来源具有正确性和可信性，也就是说需要首先验证数据是真实可信的，然后再验证数据是否被破坏。影响数据完整性的主要因素是人为的蓄意破坏，也包括设备的故障和自然灾害等因素对数据造成的破坏。</p><h2 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h2><p>可用性（Availability）是指合法许可的用户能够及时获取网络信息或服务的特征，即可授权实体或用户访问并按要求使用信息的特性。简单地说，就是保证信息在需要时能为授权者所用，防止由于主客观因素造成的系统拒绝服务。例如，网站能够给用户提供正常的网页访问服务，防止拒绝服务攻击。</p><h2 id="不可抵赖性"><a href="#不可抵赖性" class="headerlink" title="不可抵赖性"></a>不可抵赖性</h2><p>不可抵赖性也称不可否认性。是指防止网络信息系统相关用户否认其活动行为的特性。在信息交换过程中，确信参与方的真实同一性，即所有参与者都不能否认和抵赖曾经完成的操作和承诺。简单地说，就是发送信息方不能否认发送过信息，信息的接收方不能否认接收过信息。利用信息源证据可以防止发信方否认已发送过信息，利用接收证据可以防止接收方事后否认已经接收到信息。数据签名技术是解决不可否认性的重要手段之一。</p><h2 id="可控性"><a href="#可控性" class="headerlink" title="可控性"></a>可控性</h2><p>可控性是指网络信息系统责任主体对其具有管理、支配能力的属性，能够根据授权规则对系统进行有效掌握和控制，使得管理者有效地控制系统的行为和信息的使用，符合系统运行目标。是人们对信息的传播路径、范围及其内容所具有的控制能力，如：不允许不良内容通过公共网络进行传输，使信息在合法用户的有效掌控之中</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>除常见的网络信息系统安全特性，还有真实性、时效性、合规性、公平性、可靠性、可生存性和隐私性等，这些安全特性适用于不同类型的网络信息系统，其要求程度有所差异。</p><h3 id="1-真实性"><a href="#1-真实性" class="headerlink" title="1.真实性"></a>1.真实性</h3><p>真实性是指网络空间信息与实际物理空间、社会空间的客观事实保持一致性。如，网络谣言信息不符合真实情况，违背了客观事实。</p><h3 id="2-时效性"><a href="#2-时效性" class="headerlink" title="2.时效性"></a>2.时效性</h3><p>时效性是指网络空间信息、服务及系统能够满足时间约束要求。如，汽车安全驾驶的智能控制系统要求信息具有实时性，信息在规定时间范围内才有效。</p><h3 id="3-合规性"><a href="#3-合规性" class="headerlink" title="3.合规性"></a>3.合规性</h3><p>合规性是指网络信息、服务及系统符合法律法规政策、标准规范等要求。如，网站内容如何法律法规政策要求等。</p><h3 id="4-公平性"><a href="#4-公平性" class="headerlink" title="4.公平性"></a>4.公平性</h3><p>公平性是指网络信息系统相关主体处于同等地位处理相关任务，任何一方不占据优势的特性要求。如，电子合同签订双方符合公平性要求，在同一时间签订合同。</p><h3 id="5-可靠性"><a href="#5-可靠性" class="headerlink" title="5.可靠性"></a>5.可靠性</h3><p>可靠性是指网络信息系统在规定条件及时间下，能够有效完成预定的系统功能的特性。</p><h3 id="6-可生存性"><a href="#6-可生存性" class="headerlink" title="6.可生存性"></a>6.可生存性</h3><p>可生存性是指网络信息系统在安全受损的情形下，提供最小化、必要的服务功能，能够支撑业务继续运行的安全特性。</p><h3 id="7-隐私性"><a href="#7-隐私性" class="headerlink" title="7.隐私性"></a>7.隐私性</h3><p>隐私性是指有关个人的敏感信息不对外公开的安全属性，如个人的身份证号码、住址、电话号码、工资收入、疾病状况、社交关系等。</p><p>网络攻击是指损害网络系统安全属性的危害行为。危害行为导致网络系统的机密性、可用性、可控性、真实性、抗抵赖性等受到不同程度的破坏。常见的危害行为有四个基本类型：</p><ul><li>信息泄露攻击； </li><li>完整性破坏攻击； </li><li>拒绝服务攻击； </li><li>非法使用攻击。</li></ul><p>本文整理自《信息安全工程师教程第2版》</p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;常见的网络信息安全基本属性主要有机密性、完整性、可用性、不可抵赖性和可控性等，其中&lt;strong&gt;机密性（Confidentiality）、完整性（Integrity）、可用性（Availability）被称为网络信息系统核心的CIA安全属性&lt;/strong&gt;，此外还有其他
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>网络安全之常用安全设备功能及作用</title>
    <link href="https://xiejava.gitee.io/posts/4696bbec/"/>
    <id>https://xiejava.gitee.io/posts/4696bbec/</id>
    <published>2022-03-07T06:38:40.000Z</published>
    <updated>2022-03-07T06:42:37.556Z</updated>
    
    <content type="html"><![CDATA[<p>随着网络技术发展，网络威胁无孔不入，网络攻击手段呈现复杂性及多变性的趋势。要建立防御体系应从通信网络、网络边界、局域网络内部、各种业务应用平台等各个层次落实各种安全措施，形成纵深防御体系。单靠一种或几种安全设备就想保护整个网络是不可能的事情。因此，为了满足不同防护需求的安全设备应运而生。有的设备是为了严防非授权访问。有的设备是为了实时检测，拦截攻击行为。有的设备是为了自查自审，发现自身存在的问题。每一种安全设备分工都不同，设备缺失肯定会使防御体系失效造成安全隐患。</p><p>本文介绍常用的安全设备及其能力</p><h3 id="网络安全审计"><a href="#网络安全审计" class="headerlink" title="网络安全审计"></a>网络安全审计</h3><p>网络安全审计通过对网络数据的采集、分析、识别，实时动态监测通信内容、网络行为和网络流量，发现和捕获各种敏感信息、违规行为，实时报警响应，全面记录网络系统中的各种会话和事件，实现对网络信息的智能关联分析、评估及安全事件的准确定位，为整体网络安全策略的制定提供权威可靠的支持。</p><ul><li>内容审计<br>可对网页内容、邮件、数据库操作、论坛、即时通讯等提供完整的文本、图片和音视频内容检测、信息还原功能；并可自定义关键字库，进行细粒度的审计追踪。</li><li>行为审计<br>根据设定的行为审计策略，对网站访问、邮件收发、数据库访问、远程终端访问、文件上传下载、即时通讯、论坛、移动应用、在线视频、P2P 下载、网络游戏等网络应用行为进行监测，对符合行为策略的事件实时告警并记录。</li><li>流量审计<br>支持基于智能协议识别的流量分析功能；实时统计出当前网络中的各种协议流量，进行综合流量分析，提供详细的流量报表；可以统计指定协议流量的IP TOP N，为流量管理策略的制定提供可靠支持。</li></ul><h3 id="漏洞扫描"><a href="#漏洞扫描" class="headerlink" title="漏洞扫描"></a>漏洞扫描</h3><p>通过漏洞扫描全面发现信息系统存在的安全漏洞、安全配置问题、应用系统安全漏洞，检查系统存在的弱口令，收集系统不必要开放的账号、服务、端口，形成整体安全风险报告。</p><ul><li>全面系统脆弱性发现<br>能够全方位检测系统存在的脆弱性，发现信息系统存在的安全漏洞、安全配置问题、应用系统安全漏洞，检查系统存在的弱口令，收集系统不必要开放的账号、服务、端口，形成整体安全风险报告，帮助安全管理人员先于攻击者发现安全问题，及时进行修补。</li><li>风险统一分析<br>支持全方位的安全漏洞、安全配置、应用系统安全漏洞扫描，通过安全风险计算方法，对网络系统中多个方面的安全脆弱性统一进行分析和风险评估，给出总体安全状态评价，全面掌握信息系统安全风险。</li><li>识别非标准端口<br>应用先进的非标准端口识别技术、以及丰富的协议指纹库，能够快速准确的识别非标准端口上的应用服务类型，并进一步进行漏洞检测，避免扫描过程中的漏报和误报。</li><li>漏洞、配置知识库<br>依托安全知识库，涵盖所有主流基础系统、应用系统、网络设备等网元对象，提供系统<br>的配置检查库，提供专业安全厂商的加固修补建议，以及多个行业的安全配置检查标准。</li></ul><h3 id="Web漏洞扫描"><a href="#Web漏洞扫描" class="headerlink" title="Web漏洞扫描"></a>Web漏洞扫描</h3><p>定位于Web 脆弱性评估，实现全面Web 应用安全检测。帮助用户全面发现Web 漏洞，准确掌控网站风险，深度跟踪漏洞态势，提升快速响应能力。</p><ul><li>漏洞扫描及验证<br>支持系统漏洞扫描以及Web 漏洞扫描，支持Web 应用漏洞分类，全面覆盖OWASP TOP10 应用风险，高中危漏洞专家级验证。</li><li>网站挂马及黑链检测<br>依托沙箱检测技术，识别网站页面中的恶意代码，对潜藏在用户网页中的黄赌毒私服等广告黑链进行周期性检测，并将挂马及黑链情况及时邮件提醒。</li><li>网站篡改检测<br>依托相似度对比技术，识别网页变更状态，并通知用户。</li><li>网页敏感内容检测<br>依托于敏感内容词库，识别网页中的敏感内容，并邮件提醒。</li><li>可用性检测及 DNS 解析检测<br>依托多个检测节点，多条检测线路，识别网站运营是否稳定的问题，并邮件提醒。</li></ul><h3 id="堡垒机"><a href="#堡垒机" class="headerlink" title="堡垒机"></a>堡垒机</h3><p>针对云主机、云数据库、网络设备等的运维权限、运维行为进行管理和审计。主要解决云上IT运维过程中操作系统账号复用、数据泄露、运维权限混乱、运维过程不透明等难题。</p><ul><li>登录功能<br>支持对X11、linux、unix、数据库、网络设备、安全设备等一系列授权账号进行密码的自动化周期更改，简化密码管理，让使用者无需记忆众多系统密码，即可实现自动登录目标设备，便捷安全。</li><li>账号管理<br>支持统一账户管理策略，能够实现对所有服务器、网络设备、安全设备等账号进行集中管理，完成对账号整个生命周期的监控，并且可以对设备进行特殊角色设置如：审计巡检员、运维操作员、设备管理员等自定义设置，以满足审计需求。</li><li>身份认证<br>提供统一的认证接口，对用户进行认证，支持身份认证模式包括动态口令、静态密码、硬件key、生物特征等多种认证方式，设备具有灵活的定制接口，可以与其他第三方认证服务器之间结合；安全的认证模式，有效提高认证的安全性和可靠性。</li><li>资源授权<br>提供基于用户、目标设备、时间、协议类型IP、行为等要素实现细粒度的操作授权，最大限度保护用户资源的安全。</li><li>访问控制<br>支持对不同用户进行不同策略的制定，细粒度的访问控制能够最大限度的保护用户资源的安全，严防非法、越权访问事件的发生。</li><li>操作审计<br>能够对字符串、图形、文件传输、数据库等全程操作行为审计；通过设备录像方式实时监控运维人员对操作系统、安全设备、网络设备、数据库等进行的各种操作，对违规行为进行事中控制。对终端指令信息能够进行精确搜索，进行录像精确定位。</li></ul><h3 id="日志审计"><a href="#日志审计" class="headerlink" title="日志审计"></a>日志审计</h3><p>日志审计是针对大量分散设备的异构日志进行高效采集、统一管理、集中存储、统计分析，可协助企业满足等保合规要求、高效统一管理资产日志并为安全事件的事后取证据供依据。</p><ul><li>安全日志源管理<br>按照需要接入的日志源数量进行服务，提供多种日志接入方式，支持主动、被动采集。</li><li>日志采集<br>提供全面的日志采集能力：支持第三方安全设备、网络设备、数据库、windows/linux主机日志、web 服务器日志、虚拟化平台日志以及自定义等日志；提供强大的数据源管理功能:支持数据源的信息展示与管理、采集器的信息展示与管理以及agent 的信息展示与管理；提供分布式外置采集器、Agent 等多种日志采集方式；支持IPv4、IPv6 日志采集、分析以及检索查询。</li><li>日志存储<br>提供原始日志、范式化日志的存储，可自定义存储周期。</li><li>日志检索<br>提供丰富灵活的日志查询方式，支持全文.key-value、多kv布尔组合、括弧、正则、模糊等检索；提供便捷的日志检索操作，支持保存检索、从已保存的检索导入见多条件等。</li><li>报表管理<br>支持丰富的内置报表以及灵活的自定义报表模式，支持编辑报表的目录接口、引用统计项、设置报表标题、展示页眉和页码、报表配置基本内容（名称、描述等）；支持实时报表、定时报表、周期性任务报表等方式；支持html、pdf、word 格式的报表文件以及报表logo<br>的灵活配置。</li><li>日志分析<br>支持对各类应用系统产生的各类日志的分析功能。</li></ul><h3 id="数据库审计"><a href="#数据库审计" class="headerlink" title="数据库审计"></a>数据库审计</h3><p>数据库审计能够实时记录网络上的数据库活动，对数据库操作进行细粒度审计的合规性管理，对数据库遭受到的风险行为进行告警，对攻击行为进行阻断。通过对用户访问数据库行为的记录、分析和汇报，用来帮助用户事后生成合规报告、事故追根溯源，同时加强内外<br>部数据库网络行为记录，提高数据资产安全。</p><ul><li>实时告警<br>风险操作：支持通过操作类型、操作对象、风险等级等多种元素细粒度定义要求监控的风险操作行为。<br>SQL 注入：数据库安全审计提供SQL 注入库，可以基于SQL 命令特征或风险等级，发现数据库异常行为立即告警。<br>系统资源：当系统资源（CPU、内存和磁盘）占用率达到设置的告警阈值时立即告警。</li><li>多维度线索分析<br>行为线索：支持审计时长、语句总量、风险总量、风险分布、会话统计、SQL 分布等多维度的快速分析。<br>会话线索：支持根据时间、数据库用户、客户端等多角度进行分析。<br>语句线索：提供时间、风险等级、数据用户、客户端IP、数据库IP、操作类型、规则等多种语句搜索条件。</li><li>用户行为发现审计<br>关联应用层和数据库层的访问操作：提供内置或自定义隐私数据保护规则，防止审计日志中的隐私数据（例如，账号密码）在控制台上以明文显示。</li><li>精细化报表<br>会话行为：提供客户端和数据库用户会话分析报表。<br>风险操作：提供风险分布情况分析报表。<br>合规报表：提供满足数据安全标准（例如Sarbanes-Oxley）的合规报告。</li></ul><h3 id="网页防篡改"><a href="#网页防篡改" class="headerlink" title="网页防篡改"></a>网页防篡改</h3><p>网页防篡改是针对网站篡改攻击的防护，通过文件底层驱动技术对Web站点目录提供全方位的保护，为防止黑客、病毒等对目录中的网页、电子文档、图片、数据库等任何类型的文件进行非法篡改和破坏提供解决方案。</p><ul><li>篡改防护<br>同时对多台网站服务器文件，对同一台服务器内的多个web server，对同一web server内的多个virtual host进行防篡改；异地（非网站目录）保留篡改后页面快照，支持网站篡改检测；保护防篡改内嵌模块和守护进程。</li><li>防篡改分析<br>支持页面文件/结构/元素的哈希（MD5）值篡改检测、图片相似性比较。</li><li>攻击防护<br>能够防止SQL 数据库注入式攻击；能够防止跨站脚本漏洞；能够防止网站盗链。</li><li>发布备份<br>支持内容发布；支持实时同步；支持手动同步；可按照条件（按时间戳前，后，区间；按子文件夹；按WEB 服务器）；支持双机热备功能；实体间通信采用SSL 加密。</li><li>日志告警<br>保存系统日志；文件传输日志；支持篡改告警、SQL 注入告警、盗链告警，告警通知<br>支持手机短信通知、邮件通知、管理界面警示框；可通过图形报表综合统计和分析。</li></ul><h3 id="入侵检测系统"><a href="#入侵检测系统" class="headerlink" title="入侵检测系统"></a>入侵检测系统</h3><p>入侵检测系统是一种对网络传输进行即时监视，在发现可疑传输时发出警报或者采取主动反应措施的网络安全系统。根据预先设定的安全策略，它是一种积极主动的安全防护技术。</p><ul><li>敏感数据外发检测<br>能够识别并检测特定格式文件的外发，同时能够检测出文件中包含的敏感数据，进行告<br>警，保护企业敏感数据，防止敏感数据泄露造成的损失。</li><li>客户端攻击检测<br>增加针对主流客户端应用程序的攻击签名规则，如Word、Excel、PDF、Firefox 等，增强客户终端应用程序的安全检测能力。</li><li>服务器非法外联检测<br>通过服务器的自学习功能或手动设置服务器正常外联行为，建立合法连接，能够检测服务器异于该合法连接的非法外联行为，及时产生告警信息通知网络管理人员，从而检测是否存在跳转等攻击行为。</li><li>僵尸网络检测<br>基于实时的信誉机制，结合企业级和全球信誉库，可有效检测恶意URL、僵尸网络，保护用户在访问被植入木马等恶意代码的网站地址时不受侵害，有效检测Web 威胁，并能及时发现网络中可能出现的僵尸网络主机和C&amp;C 连接。</li></ul><h3 id="Web应用防火墙"><a href="#Web应用防火墙" class="headerlink" title="Web应用防火墙"></a>Web应用防火墙</h3><p>基于对Web 流量的解码和分析，可应对Web 应用中的各类攻击，如SQL 注入、XSS注入、跨站请求伪造攻击、Cookie 篡改以及应用层Web 攻击等，能有效解决网页挂马、敏感信息泄露等安全问题，充分保障Web应用安全。通过精细的配置将多种Web安全检测方法连结成一套完整的安全体系，能够在IPv4、IPv6 及二者混合环境中抵御OWASP Top 10等各类Web安全威胁，通过服务化方式快速交付，保卫Web 应用免遭当前和未来的安全威胁。</p><ul><li>Web 应用攻击防护<br>内置多种防护策略，可选择进行 SQL 注入、XSS 攻击、命令注入、非法HTTP 协议请求、常见Web 服务器漏洞攻击、扫描防护等。</li><li>Web 漏洞<br>Web 服务器漏洞探测，Web 服务器漏洞扫描（模拟攻击，判断缺陷，自动配置对应规则），及时发现漏洞隐患。</li><li>注入攻击防护<br>SQL 注入防御、LDAP 注入防御、命令注入防护（OS 命令，webshell 等）、XPath 注入防御、Xml/Json 注入防御。</li><li>IP 访问控制<br>支持对指定IP 的加白和恶意IP 的封禁。</li><li>URL 访问控制<br>支持对URL 进行黑白名单控制。</li><li>爬虫防护<br>基于源IP 周期判断访问数，防护恶意访问。</li></ul><h3 id="下一代防火墙"><a href="#下一代防火墙" class="headerlink" title="下一代防火墙"></a>下一代防火墙</h3><p>下一代防火墙采用高度一体化的架构设计方案，将所有的安全特性纳入到一体化的安全引擎。将传统五元组访问控制与具有下一代防火墙特征能力有机地结合起来，提供一个全新的网络边界防护解决方案。</p><ul><li>应用、用户识别能力<br>可识别大部分应用，并可辅助用户对这些应用进行高效管理和筛查，包括5 维度分类组织，基于特性查询应用、自定义特殊应用等。</li><li>监控统计<br>对设备数据进行统计，并以柱状图、折线图、表格、报表、日志等方式呈现出来，帮助用户通过统计数据掌握设备状况，排查问题。</li><li>用户认证<br>对用户进行识别，通过认证的用户可以访问对应的管理资源。</li><li>访问控制<br>划分安全区域和非安全区域，区域之间的访问基于安全策略进行控制。</li><li>入侵防御<br>实时监控多种网络攻击并根据配置对网络攻击进行阻断等操作。</li><li>病毒过滤<br>探测各种病毒威胁，例如恶意软件、恶意网站等，并且根据配置对发现的病毒进行处理。</li><li>DNS 重定向<br>支持对某一域名重定向到另一域名的功能。</li><li>页面访问控制<br>针对不同用户的权限对页面的访问进行区别。</li><li>带宽管理<br>能够管理和优化网络带宽，提高用户的网络体验和带宽资源利用率。</li><li>云沙箱<br>基于云端架构的恶意软件虚拟运行环境，发现未知威胁，多重静态检测引擎快速过滤正常文件及已知威胁，提升沙箱检测效率。</li><li>僵尸网络 C&amp;C 防护<br>监控 C&amp;C 连接发现内网肉鸡，阻断僵尸网络/勒索软件等高级威胁进一步破坏。</li><li>IP 信誉库<br>识别过滤各种已知风险 IP，根据配置对风险IP 进行记录或阻断处理。</li><li>封账号<br>支持对网络账户封停的功能。</li><li>包过滤<br>支持对网络中的数据包的区分和限制功能。</li><li>授权管理<br>集中管理功能授权并可进行不同种类授权的统一下发。</li><li>传统防火墙功能特性<br>兼容传统防火墙功能特性，包括访问控制、日志报表、会话管理等。</li></ul><h3 id="入侵防护系统"><a href="#入侵防护系统" class="headerlink" title="入侵防护系统"></a>入侵防护系统</h3><p>入侵防护系统是一个监视网络或网络设备的网络资料传输行为的系统，能够深入网络数据内部，即时中断、调整或隔离一些有害数据流。入侵防护系统可主动拦截黑客攻击、据虫、网络病毒、后门木马、DoS 等恶意流量，保护企业信息系统和网络架构免受侵害，防止操作<br>系统和应用程序损坏或宕机。</p><ul><li>敏感数据保护<br>提供敏感数据识别、数据安全审计、数据脱敏、智能异常检测等数据安全能力，形成一体化的数据安全解决方案。</li><li>高级威胁防御<br>高级威胁防御能够基于敏感数的外泄、文件识别、服务器非法外联等异常行为检测，实现内网的高级威胁防御功能。</li><li>恶意文件防御<br>网络中存在大量恶意文件，通过网站文件服务器、邮件服务器实现传播，对企业网络安全构成潜在威胁。对网络中传送的文件，进行快速检测，比对文件信誉，对发现恶意的文件进行告警和阻断。</li><li>网址/网站检测分析<br>支持对网站的URL 进行检测，并分析其是否是恶意网能力。</li></ul><h3 id="防病毒"><a href="#防病毒" class="headerlink" title="防病毒"></a>防病毒</h3><p>防病毒可以对计算机病毒、木马和恶意软件等一切已知的对计算机有危害的程序代码进行清除，提供终端查杀病毒、软件管理、漏洞补丁、统一升级管理等功能。</p><ul><li><p>安全防御<br>能够精准识别、分析及响应病毒传播、0day 攻击及APT 攻击等异常行为。</p></li><li><p>主机防火墙<br>支持对IP、端口协议及访问方向等维度过滤，能智能识别网络协议，同时可通过IP 黑<br>白名单，控制终端只能访问指定目标地址，或指定来源IP 地址访问。</p></li><li><p>漏洞加固<br>实时扫描记录终端的操作系统及常用应用软件漏洞，掌握全网终端漏洞情况及补丁修复。</p></li><li><p>勒索病毒防御<br>基于HIPS 的勒索者主动防御机制，蠕虫病毒、勒索病毒、宏病毒等已知未知威胁防范无忧。</p></li><li><p>安全审计<br>对攻击、病毒及漏洞等终端运行信息，以及上网行为、U 盘使用及文件操作等终端行为信息进行统一收集。</p></li><li><p>软件管理<br>记录全网安装软件清单以及每种软件安装的终端明细，以及软件使用时长。</p></li><li><p>流量管控<br>对终端流量管理包括总流量、上行及下行等管理，同时支持升级下载及日志上传等细粒度的流量管理。</p></li></ul><h3 id="终端检测与响应"><a href="#终端检测与响应" class="headerlink" title="终端检测与响应"></a>终端检测与响应</h3><p>利用终端检测响应，对终端的运行状态进行检测和监控，对进程、文件和配置等进行分析，对异常行为进行处理，确保主机安全，从而实现东西向防护。</p><ul><li>病毒及恶意程序防护<br>基于文件动作行为特征模型分析查杀，主动防御型查杀，文件黑白名单管理，文件多算法(MD5、SHA1、SHA256)校验。</li><li>攻击与威胁防护<br>检测模式，拦截模式，支持端口扫描、泛洪攻击、TCP 洪水攻击、漏洞攻击、注册表安全检测等。</li><li>主机网络访问隔离<br>基于主机维度，定义出入站网络访问，能自定义网络访问对象和端口对象，并记录违规访问日志，可追溯网络访问发起的进程及进程详细路径和进程文件安全性。</li><li>终端环境强控<br>通过设定终端运行的白环境，达到除白名单外的文件无法运行。</li><li>安全基线检查<br>同时含盖 Windows 和Linux 平台，支持帐号与口令检查、密码生存周期检查、远程登录检查、网络与服务检查、日志审计检查、防火墙检查、系统安全配置检查等内容，核查项完全满足工信部等单位要求。</li><li>沙箱防护<br>云端沙箱检查结果查询，用户本地上传文件至沙箱。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;随着网络技术发展，网络威胁无孔不入，网络攻击手段呈现复杂性及多变性的趋势。要建立防御体系应从通信网络、网络边界、局域网络内部、各种业务应用平台等各个层次落实各种安全措施，形成纵深防御体系。单靠一种或几种安全设备就想保护整个网络是不可能的事情。因此，为了满足不同防护需求的安全
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
    
      <category term="网络安全" scheme="https://xiejava.gitee.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>pandas快速入门指南</title>
    <link href="https://xiejava.gitee.io/posts/17215b2c/"/>
    <id>https://xiejava.gitee.io/posts/17215b2c/</id>
    <published>2022-02-23T02:29:43.000Z</published>
    <updated>2022-02-23T02:32:20.858Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/69c7c56ec4614617a28ae2fc480cbf88.png#pic_center" alt="pandas"></p><p>Pandas 是一个开源的第三方 Python 库，从 Numpy 和 Matplotlib 的基础上构建而来，享有数据分析“三剑客之一”的盛名（NumPy、Matplotlib、Pandas）。是学习数据分析、AI机器学习必学组件之一。<br>Pandas 这个名字来源于面板数据（Panel Data）与数据分析（data analysis）这两个名词的组合。在经济学中，Panel Data 是一个关于多维数据集的术语。Pandas 对数据的处理是为数据的分析服务的，它所提供的各种数据处理方法、工具是基于数理统计学出发，包含了日常应用中的众多数据分析方法。</p><p>Pandas 可以实现复杂的处理逻辑，这些往往是 Excel 等工具无法处理的，还可以自动化、批量化，对于相同的大量的数据处理我们不需要重复去工作。Pandas 的出现使得 Python 做数据分析的能力得到了大幅度提升，它主要实现了数据分析的五个重要环节：</p><ul><li>加载数据 </li><li>整理数据 </li><li>操作数据 </li><li>构建数据模型 </li><li>分析数据</li></ul><p>主要特点</p><ul><li>它提供了一个简单、高效、带有默认标签（也可以自定义标签）的 DataFrame 对象。 </li><li>能够快速得从不同格式的文件中加载数据（比如<br>Excel、CSV 、SQL文件），然后将其转换为可处理的对象； </li><li>能够按数据的行、列标签进行分组，并对分组后的对象执行聚合和转换操作；</li><li>能够很方便地实现数据归一化操作和缺失值处理； </li><li>能够很方便地对 DataFrame 的数据列进行增加、修改或者删除的操作；</li><li>能够处理不同格式的数据集，比如矩阵数据、异构数据表、时间序列等；</li><li>提供了多种处理数据集的方式，比如构建子集、切片、过滤、分组以及重新排序等。</li></ul><p>本教程梳理了快速入门pandas的一些知识点。</p><p><img src="https://img-blog.csdnimg.cn/3c9638a1d2c14b479bb46e0e33b32614.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="pandas快速入门"></p><p><a href="http://xiejava.ishareread.com/posts/531458d5/" target="_blank" rel="noopener">一、pandas数据结构(Series和DataFrame)</a></p><p><a href="http://xiejava.ishareread.com/posts/4864590d/" target="_blank" rel="noopener">二、pandas数据加载(csv、excel、json、mysql、webAPI)</a></p><p><a href="http://xiejava.ishareread.com/posts/808d8fe8/" target="_blank" rel="noopener">三、pandas基本操作之数据访问(查看与检索)</a></p><p><a href="http://xiejava.ishareread.com/posts/16c9fc17/" target="_blank" rel="noopener">四、pandas数据分析之排序和排名(sort和rank)</a></p><p><a href="http://xiejava.ishareread.com/posts/a87a78e2/" target="_blank" rel="noopener">五、pandas数据清洗之处理缺失、重复、异常数据</a></p><p><a href="http://xiejava.ishareread.com/posts/2c80aac2/" target="_blank" rel="noopener">六、pandas数据处理之数据转换(映射map、替换replace、重命名rename)</a></p><p><a href="http://xiejava.ishareread.com/posts/f44191db/" target="_blank" rel="noopener">七、pandas数据分析之数据运算(逻辑运算、算术运算、统计运算、自定义运算)</a></p><p><a href="http://xiejava.ishareread.com/posts/e7d4d6e1/" target="_blank" rel="noopener">八、pandas数据处理之合并与拼接</a></p><p><a href="http://xiejava.ishareread.com/posts/dd24116d/" target="_blank" rel="noopener">九、pandas数据分析之分组聚合</a></p><p><a href="http://xiejava.ishareread.com/posts/bc5826bd/" target="_blank" rel="noopener">十、pandas数据分析之数据重塑透视(stack、unstack、melt、pivot)</a></p><p><a href="http://xiejava.ishareread.com/posts/e8cac912/" target="_blank" rel="noopener">十一、pandas数据分析之数据绘图</a></p><p>学习pandas最好的资料肯定是pandas的官网  <a href="https://pandas.pydata.org/docs/user_guide/index.html" target="_blank" rel="noopener">https://pandas.pydata.org/docs/user_guide/index.html</a></p><p>书籍推荐pandas的作者写的《利用python进行数据分析》</p><hr><p>本教程作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/69c7c56ec4614617a28ae2fc480cbf88.png#pic_center&quot; alt=&quot;pandas&quot;&gt;&lt;/p&gt;
&lt;p&gt;Pandas 是一个开源的第三方 Python 库，从 N
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据分析之数据绘图</title>
    <link href="https://xiejava.gitee.io/posts/e8cac912/"/>
    <id>https://xiejava.gitee.io/posts/e8cac912/</id>
    <published>2022-02-16T03:32:09.000Z</published>
    <updated>2022-02-16T03:33:30.408Z</updated>
    
    <content type="html"><![CDATA[<p>一图胜千言，将信息可视化（绘图）是数据分析中最重要的工作之一。它除了让人们对数据更加直观以外，还可以帮助我们找出异常值、必要的数据转换、得出有关模型的想法等等。pandas 在数据分析、数据可视化方面有着较为广泛的应用。本文将通过实例介绍pandas的数据绘图。<br><img src="https://img-blog.csdnimg.cn/71f0a92c1e9b4d72985c5d7705076be8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="pandas数据绘图"></p><p>pandas的数据可视化依赖于matplotlib模块的pyplot类，matplotlib在安装Pandas会自动安装。Matplotlib可以对图形做细节控制，绘制出出版质量级别的图形，通过Matplotlib，可以简单地绘制出常用的统计图形。pandas 对 Matplotlib 绘图软件包的基础上单独封装了一个plot()接口，通过调用该接口可以实现常用的绘图操作。<br>让我们先来认识mataplotlib图形的基本构成。</p><h1 id="一、matplotlib图形基本构成"><a href="#一、matplotlib图形基本构成" class="headerlink" title="一、matplotlib图形基本构成"></a>一、matplotlib图形基本构成</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data=np.arange(<span class="number">10</span>)</span><br><span class="line">plt.plot(data)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8fb478e612224148b3f7346cd78895ac.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="matplotlib.plot()"></p><p>通过引入matplotlib模块的pyplot类，将数据传入plot()的接口，就可以将数据以图形化的方式展示出来。Matplotlib 生成的图形主要由以下几个部分构成：<br><img src="https://img-blog.csdnimg.cn/7f23fcaedb244bada98003004d7e975f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_9,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="绘图基本结构"></p><ul><li>Figure：指整个图形，您可以把它理解成一张画布，它包括了所有的元素，比如标题、轴线等； </li><li>Axes：绘制 2D图像的实际区域，也称为轴域区，或者绘图区； </li><li>Axis：指坐标系中的垂直轴与水平轴，包含轴的长度大小（图中轴长为 7）、轴标签（指 x轴，y轴）和刻度标签； </li><li>Artist：在画布上看到的所有元素都属于 Artist对象，比如文本对象（title、xlabel、ylabel）、Line2D 对象（用于绘制2D图像）等。</li></ul><p>了解matplotlib图形的基本构成非常重要，绘图就是通过matplotlib提供的方法来定义和设置这些基本图形的构成元素来将数据显示在这些元素中。</p><h1 id="二、matplotlib显示中文"><a href="#二、matplotlib显示中文" class="headerlink" title="二、matplotlib显示中文"></a>二、matplotlib显示中文</h1><p>Matplotlib 默认不支持中文字体，这因为 Matplotlib 只支持 ASCII 字符，但中文标注更加符合中国人的阅读习惯。下面介绍如何在 Windows 环境下让 Matplotlib 显示中文。</p><h2 id="1、方法一：临时重写配置文件（临时）"><a href="#1、方法一：临时重写配置文件（临时）" class="headerlink" title="1、方法一：临时重写配置文件（临时）"></a>1、方法一：临时重写配置文件（临时）</h2><p>通过临时重写配置文件的方法，可以解决 Matplotlib 显示中文乱码的问题，代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">"font.sans-serif"</span>]=[<span class="string">"SimHei"</span>] <span class="comment">#设置字体</span></span><br><span class="line">plt.rcParams[<span class="string">"axes.unicode_minus"</span>]=<span class="literal">False</span> <span class="comment">#该语句解决图像中的“-”负号的乱码问题</span></span><br></pre></td></tr></table></figure><h2 id="2、方法二：修改配置文件-（永久）"><a href="#2、方法二：修改配置文件-（永久）" class="headerlink" title="2、方法二：修改配置文件 （永久）"></a>2、方法二：修改配置文件 （永久）</h2><p>通过直接修改配置文件的方法，可以一劳永逸的解决 Matplotlib 的中文乱码问题。注意此过程在 Windows 环境下进行。<br>Matplotlib 从配置文件 matplotlibrc 中读取相关配置信息，比如字体、样式等，因此我们需要对该配置文件进行更改。使用如下代码查看 matplotlibrc 所在的目录：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.matplotlib_fname()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/784e00d0e5664e00a67f54309f8fa9b7.png#pic_center" alt="matplotlib_fname"></p><p>打开配置文件后，找到以下信息：<br>#font.family: sans-serif<br>#font.serif: DejaVu Serif, Bitstream Vera Serif, Computer Modern Roman, New Century Schoolbook, Century Schoolbook L, Utopia, ITC Bookman, Bookman, Nimbus Roman No9 L, Times New Roman, Times, Palatino, Charter, serif<br>修改配置将#注释去掉，并将微软雅黑Microsoft  YaHei的字体给加上。<br><img src="https://img-blog.csdnimg.cn/ceaa6040ac1f44ecaf70121f7e691f79.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="微软雅黑"><br>最后，在windows的字体目录中复制中文字体微软雅黑：<br>C:\Windows\Fonts\Microsoft YaHei UI<br>将微软雅黑的字体复制粘贴到matplotlib的字体库中，字体库路径就在matplotlibrc 所在的目录下<br>D:\Anaconda3\Lib\site-packages\matplotlib\mpl-data\fonts\ttf<br><img src="https://img-blog.csdnimg.cn/1a25065992144bff99f693d16b143a5c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="复制字体"><br>如果是jupyter notbook重启启动jupyter notbook让它重新读取配置文件即可。</p><h1 id="三、pandas绘图"><a href="#三、pandas绘图" class="headerlink" title="三、pandas绘图"></a>三、pandas绘图</h1><p>数据分析将数据进行可视化绘图展示离不开数据，pandas的两大数据结构Series和DataFrame都提供了相应的方法很方便的进行数据的可视化绘图展示。</p><h2 id="1、数据"><a href="#1、数据" class="headerlink" title="1、数据"></a>1、数据</h2><p>pandas 提供了 plot() 方法可以快速方便地将 Series 和 DataFrame 中的数据进行可视化。</p><h3 id="a-Series"><a href="#a-Series" class="headerlink" title="a) Series"></a>a) Series</h3><p>Series 使用 plot 时 x 轴为索引，y 轴为索引对应的具体值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">series_data=pd.Series(np.random.randn(<span class="number">10</span>),index=range(<span class="number">10</span>))</span><br><span class="line">series_data</span><br><span class="line">series_data.plot()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c72c01ada00d4db6b5b60154d59e06b3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="Series绘图"></p><h3 id="b-DataFrame"><a href="#b-DataFrame" class="headerlink" title="b) DataFrame"></a>b) DataFrame</h3><p>DataFrame 使用 plot 时 x 轴为索引，y 轴为索引对应的多个具体值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_staff = pd.read_excel(<span class="string">'D:\\Python\\study\\pythontest\\pandastest\\数据集\\staff_sale_byQ.xlsx'</span>)</span><br><span class="line">df_staff</span><br><span class="line">df_staff.plot()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/14733be19b964a818d897f061fa7dcbf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="DataFrame绘图"><br>plot()可以通过传入x和y指定显示具体的列数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定X轴及y显示的列数据</span></span><br><span class="line">df_staff.plot(x=<span class="string">'季度'</span>,y=[<span class="string">'张三'</span>,<span class="string">'李四'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/5e25b52456c94e54a321eb6fcfe52d02.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="dataframe指定x和y"></p><h2 id="2、图形"><a href="#2、图形" class="headerlink" title="2、图形"></a>2、图形</h2><p>plot 默认为折线图，折线图也是最常用和最基础的可视化图形，足以满足我们日常 80% 的需求。<br>除了使用默认的线条绘图外，还可以使用其他绘图方式，如下所示：</p><ul><li>柱状图：bar() 或 barh() </li><li>箱形图：box() </li><li>区域图：area() </li><li>饼状图：pie() </li><li>散点图：scatter()</li><li>直方图：hist()</li></ul><h3 id="a-柱状图"><a href="#a-柱状图" class="headerlink" title="a) 柱状图"></a>a) 柱状图</h3><p>柱状图（bar chart），使用与轴垂直的柱子，通过柱形的高低来表达数据的多少，适用于数据的对比，在整体中也能看到数据的发展变化趋势。<br>DataFrame 可以直接调用 plot.bar() 生成折线图，与折线图类似，x 轴为索引，其他数字类型的列为 y 轴上的条形，可以设置参数stacked=True生成柱状堆叠图<br>df.plot.bar()<br>df.plot.barh() # 横向<br>df[:5].plot.bar(x=’name’, y=’Q4’) # 指定xy轴<br>df[:5].plot.bar(‘name’, [‘Q1’, ‘Q2’]) # 指定xy轴</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#柱状图</span></span><br><span class="line">df_staff.plot.bar(x=<span class="string">'季度'</span>,y=[<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>]) </span><br><span class="line"><span class="comment">#柱状图可以设置参数stacked=True生成柱状堆叠图</span></span><br><span class="line">df_staff.plot.bar(x=<span class="string">'季度'</span>,y=[<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>],stacked=<span class="literal">True</span>) </span><br><span class="line"><span class="comment">#通过barh()方法可以绘制水平柱状图</span></span><br><span class="line">df_staff.plot.barh(x=<span class="string">'季度'</span>,y=[<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>],stacked=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b6aa2053a83e4488a41590fca651e31b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="柱状图"></p><h3 id="b-箱形图"><a href="#b-箱形图" class="headerlink" title="b) 箱形图"></a>b) 箱形图</h3><p>箱形图（Box Chart）又称盒须图、盒式图或箱线图，是一种用作显示一组数据分布情况的统计图。Series.plot.box() 、 DataFrame.plot.box(), 和 DataFrame.boxplot() 都可以绘制箱形图。<br>从箱形图中我们可以观察到：</p><ul><li>一组数据的关键值：中位数、最大值、最小值等。</li><li>数据集中是否存在异常值，以及异常值的具体数值。 </li><li>数据是否是对称的。</li><li>这组数据的分布是否密集、集中。 </li><li>数据是否扭曲，即是否有偏向性。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_staff.plot.box(x=<span class="string">'季度'</span>,y=[<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/872f3c82acf141adb2b37d6b8474acb2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="箱形图"></p><h3 id="c-区域图"><a href="#c-区域图" class="headerlink" title="c) 区域图"></a>c) 区域图</h3><p>区域图（Area Chart），又叫面积图。 将折线图中折线与自变量坐标轴之间的区域使用颜色或者纹理填充，这样一个填充区域叫做面积，颜色的填充可以更好的突出趋势信息，需要注意的是颜色要带有一定的透明度，透明度可以很好的帮助使用者观察不同序列之间的重叠关系，没有透明度的面积会导致不同序列之间相互遮盖减少可以被观察到的信息。<br>面积图默认情况下是堆叠的。 要生成堆积面积图，每列必须全部为正值或全部为负值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_staff.plot.area(x=<span class="string">'季度'</span>,y=[<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/314e2710b0554883b9edd185a8578b19.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="区域图"></p><h3 id="d-饼状图"><a href="#d-饼状图" class="headerlink" title="d) 饼状图"></a>d) 饼状图</h3><p>饼图（Pie Chart）广泛得应用在各个领域，用于表示不同分类的占比情况，通过弧度大小来对比各种分类。饼图通过将一个圆饼按照分类的占比划分成多个区块，整个圆饼代表数据的总量，每个区块（圆弧）表示该分类占总体的比例大小，所有区块（圆弧）的加和等于 100%。<br>可以使用 DataFrame.plot.pie() 或 Series.plot.pie() 创建饼图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df_staff</span><br><span class="line"><span class="comment">#看张三每个季度的业绩分布</span></span><br><span class="line">df_staff.plot.pie(y=<span class="string">'张三'</span>,subplots=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#看第一个季度，每个人的绩效分布</span></span><br><span class="line">df_staff1=df_staff.loc[<span class="number">0</span>:<span class="number">0</span>,<span class="string">'张三'</span>:<span class="string">'孙八'</span>].T</span><br><span class="line">df_staff1.columns=[<span class="string">'Q'</span>]</span><br><span class="line">df_staff1.plot.pie(y=<span class="string">'Q'</span>,subplots=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/30d2a79821494d60b71788d59a973731.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="饼图"></p><h3 id="e-散点图"><a href="#e-散点图" class="headerlink" title="e) 散点图"></a>e) 散点图</h3><p>散点图（Scatter graph）也叫 X-Y 图，它将所有的数据以点的形式展现在直角坐标系上，以显示变量之间的相互影响程度，点的位置由变量的数值决定。<br>通过观察散点图上数据点的分布情况，我们可以推断出变量间的相关性。如果变量之间不存在相互关系，那么在散点图上就会表现为随机分布的离散的点，如果存在某种相关性，那么大部分的数据点就会相对密集并以某种趋势呈现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df1 = pd.DataFrame(np.random.rand(<span class="number">50</span>, <span class="number">4</span>), columns=[<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>])</span><br><span class="line">df1.plot.scatter(x=<span class="string">"a"</span>, y=<span class="string">"b"</span>);</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/808e596351ac4d498e7ff764a61d58bd.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在散点图"></p><h3 id="f-直方图"><a href="#f-直方图" class="headerlink" title="f) 直方图"></a>f) 直方图</h3><p>直方图(Histogram)，又称质量分布图，是一种统计报告图，它是根据具体数据的分布情况，画成以组距为底边、以频数为高度的一系列连接起来的直方型矩形图。<br><img src="https://img-blog.csdnimg.cn/e196cd720e62469288f48ac3e5d3170c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="直方图说明"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构建数据集</span></span><br><span class="line">df4=pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">"a"</span>: np.random.randn(<span class="number">1000</span>) + <span class="number">1</span>,</span><br><span class="line">    <span class="string">"b"</span>: np.random.randn(<span class="number">1000</span>),</span><br><span class="line">    <span class="string">"c"</span>: np.random.randn(<span class="number">1000</span>) - <span class="number">1</span>,</span><br><span class="line">    <span class="string">"d"</span>: np.random.randn(<span class="number">1000</span>) - <span class="number">2</span>,</span><br><span class="line">    &#125;,columns=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>])</span><br><span class="line">df4</span><br><span class="line">df4.plot.hist(alpha=<span class="number">0.5</span>)  <span class="comment">#指定图形透明度</span></span><br><span class="line">df4.plot.hist(stacked=<span class="literal">True</span>,bins=<span class="number">20</span>) <span class="comment">#堆叠并指定箱数为20</span></span><br><span class="line">df4.diff().hist() <span class="comment">#通过diff给每一列数据都绘制一个直方图</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/f12ed9d079a641c7953c15a54534d494.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="直方图"></p><p>至此，本文介绍了pandas常用的绘图组件matplotlib，包括mataplotlib绘图的基本构成，如何在windows下解决中文问题，并通过实例介绍了如何通过pandas的数据集绘制折线图、箱线图、柱状图、饼图、面积图、散点图、直方图等。</p><p>参考资料：《利用python进行数据分析》、pandas官网 user guide</p><p>数据集及源代码见：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一图胜千言，将信息可视化（绘图）是数据分析中最重要的工作之一。它除了让人们对数据更加直观以外，还可以帮助我们找出异常值、必要的数据转换、得出有关模型的想法等等。pandas 在数据分析、数据可视化方面有着较为广泛的应用。本文将通过实例介绍pandas的数据绘图。&lt;br&gt;&lt;i
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据分析之数据重塑透视(stack、unstack、melt、pivot)</title>
    <link href="https://xiejava.gitee.io/posts/bc5826bd/"/>
    <id>https://xiejava.gitee.io/posts/bc5826bd/</id>
    <published>2022-02-13T16:30:52.000Z</published>
    <updated>2022-02-13T16:31:50.556Z</updated>
    
    <content type="html"><![CDATA[<p>在数据分析的过程中，分析师常常希望通过多个维度多种方式来观察分析数据，重塑和透视是常用的手段。<br>数据的重塑简单说就是对原数据进行变形，为什么需要变形，因为当前数据的展示形式不是我们期望的维度，也可以说索引不符合我们的需求。对数据的重塑不是仅改变形状那么简单，在变形过程中，数据的内在数据意义不能变化，但数据的提示逻辑则发生了重大的改变。<br>数据透视是最常用的数据汇总工具，Excel 中经常会做数据透视，它可以根据一个或者多个指定的维度来聚合数据。pandas 也提供了数据透视函数来实现这些功能。<br>如果能熟练区分和使用各种重塑和透视分析方法，那用pandas处理分析日常的数据基本上就没有什么难度了。<br><img src="https://img-blog.csdnimg.cn/924f8a4672984116a4b502d6f05d549b.png#pic_center" alt="重塑和透视"></p><p>在介绍数据重塑透视之前，先来介绍一下pandas中DataFrame的层次化索引，它广泛应用于重塑透视操作。</p><h1 id="一、层次化索引"><a href="#一、层次化索引" class="headerlink" title="一、层次化索引"></a>一、层次化索引</h1><p>层次化索引是pandas的一项重要功能，它使你能在一个轴上拥有多个（两个以上）索引层数，分层索引的目的是用低维度的结构（Series 或者 DataFrame）更好地处理高维数据。通过分层索引，我们可以像处理二维数据一样，处理三维及以上的数据。分层索引的存在使得分析高维数据变得简单。<br>我们来看一下student数据集，并根据该数据集分别构建列和行的层次索引。然后再介绍数据的重塑和透视。<br>引入student数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">'D:\\Python\\study\\pythontest\\pandastest\\数据集\\student.xlsx'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/810d28e429e9431fa7f223eba7b53b01.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="student数据集"></p><p>该student数据集包含学生学号、姓名、语文、数据、英语的成绩等。</p><h2 id="1、列索引分层"><a href="#1、列索引分层" class="headerlink" title="1、列索引分层"></a>1、列索引分层</h2><p>我们选取一些关键的数据构建列标签的层次化索引。这里我们选取’班级’,’姓名’,’语文’,’数学’,’英语’的列，并且将‘班级’、‘姓名’标记为‘标识’，’语文’,’数学’,’英语’标记为‘成绩’</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_student=df[[<span class="string">'班级'</span>,<span class="string">'2-姓名'</span>,<span class="string">'4-语文'</span>,<span class="string">'5-数学'</span>,<span class="string">'6-英语'</span>]]</span><br><span class="line">df_student.columns=[[<span class="string">'标识'</span>,<span class="string">'标识'</span>,<span class="string">'成绩'</span>,<span class="string">'成绩'</span>,<span class="string">'成绩'</span>],[<span class="string">'班级'</span>,<span class="string">'姓名'</span>,<span class="string">'语文'</span>,<span class="string">'数学'</span>,<span class="string">'英语'</span>]]</span><br><span class="line">df_student</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/cecd15ff3dca49369fd0e266efb676cb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="列索引分层"><br>通过指定DataFrame的columns的层级将’班级’,’姓名’,’语文’,’数学’,’英语’，上多抽出了一个层级，这个层有两个索引一个是‘标识’，一个是成绩，其中‘班级’和‘名称’是属于标识，’语文’,’数学’,’英语’都是’成绩’。</p><h2 id="2、行索引分层"><a href="#2、行索引分层" class="headerlink" title="2、行索引分层"></a>2、行索引分层</h2><p>  接下来看行索引的分层。我们将属于一班的和属于二班的同学进行分层，再分成两个索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#根据行索引分层，设置行索引将其分成班级和姓名两个层次索引</span></span><br><span class="line">df_student=df_student.set_index([(<span class="string">'标识'</span>,<span class="string">'班级'</span>),(<span class="string">'标识'</span>,<span class="string">'姓名'</span>)])</span><br><span class="line">df_student.index.names=[<span class="string">'班级'</span>,<span class="string">'姓名'</span>]</span><br><span class="line">df_student</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c06f260cd18c45999475887d39c6bd97.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="行索引的分层"></p><p>可以看到将数据集的班级和姓名列分成了两个行的层级索引。没有用默认的0-9的行索引</p><h1 id="二、数据堆叠与拆堆"><a href="#二、数据堆叠与拆堆" class="headerlink" title="二、数据堆叠与拆堆"></a>二、数据堆叠与拆堆</h1><p>层次化索引为DataFrame数据的重排任务提供了一种具有良好一致性的方式，有许多用于重新排列表格数据的基础运算。这些函数也称作重塑（reshape）或轴向旋转（pivot）运算。<br>常见的数据重塑包括数据的堆叠 stack 和 取消堆叠 unstck</p><h2 id="1、数据堆叠-stack"><a href="#1、数据堆叠-stack" class="headerlink" title="1、数据堆叠 stack"></a>1、数据堆叠 stack</h2><p>堆叠 stack ，顾名思义，就是将列的数据堆叠形成行。<br>借用pandas官网的示意图：<br><img src="https://img-blog.csdnimg.cn/45611145863746e6a3c5c2d7c13b31d0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="堆叠 stack"></p><p>看实际数据数据会更容易理解，为了方便我们取student数据集的前5行记录来进行数据堆叠stack()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df_student[:<span class="number">5</span>]</span><br><span class="line"><span class="comment">#将数据进行堆叠</span></span><br><span class="line"><span class="comment">#将数据进行堆叠</span></span><br><span class="line">df_student5=df_student[:<span class="number">5</span>].stack()</span><br><span class="line">df_student5</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/bf421506617446528c423c4db58f96cf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="堆叠 stack(）"><br>在这里可以看到通过stack()将“语文”、“数学”、”英语”，三列，一个个堆叠形成一条记录的三行。这样列数减少了，行数增多了。<br><img src="https://img-blog.csdnimg.cn/4d2c9436ca6440c783f10425c38a150f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="stack()"></p><p>对于多层索引，可以根据指定堆叠层次，默认是最高层次的堆叠。<br>我们来看指定堆叠层次，如果<code>stack(0)</code>，表示堆叠level0层的。<br><img src="https://img-blog.csdnimg.cn/460a7536308e4cb8b76e548098aa291d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="分层堆叠"></p><h2 id="2、取消堆叠-unstack"><a href="#2、取消堆叠-unstack" class="headerlink" title="2、取消堆叠 unstack"></a>2、取消堆叠 unstack</h2><p>取消堆叠 unstack是堆叠的反操作。<br><img src="https://img-blog.csdnimg.cn/415206f012124a8aa75ecf0e39bd8bae.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="Unstack"></p><p>也就是将堆叠好了的行数据，一个个卸下来形成列。这样一来行数减少了，但是列数增多了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取消堆叠 unstack()</span></span><br><span class="line">df_student5.unstack()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/41728158c7d140109b330787c12bf6da.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="unstack"></p><p>可以看到原来的“语文”、“数学”、”英语”三行，通过unstack()进行拆堆，拆成了三列，明显数据没有那么高了，行数少了，列数多了。<br><img src="https://img-blog.csdnimg.cn/9322cae9843e45038a0989e4b736bd2d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="unstack"></p><p>同样对于多层索引可以逐层拆堆<br><img src="https://img-blog.csdnimg.cn/7533debe490b483983e1ddc89ac423a8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="逐层拆堆"></p><h1 id="三、数据融合与透视"><a href="#三、数据融合与透视" class="headerlink" title="三、数据融合与透视"></a>三、数据融合与透视</h1><p>数据透视是最常用的数据汇总工具，它可以根据一个或者多个指定的维度来聚合数据。实际上搞懂了stack和unstack就很容易搞懂pivot和melt了，stack和unstack根据索引来进行堆叠和拆堆，pivot和melt可以根据指定的数据来进行变换操作灵活性更高。</p><h2 id="1、数据融合-melt"><a href="#1、数据融合-melt" class="headerlink" title="1、数据融合 melt"></a>1、数据融合 melt</h2><p>来看pandas官网的示意图，是不是和stack的图有点类似，都是将列转换成行，不同的是melt可以指定哪些列固定，哪些列转换成行等灵活性更高。简单说就是将指定的列放到铺开放到行上名为variable(可指定)列，值在value(可指定)列<br><img src="https://img-blog.csdnimg.cn/a613abd84db744199b1276334d6fe776.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="melt"><br>melt语法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pd.melt(frame: pandas.core.frame.DataFrame,</span><br><span class="line">        id_vars=<span class="literal">None</span>, value_vars=<span class="literal">None</span>,</span><br><span class="line">        var_name=<span class="string">'variable'</span>, value_name=<span class="string">'value'</span>,</span><br><span class="line">        col_level=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li>id_varstuple，list或ndarray（可选），用作标识变量的列。</li><li>value_varstuple，列表或ndarray，可选，要取消透视的列。 如果未指定，则使用未设置为id_vars的所有列。</li><li>var_namescalar，用于“变量”列的名称。 如果为None，则使用frame.columns.name或“variable”。</li><li>value_namescalar，默认为“ value”，用于“ value”列的名称。<ul><li>col_levelint或str，可选，如果列是MultiIndex，则使用此级别来融化。</li></ul></li></ul><p>我们还是来看示例：<br>数据集还是student数据集，为了演示方便取前5条记录</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_student=df[[<span class="string">'班级'</span>,<span class="string">'2-姓名'</span>,<span class="string">'4-语文'</span>,<span class="string">'5-数学'</span>,<span class="string">'6-英语'</span>]]</span><br><span class="line">df_student.columns=[[<span class="string">'标识'</span>,<span class="string">'标识'</span>,<span class="string">'成绩'</span>,<span class="string">'成绩'</span>,<span class="string">'成绩'</span>],[<span class="string">'班级'</span>,<span class="string">'姓名'</span>,<span class="string">'语文'</span>,<span class="string">'数学'</span>,<span class="string">'英语'</span>]]</span><br><span class="line">df_student[<span class="number">0</span>:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/af39dc398bf4485bb1943c9cb06bd2c4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="melt"></p><p>现在将“班级”和“姓名”固定，’语文’,’数学’,’英语’三列转换成行融合为“学科”字段，这三个列的值定义为“分数”列。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将“班级”和“姓名”固定，'语文','数学','英语'三列转换成行融合为“学科”字段，这三个列的值定义为“分数”列</span></span><br><span class="line">df_student[<span class="number">0</span>:<span class="number">5</span>].melt(id_vars=[<span class="string">'班级'</span>,<span class="string">'姓名'</span>],</span><br><span class="line">                     value_vars=[<span class="string">'语文'</span>,<span class="string">'数学'</span>,<span class="string">'英语'</span>],</span><br><span class="line">                     var_name=<span class="string">'学科'</span>,</span><br><span class="line">                     value_name=<span class="string">'分数'</span>,col_level=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c1629d283a024027bd3552de331c95c2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="melt"><br>具体实现如下图所示：<br><img src="https://img-blog.csdnimg.cn/1293078bb0bb4ec08a2a6ad64ad25c66.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="melt"></p><h2 id="2、数据透视-pivot"><a href="#2、数据透视-pivot" class="headerlink" title="2、数据透视 pivot"></a>2、数据透视 pivot</h2><p>来看pandas官网的示意图，是不是和unstack的图有点类似，将行数据转换成列。同样pivot提供了更多的参数可以指定相应的数据进行转换，比unstack更加灵活。<br><img src="https://img-blog.csdnimg.cn/f429e482c946477883cfe377725cd26f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="pivot"></p><p>这里有三个参数，作用分别是：</p><ul><li>index：新 df 的索引列，用于分组，如果为None，则使用现有索引 </li><li>columns：新 df 的列，如果透视后有重复值会报错</li><li>values：用于填充 df 的列。 如果未指定，将使用所有剩余的列，并且结果将具有按层次结构索引的列</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df_student5=df_student[<span class="number">0</span>:<span class="number">5</span>].melt(id_vars=[<span class="string">'班级'</span>,<span class="string">'姓名'</span>],</span><br><span class="line">                     value_vars=[<span class="string">'语文'</span>,<span class="string">'数学'</span>,<span class="string">'英语'</span>],</span><br><span class="line">                     var_name=<span class="string">'学科'</span>,</span><br><span class="line">                     value_name=<span class="string">'分数'</span>,col_level=<span class="number">1</span>)</span><br><span class="line">df_student5</span><br><span class="line">df_student5.pivot(index=[<span class="string">'班级'</span>,<span class="string">'姓名'</span>],columns=<span class="string">'学科'</span>,values=<span class="string">'分数'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a76f88c898f949668a9d8d9219d876e9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="pivot"></p><p>这里通过pivot将“学科”的行数据透视转换成“数学”、“英语”、“语文”三列，具体实现如下图所示：<br><img src="https://img-blog.csdnimg.cn/52879541f0904c1597436fbb6c476585.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="privot"><br>可以看出privot实际和unstack类似是由行转换成列的视图，但比起unstack更加灵活。</p><p>至此，介绍了pandas的多层索引及pandas的4种重塑操作：<strong>stack、unstack、pivot、melt</strong>:<br><strong>stack、unstack是基础：stack实现列转行，unstack实现行转列</strong>。<br>melt与stack类似，比stack更加灵活。<br>pivot与unstack类似，比unstack更加灵活。</p><p>数据集及源代码见：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在数据分析的过程中，分析师常常希望通过多个维度多种方式来观察分析数据，重塑和透视是常用的手段。&lt;br&gt;数据的重塑简单说就是对原数据进行变形，为什么需要变形，因为当前数据的展示形式不是我们期望的维度，也可以说索引不符合我们的需求。对数据的重塑不是仅改变形状那么简单，在变形过程
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据分析之分组聚合</title>
    <link href="https://xiejava.gitee.io/posts/dd24116d/"/>
    <id>https://xiejava.gitee.io/posts/dd24116d/</id>
    <published>2022-02-12T01:56:00.000Z</published>
    <updated>2022-02-12T01:59:11.586Z</updated>
    
    <content type="html"><![CDATA[<p>在数据分析过程中，经常会需要根据某一列或多列把数据划分为不同的组别，然后再对其进行数据分析。本文将介绍pandas的数据分组及分组后的应用如对数据进行聚合、转换和过滤。<br><img src="https://img-blog.csdnimg.cn/7c67a04fbecc420fbaa3f573773b4599.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="分组聚合"><br>在关系型数据库中我们常用SQL的GROUP BY操作进行分组分析计算。在pandas中要完成数据的分组操作同样可用groupby()函数，然后再在划分出来的组（group）上应用一些统计函数，从而达到数据分析的目的，比如对分组数据进行聚合、转换或者过滤。这个过程主要包含以下三步：<strong>拆分(split)-应用(apply)-合并(combine）</strong><br>例如，DataFrame可以在列(axis=1)或行(axis=0)上进行分组(split)，然后将一个函数应用(apply)到各个分组并产生一个新值，最后所有这些函数的执行结果会被合并(combine)到最终的结果对象中。<br>一个简单的分组聚合的过程如下图所示：<br><img src="https://img-blog.csdnimg.cn/bfcdc29750f74bbc9310ec28073c4dd1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="拆分(split)-应用(apply)-合并(combine）"></p><p>我们来构造图中所示的DataFrame数据集，看看pandas的分组聚合是怎么做的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df=pd.DataFrame(&#123;<span class="string">'key'</span>:[<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>],<span class="string">'data'</span>:[<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>]&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/96e8c83812014be19a9f425344d21b80.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据集"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">grouped=df.groupby([<span class="string">'key'</span>]) <span class="comment">#通过key分组</span></span><br><span class="line"><span class="comment">#查看分组情况</span></span><br><span class="line"><span class="keyword">for</span> dtype,group <span class="keyword">in</span> grouped:</span><br><span class="line">    print(dtype)</span><br><span class="line">grouped.sum() <span class="comment">#对每个分组应用sum函数，并最后组合成结果</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/88fe2175cc574f27a9035c01b32e068c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="对df的key进行用groupby()进行分组"><br>通过对df的key进行用groupby()进行分组，这里可看到，将数据分成了A、B、C三组，然后对这三组分别应用sum()函数求和，再组合成最终的结果。<br>对于分组聚合一般来说实际上是分两步：一是创建分组对象进行分组，二是对分组进行相应处理如（对组应用聚合函数、对组进行转换、对组的数据进行过滤）。不过实际在具体写的时候可以通过链式调用一个语句就可以实现如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.groupby([<span class="string">'key'</span>]).sum() <span class="comment">#链式调用先分组再用聚合函数聚合</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e03b9d8cd4cb4d9bba47d3887cfe6297.png#pic_center" alt="链式调用先分组再用聚合函数聚合"></p><h1 id="一、创建分组对象进行分组"><a href="#一、创建分组对象进行分组" class="headerlink" title="一、创建分组对象进行分组"></a>一、创建分组对象进行分组</h1><p>groupby可以把分组时指定的键（key）作为每组的组名。groupby对象支持迭代，可以遍历每个分组的具体数据。<br>如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看分组情况</span></span><br><span class="line"><span class="keyword">for</span> name,group <span class="keyword">in</span> grouped:</span><br><span class="line">    print(name)</span><br><span class="line">    print(group)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b2850e2072f7406ea1a1cb099fe4a049.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="查看分组情况"></p><h2 id="1、根据多列进行分组"><a href="#1、根据多列进行分组" class="headerlink" title="1、根据多列进行分组"></a>1、根据多列进行分组</h2><p>groupby可以通过传入需要分组的参数实现对数据的分组，参数可以是单列，也可以是多列，多列以列表的方式传入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grouped=df.groupby([<span class="string">'key1'</span>,<span class="string">'key2'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/349bebc6743449b99b350bd0c7bf7958.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="多列进行分组"></p><h2 id="2、通过字典或Series进行分组"><a href="#2、通过字典或Series进行分组" class="headerlink" title="2、通过字典或Series进行分组"></a>2、通过字典或Series进行分组</h2><p>除数组以外，分组信息还可以其他形式存在。如可以定义字典或Series进行分组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">people=pd.DataFrame(np.random.randn(<span class="number">5</span>,<span class="number">5</span>),</span><br><span class="line">                   columns=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>],</span><br><span class="line">                   index=[<span class="string">'Joe'</span>,<span class="string">'Steve'</span>,<span class="string">'Wes'</span>,<span class="string">'Jim'</span>,<span class="string">'Bob'</span>])</span><br><span class="line">people</span><br><span class="line">mapping=&#123;<span class="string">'a'</span>:<span class="string">'red'</span>,<span class="string">'b'</span>:<span class="string">'red'</span>,<span class="string">'c'</span>:<span class="string">'blue'</span>,<span class="string">'d'</span>:<span class="string">'blue'</span>,<span class="string">'e'</span>:<span class="string">'red'</span>&#125;<span class="comment">#定义分组字典</span></span><br><span class="line">by_column=people.groupby(mapping,axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#查看分组情况</span></span><br><span class="line"><span class="keyword">for</span> group_name,group_data <span class="keyword">in</span> by_column:</span><br><span class="line">    print(group_name)</span><br><span class="line">    print(group_data)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ffaacc1096844fbcb4b2436fc5ef2bd0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="字典分组"></p><p>在字典中我们定义了<code>mapping={&#39;a&#39;:&#39;red&#39;,&#39;b&#39;:&#39;red&#39;,&#39;c&#39;:&#39;blue&#39;,&#39;d&#39;:&#39;blue&#39;,&#39;e&#39;:&#39;red&#39;}#定义分组字典</code><br>a、b、e对应“red”，c、d对应“blue”所以将blue和red分成了两组。<br><img src="https://img-blog.csdnimg.cn/28718e616ddb4824a30244d08059fbc6.png#pic_center" alt="sum聚合"></p><p>应用sum()求和函数，可以看到分别对blue和red的分组进行了求和。<br>类似的，Series也是一样的，我们将map转换成Series，可以看到分组结果和map分组一样的。<br><img src="https://img-blog.csdnimg.cn/2bc677d7cad34810ba14fde3287655dd.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="Series分组"></p><h2 id="3、通过函数进行分组"><a href="#3、通过函数进行分组" class="headerlink" title="3、通过函数进行分组"></a>3、通过函数进行分组</h2><p>比起使用字典或Series,使用Python函数是一种更原生的方法定义分组映射，。任何被当做分组键的函数都会在各个索引值上被调用一次，其返回值就会被用作分组名称。<br>如上面的people数据集，将姓名索引的长度进行分组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">by_len=people.groupby(len)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/6125e1b8c36741a1a4216697aa666143.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="by_len"></p><p>可以看到将姓名长度相同的3分成一组，长度为5的数据分成了一组<br>更加通用的是可以自定义函数进行分组，如要将索引&gt;5的和小于5的分别分组，可以自定义函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据集</span></span><br><span class="line">df=pd.DataFrame(&#123;<span class="string">'key'</span>:[<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>],</span><br><span class="line">                 <span class="string">'data'</span>:[<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>]&#125;,</span><br><span class="line">                index=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line">df</span><br><span class="line"><span class="comment">#自定义函数区分大于5和小于5的数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">big5</span><span class="params">(x)</span>:</span>  </span><br><span class="line">    result=<span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> x&gt;<span class="number">5</span>:</span><br><span class="line">        result=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">by_big5=df.groupby(big5)  <span class="comment">#根据索引是否大于5进行分组</span></span><br><span class="line"><span class="comment">#查看分组情况</span></span><br><span class="line"><span class="keyword">for</span> group_name,group_data <span class="keyword">in</span> by_big5:</span><br><span class="line">    print(group_name)</span><br><span class="line">    print(group_data)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/7cb4a45173eb474fafae0482775e977f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="自定义函数分组"></p><h1 id="二、对分组后的数据进行应用"><a href="#二、对分组后的数据进行应用" class="headerlink" title="二、对分组后的数据进行应用"></a>二、对分组后的数据进行应用</h1><p>前面通过分组将数据集根据条件分组后，可以对分组后的数据进行各种处理包括聚合、转换、过滤等操作。</p><h2 id="1、对分组数据用聚合函数进行聚合"><a href="#1、对分组数据用聚合函数进行聚合" class="headerlink" title="1、对分组数据用聚合函数进行聚合"></a>1、对分组数据用聚合函数进行聚合</h2><h3 id="a-使用pandas聚合函数"><a href="#a-使用pandas聚合函数" class="headerlink" title="a) 使用pandas聚合函数"></a>a) 使用pandas聚合函数</h3><p>前面第一部分的例子中对数据分组后进行了sum()求和聚合操作，类似的聚合函数还有很多如：</p><table><thead><tr><th>函数名</th><th>描述</th></tr></thead><tbody><tr><td>count</td><td>分组中非NA值的数量</td></tr><tr><td>sum</td><td>非NA值的和</td></tr><tr><td>mean</td><td>非NA值的平均值</td></tr><tr><td>median</td><td>非NA值的中位数</td></tr><tr><td>std, var</td><td>标准差和方差</td></tr><tr><td>min, max</td><td>非NA的最小值，最大值</td></tr><tr><td>prod</td><td>非NA值的乘积</td></tr><tr><td>first, last</td><td>非NA值的第一个,最后一个</td></tr></tbody></table><p><img src="https://img-blog.csdnimg.cn/a601e7ac84744ac38faf7199a6b7c181.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="聚合函数"></p><h3 id="b-使用自定义聚合函数"><a href="#b-使用自定义聚合函数" class="headerlink" title="b) 使用自定义聚合函数"></a>b) 使用自定义聚合函数</h3><p>pandas的groupby分组对象还可以用自定义的聚合函数可以通过groupby分组对象，将你自己的聚合函数，传入aggregate或agg方法即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df=pd.DataFrame(&#123;<span class="string">'key'</span>:[<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>],<span class="string">'data'</span>:[<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>]&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/0663228f377a4b2788efb15aaa64800d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据集"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">grouped=df.groupby([<span class="string">'key'</span>])</span><br><span class="line"><span class="comment">#查看分组情况</span></span><br><span class="line"><span class="keyword">for</span> group_name,group_data <span class="keyword">in</span> grouped:</span><br><span class="line">    print(group_name)</span><br><span class="line">    print(group_data)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/96c5ea9c86aa477eaee733930ae7d236.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="分组情况"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">peak_to_peak</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> arr.max() - arr.min()</span><br><span class="line"></span><br><span class="line">grouped.agg(peak_to_peak)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/d615027ffaeb4e4bbba2ca9c0e8f41ef.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="自定义函数分组"></p><h2 id="2、根据分组数据进行转换"><a href="#2、根据分组数据进行转换" class="headerlink" title="2、根据分组数据进行转换"></a>2、根据分组数据进行转换</h2><p>根据分组数据进行数据转换或其他操作，可以在分组的基础上用apply函数进行数据的转换。<br>如数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df=pd.DataFrame(&#123;<span class="string">'key'</span>:[<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>],</span><br><span class="line">                 <span class="string">'data'</span>:[<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>]&#125;)</span><br><span class="line">df</span><br><span class="line">根据key分组</span><br><span class="line">grouped=df.groupby([<span class="string">'key'</span>])</span><br><span class="line"><span class="comment">#查看分组情况</span></span><br><span class="line"><span class="keyword">for</span> group_name,group_data <span class="keyword">in</span> grouped:</span><br><span class="line">    print(group_name)</span><br><span class="line">    print(group_data)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c4c883153a7b41249bb8cec76ddffcfb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据集"></p><p>现在我们要对data求和后小于25的分组数据都加1<br>那么我们可以定义函数，然后再对分数数据进行应用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add1</span><span class="params">(df)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> df[:][<span class="string">'data'</span>].sum()&lt;<span class="number">25</span>:</span><br><span class="line">        <span class="keyword">return</span> df[:][[<span class="string">'data'</span>]]+<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> df[:][[<span class="string">'data'</span>]]</span><br><span class="line">grouped.apply(add1)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/3ba316630f3e4c318f3062296722bcb3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据转换"></p><h2 id="3、根据分组数据进行过滤"><a href="#3、根据分组数据进行过滤" class="headerlink" title="3、根据分组数据进行过滤"></a>3、根据分组数据进行过滤</h2><p>通过 filter() 函数可以实现数据的筛选，该函数根据定义的条件过滤数据并返回一个新的数据集。<br>如当我们要过滤掉分组后data求和小于25的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#过滤掉sum()求和小于25的数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filtersum25</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x[<span class="string">'data'</span>].sum()&gt;<span class="number">25</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">grouped.filter(filtersum25)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/f5ebdff87ba048e8b6c9513fc551bc3f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据过滤"></p><p>至此，本文通过实例介绍了pandas的数据分组及分组后的应用如对数据进行聚合、转换和过滤。数据的分组和聚合是数据分析中常用的分析手段，转换和过滤是数据处理中可用到的方法。</p><p>数据集及源代码见：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在数据分析过程中，经常会需要根据某一列或多列把数据划分为不同的组别，然后再对其进行数据分析。本文将介绍pandas的数据分组及分组后的应用如对数据进行聚合、转换和过滤。&lt;br&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/7c67a04fbec
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据处理之合并与拼接</title>
    <link href="https://xiejava.gitee.io/posts/e7d4d6e1/"/>
    <id>https://xiejava.gitee.io/posts/e7d4d6e1/</id>
    <published>2022-02-10T06:10:57.000Z</published>
    <updated>2022-02-10T10:08:08.506Z</updated>
    
    <content type="html"><![CDATA[<p>在许多应用中，数据可能来自不同的渠道，在数据处理的过程中常常需要将这些数据集进行组合合并拼接，形成更加丰富的数据集。pandas提供了多种方法完全可以满足数据处理的常用需求。具体来说包括有join、merge、concat、append等。<br><img src="https://img-blog.csdnimg.cn/dd40ce2e4f694ae89ce8f85eceeb0c29.png#pic_center" alt="合并与拼接"><br>一般来说</p><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>join</td><td>最简单，主要用于基于索引的横向合并拼接</td></tr><tr><td>merge</td><td>最常用，主要用户基于指定列的横向合并拼接</td></tr><tr><td>concat</td><td>最强大，可用于横向和纵向合并拼接</td></tr><tr><td>append</td><td>主要用于纵向追加</td></tr><tr><td>combine_first</td><td>合并重叠数据，填充缺失值</td></tr><tr><td>update</td><td>将一个数据集的值更新到另一个数据集</td></tr></tbody></table><p>下面就来逐一介绍每个方法</p><h1 id="一、join"><a href="#一、join" class="headerlink" title="一、join"></a>一、join</h1><p>join主要用于基于索引的横向合并拼接<br>在介绍pandas的join之前我们来看一下SQL对数据集join的几种模式。如果大家对SQL比较熟悉的话应该对SQL操作数据集进行各种合并拼接印象深刻。SQL中各种JOIN的方法如下：<br><img src="https://img-blog.csdnimg.cn/4b3662215d2944efaf765b0846d6102a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="SQL-JOIN"></p><p>pandas的join实现了<strong>left join、right jion、inner join、out jion</strong>常用的4中join方法<br>来自官网的参数说明：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataframe.join(other,  <span class="comment"># 待合并的另一个数据集</span></span><br><span class="line">                   on=<span class="literal">None</span>,  <span class="comment"># 连接的键</span></span><br><span class="line">                   how=<span class="string">'left'</span>,   <span class="comment"># 连接方式：‘left’, ‘right’, ‘outer’, ‘inner’ 默认是left</span></span><br><span class="line">                   lsuffix=<span class="string">''</span>,  <span class="comment"># 左边（第一个）数据集相同键的后缀</span></span><br><span class="line">                   rsuffix=<span class="string">''</span>,  <span class="comment"># 第二个数据集的键的后缀</span></span><br><span class="line">                   sort=<span class="literal">False</span>)  <span class="comment"># 是否根据连接的键进行排序；默认False</span></span><br></pre></td></tr></table></figure><p>我们来看下实例，有两个数据集一个是人员姓名，一个是人员的工资</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">left=pd.DataFrame([<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>,<span class="string">'赵六'</span>,<span class="string">'钱七'</span>], index=[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],columns=[<span class="string">'姓名'</span>])</span><br><span class="line">right=pd.DataFrame([<span class="number">13000</span>,<span class="number">15000</span>,<span class="number">9000</span>,<span class="number">8600</span>,<span class="number">10000</span>], index=[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">8</span>],columns=[<span class="string">'工资'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/1f04c5a156c44172960950508e287fbe.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据集"></p><blockquote><p>注意，left和right的数据集分别都指定了index，因为join主要用于基于索引的横向合并拼接。</p></blockquote><h2 id="1、left-join"><a href="#1、left-join" class="headerlink" title="1、left join"></a>1、left join</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left.join(right)  <span class="comment">#默认how='left'</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/1b288957d7e0406984f56457544cc4e0.png#pic_center" alt="left join"></p><p>jion操作默认是left jion的操作，可以看到left索引为7姓名为钱七，在right中没有索引为7的对应所以显示left的姓名但right的工资为NaN，right中索引为8的数据在left中没有索引为8的，所以没有显示。left join合并left的数据<br>left join 如下图所示<br><img src="https://img-blog.csdnimg.cn/f83248acc33f426cad52fd05f391f467.png#pic_center" alt="left join"></p><h2 id="2、right-join"><a href="#2、right-join" class="headerlink" title="2、right join"></a>2、right join</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left.join(right,how=<span class="string">'right'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/9c959ac942b24db7a8740e1bdcae416a.png#pic_center" alt="right join"></p><p>右链接合并时可以看到，left的数据集没有索引为8的项，所以索引为8的项显示right数据集的工资数据但姓名为NaN，在left中索引为7的项因为right中不存在，所以没有显示。right join合并right的数据<br>right join 如下图所示<br><img src="https://img-blog.csdnimg.cn/57ca11901b8443a9bfd8eecfd39de242.png#pic_center" alt="right join"></p><h2 id="3、inner-join"><a href="#3、inner-join" class="headerlink" title="3、inner join"></a>3、inner join</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left.join(right,how=<span class="string">'inner'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/2f46d399e5014f959aed74e50e3a8173.png#pic_center" alt="inner join"></p><p>内链接合并时，可以看到left数据集中的索引为7姓名为钱七因为在right数据集中找不到对应的索引，right数据集中索引为8的在left找不到对应的索引所以内连接合并时索引7和8都没有进行合并，inner join只合并两个数据集共有的数据<br>inner join 如下图所示<br><img src="https://img-blog.csdnimg.cn/28191c9ea9c04060a72a4c9e3586a342.png#pic_center" alt="inner join"></p><h2 id="4、out-join"><a href="#4、out-join" class="headerlink" title="4、out join"></a>4、out join</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left.join(right,how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c94d60a0e8ac49658d81f0ee959ddd30.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="out join"><br>外链接合并时，可以看到不管是left中的数据还是right中的数据都进行了合并。right join合并两个数据集中所有的数据。<br>outer join 如下图所示<br><img src="https://img-blog.csdnimg.cn/58c32617de5c476487c9cf0dfe7a0e82.png#pic_center" alt="outer join"><br>join很简单，但是它有局限性，因为它只能根据索引来合并。不能指定键来进行合并。比如我要根据编号和姓名来合并，join就比较难办了。但是pandas提供了merge的方法，可以指定列来进行合并拼接。</p><h1 id="二、merge"><a href="#二、merge" class="headerlink" title="二、merge"></a>二、merge</h1><p>merge最常用，主要用户基于指定列和横向合并拼接，语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(left, right, how=<span class="string">'inner'</span>, on=<span class="literal">None</span>, left_on=<span class="literal">None</span>, right_on=<span class="literal">None</span>,</span><br><span class="line">left_index=<span class="literal">False</span>, right_index=<span class="literal">False</span>, sort=<span class="literal">True</span>,suffixes=(<span class="string">'_x'</span>, <span class="string">'_y'</span>), copy=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数名称</th><th>说明</th></tr></thead><tbody><tr><td>left/right</td><td>两个不同的 DataFrame 对象。</td></tr><tr><td>on</td><td>指定用于连接的键（即列标签的名字），该键必须同时存在于左右两个 DataFrame 中，如果没有指定，并且其他参数也未指定， 那么将会以两个 DataFrame 的列名交集做为连接键。</td></tr><tr><td>left_on</td><td>指定左侧 DataFrame 中作连接键的列名。该参数在左、右列标签名不相同，但表达的含义相同时非常有用。</td></tr><tr><td>right_on</td><td>指定左侧 DataFrame 中作连接键的列名。</td></tr><tr><td>left_index</td><td>布尔参数，默认为 False。如果为 True 则使用左侧 DataFrame 的行索引作为连接键，若 DataFrame 具有多层索引(MultiIndex)，则层的数量必须与连接键的数量相等。</td></tr><tr><td>right_index</td><td>布尔参数，默认为 False。如果为 True 则使用左侧 DataFrame 的行索引作为连接键。</td></tr><tr><td>how</td><td>要执行的合并类型，从 {‘left’, ‘right’, ‘outer’, ‘inner’} 中取值，默认为“inner”内连接。</td></tr><tr><td>sort</td><td>布尔值参数，默认为True，它会将合并后的数据进行排序；若设置为 False，则按照 how 给定的参数值进行排序。</td></tr><tr><td>suffixes</td><td>字符串组成的元组。当左右 DataFrame 存在相同列名时，通过该参数可以在相同的列名后附加后缀名，默认为(‘_x’,’_y’)。</td></tr><tr><td>copy</td><td>默认为 True，表示对数据进行复制。</td></tr></tbody></table><p>我们来看下面的数据集，在上面的数据集中left数据集加入了员工的编号，right数据集加入了编号及姓名。索引就按默认的索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">left=pd.DataFrame([[<span class="number">3</span>,<span class="string">'张三'</span>],[<span class="number">4</span>,<span class="string">'李四'</span>],[<span class="number">5</span>,<span class="string">'王五'</span>],[<span class="number">6</span>,<span class="string">'赵六'</span>],[<span class="number">7</span>,<span class="string">'钱七'</span>]],</span><br><span class="line">columns=[<span class="string">'编号'</span>,<span class="string">'姓名'</span>])</span><br><span class="line"></span><br><span class="line">right=pd.DataFrame([[<span class="number">3</span>,<span class="string">'张三'</span>,<span class="number">13000</span>],[<span class="number">4</span>,<span class="string">'李四'</span>,<span class="number">15000</span>],[<span class="number">5</span>,<span class="string">'王五'</span>,<span class="number">9000</span>],[<span class="number">6</span>,<span class="string">'赵六'</span>,<span class="number">8600</span>],[<span class="number">8</span>,<span class="string">'孙八'</span>,<span class="number">10000</span>]],</span><br><span class="line">columns=[<span class="string">'编号'</span>,<span class="string">'姓名'</span>,<span class="string">'工资'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/fcc9ae729d564abd89ce6b0144269a53.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="merge数据集"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(left,right)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/d3a58242a2da4719a3fa8b63aab5f9b9.png#pic_center" alt="pd.merge(left,right)"></p><p>没有指定连接键，默认用重叠列名，没有指定连接方式，默认inner内连接（取left和right编号和姓名的交集）<br>和join一样通过how来指定连接方式如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(left,right,how=<span class="string">'left'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e6ba32e087644c7ca662e18969d3419b.png#pic_center" alt="pd.merge(left,right,how=&#39;left&#39;)"></p><p>how的连接方式和join一样支持left、right、inner、outer<br>merge还可以指定多个列进行合并链接，也就是和SQL一样设置多个关联的列。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(left,right,how=<span class="string">'outer'</span>,on=[<span class="string">'编号'</span>,<span class="string">'姓名'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ec980f11279948188c804f9bddd80f36.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="merge-out"></p><p>如果两个对象的列名不同，可以使用<code>left_on</code>，<code>right_on</code>分别指定，如我们把right数据集的“编码”列标签改成“ID”后如果需要left数据集的”编号”和right数据集的”ID”进行关联</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">right=pd.DataFrame([[<span class="number">3</span>,<span class="string">'张三'</span>,<span class="number">13000</span>],[<span class="number">4</span>,<span class="string">'李四'</span>,<span class="number">15000</span>],[<span class="number">5</span>,<span class="string">'王五'</span>,<span class="number">9000</span>],[<span class="number">6</span>,<span class="string">'赵六'</span>,<span class="number">8600</span>],[<span class="number">8</span>,<span class="string">'孙八'</span>,<span class="number">10000</span>]],columns=[<span class="string">'ID'</span>,<span class="string">'姓名'</span>,<span class="string">'工资'</span>])</span><br><span class="line"></span><br><span class="line">pd.merge(left,right,how=<span class="string">'outer'</span>,left_on=<span class="string">'编号'</span>,right_on=<span class="string">'ID'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/dbd437e103634655bef58d4ef5b05d2b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="指定列名关联"></p><p>虽然说merge已经很强大了，但是pandas愿意给你更多，它提供了concat，可以实现横向和纵向的合并与拼接。也就是说不但实现了SQL中的join还实现了union</p><h1 id="三、concat"><a href="#三、concat" class="headerlink" title="三、concat"></a>三、concat</h1><p>concat() 函数用于沿某个特定的轴执行连接操作，语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.concat(objs,axis=<span class="number">0</span>,join=<span class="string">'outer'</span>,join_axes=<span class="literal">None</span>,ignore_index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数名称</th><th>说明</th></tr></thead><tbody><tr><td>objs</td><td>一个序列或者是Series、DataFrame对象。</td></tr><tr><td>axis</td><td>表示在哪个轴方向上（行或者列）进行连接操作，默认 axis=0 表示行方向。</td></tr><tr><td>join</td><td>指定连接方式，取值为{“inner”,”outer”}，默认为 outer 表示取并集，inner代表取交集。</td></tr><tr><td>ignore_index</td><td>布尔值参数，默认为 False，如果为 True，表示不在连接的轴上使用索引。</td></tr><tr><td>join_axes</td><td>表示索引对象的列表。</td></tr></tbody></table><p>来看具体的例子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left2=pd.DataFrame([[<span class="number">1</span>,<span class="string">'陈一'</span>],[<span class="number">2</span>,<span class="string">'周二'</span>]],columns=[<span class="string">'编号'</span>,<span class="string">'姓名'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/22564f0092714a18ba0a8e312bde8ff2.png#pic_center" alt="数据集"></p><h2 id="1、纵向合并"><a href="#1、纵向合并" class="headerlink" title="1、纵向合并"></a>1、纵向合并</h2><p>concat默认纵向拼接，我们要在left1数据集的基础上把left2数据集给合并上去，很简单用concat直接就可以合并。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df=pd.concat([left,left2])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/19c5007f016d4a46b5ef715aa4d52445.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="纵向合并"></p><h2 id="2、横向合并"><a href="#2、横向合并" class="headerlink" title="2、横向合并"></a>2、横向合并</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_outer=pd.concat([left,right],axis=<span class="number">1</span>,join=<span class="string">'outer'</span>)<span class="comment">#外链接</span></span><br><span class="line">df_inner=pd.concat([left,right],axis=<span class="number">1</span>,join=<span class="string">'inner'</span>)<span class="comment">#内链接</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/d7bf47354d8b45dbabe3ed5f82aee366.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="横向合并"></p><blockquote><p>注意：因为concat的链接和join一样是通过索引来链接合并，并不能指定通过某个特定的列来链接进行合并，所以看到的合并后的数据集left和right的编号和姓名是错位的。</p></blockquote><p>如果要根据编号来关联可以指定编号作为索引再进行横向合并，这样就没有问题了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">left.index=left[<span class="string">'编号'</span>].values</span><br><span class="line">right.index=right[<span class="string">'编号'</span>].values</span><br><span class="line">df_outer=pd.concat([left,right],axis=<span class="number">1</span>,join=<span class="string">'outer'</span>)</span><br><span class="line">df_inner=pd.concat([left,right],axis=<span class="number">1</span>,join=<span class="string">'inner'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/5b57174ea9b14e7e96164c1ae1dd183d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="横向合并"></p><h1 id="四、append"><a href="#四、append" class="headerlink" title="四、append"></a>四、append</h1><p>df.append 可以将其他行附加到调用方的末尾，并返回一个新对象。它是最简单常用的数据合并方式。语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.append(self, other, ignore_index=<span class="literal">False</span>,verify_integrity=<span class="literal">False</span>, sort=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li>other 是它要追加的其他 DataFrame 或者类似序列内容 </li><li>ignore_index 如果为 True 则重新进行自然索引</li><li>verify_integrity 如果为 True 则遇到重复索引内容时报错 </li><li>sort 进行排序</li></ul><p>来看下面的例子：</p><h2 id="1、同结构数据追加"><a href="#1、同结构数据追加" class="headerlink" title="1、同结构数据追加"></a>1、同结构数据追加</h2><p>将同结构的数据追加在原数据后面，在left数据集后面追加left2数据集，left2的数据集内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">left2=pd.DataFrame([[<span class="number">1</span>,<span class="string">'陈一'</span>],[<span class="number">2</span>,<span class="string">'周二'</span>]],columns=[<span class="string">'编号'</span>,<span class="string">'姓名'</span>])</span><br><span class="line">left2</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/82937b0bd5404b2a983a61e1afae4b1d.png#pic_center" alt="append数据集"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left.append(left2)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/f968e6e71cd24039b3d5f3f728fe0efb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="append"></p><h2 id="2、不同结构数据追加"><a href="#2、不同结构数据追加" class="headerlink" title="2、不同结构数据追加"></a>2、不同结构数据追加</h2><p>不同结构数据追加，原数据没有的列会增加，没有对应内容的会为空NaN。<br>如：left3的数据集列有”编号”、”姓名”、”工资”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">left3=pd.DataFrame([[<span class="number">8</span>,<span class="string">'孙八'</span>,<span class="number">10000</span>],[<span class="number">9</span>,<span class="string">'何九'</span>,<span class="number">15000</span>]],columns=[<span class="string">'编号'</span>,<span class="string">'姓名'</span>,<span class="string">'工资'</span>])</span><br><span class="line">left3</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/63772c8399cf42e1b5fa4c8056cdcf5e.png#pic_center" alt="left3的数据集"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left.append(left3)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/40aa9fe061454ec1b5a2a2085ceacc4e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="不同结构数据追加"></p><p>当left后追加left3后的数据集会增加“工资列”，没有对应内容的会为空。</p><h2 id="3、追加合并多个数据集"><a href="#3、追加合并多个数据集" class="headerlink" title="3、追加合并多个数据集"></a>3、追加合并多个数据集</h2><p>append参数可带数据集列表，可以将多个数据集追加到原数据集<br>如我们将left2和left3都追加到left</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left.append([left2,left3])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/3e6c5584e92e46a287a1fbe89e19fa54.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="追加合并多个数据集"></p><h1 id="五、combine-first"><a href="#五、combine-first" class="headerlink" title="五、combine_first"></a>五、combine_first</h1><p>combine_first可用于合并重复数据，用其他数据集填充没有的数据。如一个DataFrame数据集中出现了缺失数据，就可以用其他DataFrame数据集中的数据进行填充。语法格式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">combine_first(other) <span class="comment">#只有一个参数other，该参数用于接收填充缺失值的DataFrame对象。</span></span><br></pre></td></tr></table></figure><p>如left数据集中没有”工资”的数据，我们可以用right数据集有的数据去填充left数据集中的数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left.combine_first(right) <span class="comment">#用right去填充left</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a7c3857131df4cd0879a6c211196eeb5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="combine_first"></p><h1 id="六、update"><a href="#六、update" class="headerlink" title="六、update"></a>六、update</h1><p>update和combine_first比较类似，区别在于：<br>1、填充合并方式稍有差异<br>combine_first：如果s1中c的值为空，用s2的值替换，否则保留s1的值<br>update：如果s2中的值不为空，那么替换s1，否则保留s1的值<br>2、update是更新原数据，combine_first会返回一个填充后的新数据集，对原数据不做更新。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">left.update(right) <span class="comment">#用right的数据更新left中的数据。</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/023ee8c45f0c4ebcab1591405bd43162.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="update"></p><p>至此，本文介绍了pandas的多种数据合并与拼接方法，并介绍了每种方法的异同，通过pandas的数据处理可以应付日常数据处理中大部分的数据处理工作。</p><p>数据集及源代码见：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在许多应用中，数据可能来自不同的渠道，在数据处理的过程中常常需要将这些数据集进行组合合并拼接，形成更加丰富的数据集。pandas提供了多种方法完全可以满足数据处理的常用需求。具体来说包括有join、merge、concat、append等。&lt;br&gt;&lt;img src=&quot;htt
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas基本操作之数据访问(查看与检索)</title>
    <link href="https://xiejava.gitee.io/posts/808d8fe8/"/>
    <id>https://xiejava.gitee.io/posts/808d8fe8/</id>
    <published>2022-02-07T15:40:32.000Z</published>
    <updated>2022-02-07T15:42:00.505Z</updated>
    
    <content type="html"><![CDATA[<p>对于数据分析来说，在构造或载入数据后最基本的操作应该就是对数据的访问了。看一看数据的结构、组成、分布等，根据需要从数据集中检索提取出相应的数据。pandas作为数据分析的利器，当然提供了多种查看和检索数据的方法。本文就来捋一捋pandas基本的数据访问。<br><img src="https://img-blog.csdnimg.cn/8581e4736c4e47ef8a6c71db7f941d18.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_10,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据访问"></p><h1 id="一、查看数据"><a href="#一、查看数据" class="headerlink" title="一、查看数据"></a>一、查看数据</h1><p>当我们拿到数据集后，第一步可能就是查看数据了，一方面是了解拿到的数据集的数据结构，另一方面随机检查一下数据的质量问题。<br>不管是Series还是DataFrame的数据集pandas常用的数据查看方法有：</p><table><thead><tr><th>方法</th><th>操作</th><th>结果</th></tr></thead><tbody><tr><td>head(n)</td><td>查看数据集对象的前n行</td><td>Series或DataFrame</td></tr><tr><td>tail(n)</td><td>查看数据集的最后n行</td><td>Series或DataFrame</td></tr><tr><td>sample(n)</td><td>随机查看n个样本</td><td>Series或DataFrame</td></tr><tr><td>describe()</td><td>数据集的统计摘要</td><td>Series</td></tr></tbody></table><p>以下就以一个DataFrame数据集为例来看看这些查看数据的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">'D:\\Python\\study\\pythontest\\pandastest\\数据集\\staff.xlsx'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/d4afe8d481f64beaab0b6ecfa556bb17.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="studend数据集"></p><h2 id="1、查看头部-head-n"><a href="#1、查看头部-head-n" class="headerlink" title="1、查看头部 head(n)"></a>1、查看头部 head(n)</h2><p>head()方法如果不带参数，默认返回前5条记录，带了参数n就返回前n条记录。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.head() <span class="comment">#默认查看前5条记录</span></span><br><span class="line">df.head(<span class="number">8</span>) <span class="comment">#指定查看前8条记录</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/fc0d5daa5bf04091988e85fd660845df.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="查看头部 head(n)"></p><h2 id="2、查看尾部-tail-n"><a href="#2、查看尾部-tail-n" class="headerlink" title="2、查看尾部 tail(n)"></a>2、查看尾部 tail(n)</h2><p>同样tail()方法如果不带参数，默认返回后面5条记录，带了参数n就返回后面n条记录。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.tail() <span class="comment">#默认查看后面5条记录</span></span><br><span class="line">df.tail(<span class="number">4</span>) <span class="comment">#指定查看后面4条记录</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/3387c860aef141e5a91955907af1e0f0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="查看尾部 tail(n)"></p><h2 id="3、随机查看样本-sample-n"><a href="#3、随机查看样本-sample-n" class="headerlink" title="3、随机查看样本 sample(n)"></a>3、随机查看样本 sample(n)</h2><p>sample() 不带参数会随机返回一条样本数据，带了参数n就会随机返回n条记录。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.sample() <span class="comment">#随机查看一条记录</span></span><br><span class="line">df.sample(<span class="number">4</span>) <span class="comment">#随机查看4条记录</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/dccdd7792d564c64b5b4a6f6b8b68cf5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="随机查看样本 sample(n)"></p><h2 id="4、查看统计摘要"><a href="#4、查看统计摘要" class="headerlink" title="4、查看统计摘要"></a>4、查看统计摘要</h2><p><code>df.describe()</code> 返回所有数字列的统计摘要。<br><img src="https://img-blog.csdnimg.cn/d9cb60a2e4324e6aae5a18e17f82e2be.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="查看统计摘要"></p><p>这里连staff_id的统计摘要就显示出来了，因为它是数字列。如果只看某一列的统计摘要</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[[<span class="string">'staff_salary'</span>]].describe()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/d1c277b8fc684e47b1ef6eacb1e59d7a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="只看某一列的统计摘要"></p><h1 id="二、检索数据"><a href="#二、检索数据" class="headerlink" title="二、检索数据"></a>二、检索数据</h1><p>在数据分析过程中，很多时候需要从数据表中提取出相应的数据，而这么做的前提是需要先“检索”出这一部分数据。虽然通过 Python 提供的索引操作符”[]”和属性操作符”.”可以访问 Series 或者 DataFrame 中的数据，但这种方式只适应与少量的数据，为了解决这一问题，pandas 提供了多种类型的索引方式来实现数据的访问。包括[]、loc\iloc、at\iat、布尔索引<br>一般的:<br>df[‘name’] #会返回本列的Series<br>df.name   #也会返回本列的Series</p><blockquote><p>但是要注意，name应该是一个合法的python变量时才可以直接作为属性来使用。</p></blockquote><p>如：<br><strong>df[‘1级别’]可以正常返回索引列为“1级别”的数据，而df.1级别会报错，因为”1级别”不是一个合法的python变量。</strong><br><img src="https://img-blog.csdnimg.cn/311840594a5d4d968a8e071783b8ad8b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="列索引检索"><br>以下通过DataFrame数据集来说明常用检索数据的方法。对于DataFrame的数据集来说要检索数据通常是确定数据所在的行和列。而确定行和列也有两种方式，一是通过<strong>标签索引</strong>来确定，二是通过数据<strong>所在的位置</strong>来确定。<br>一般的：</p><table><thead><tr><th>操作</th><th>语法</th><th>返回结果</th></tr></thead><tbody><tr><td>选择列</td><td>df[col]</td><td>Series</td></tr><tr><td>按索引选择行</td><td>df.loc[label]</td><td>Series</td></tr><tr><td>按位置选择行</td><td>df.iloc[loc]</td><td>Series</td></tr><tr><td>使用切片选择行</td><td>df[2:5]</td><td>DataFrame</td></tr><tr><td>用表达式筛选行</td><td>df[bool]</td><td>DataFrame</td></tr></tbody></table><h2 id="1、切片"><a href="#1、切片" class="headerlink" title="1、切片[]"></a>1、切片[]</h2><p>通过[]进行检索，这将会对行进行切片</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="number">0</span>:<span class="number">3</span>] <span class="comment">#通过切片检索行数据</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8970b0d6e75847efa828127460679b29.png#pic_center" alt="在这里插入图片描述"></p><p>切片并不对列有效，如果是<code>df[0:3][1:2]</code>，会检索出0-3行，再在这三行切片的基础上切片中检索出第二行。<br><img src="https://img-blog.csdnimg.cn/fe95d1c6e4e44b9f850b8aa31a7a6ac9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="df[0:3][1:2]"></p><p>如果要在切片检索的结果上再选择列，则可以通过列标签索引列表来选择</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="number">0</span>:<span class="number">3</span>][[<span class="string">'staff_id'</span>,<span class="string">'staff_name'</span>,<span class="string">'staff_gender'</span>]] <span class="comment">#通过列标签索引列表检索列数据</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/5c44f494b92143c6b15c4933e9770b50.png#pic_center" alt="通过列标签索引列表来选择"></p><h2 id="2、loc-iloc"><a href="#2、loc-iloc" class="headerlink" title="2、loc\iloc"></a>2、loc\iloc</h2><h3 id="loc"><a href="#loc" class="headerlink" title="loc"></a>loc</h3><p>df.loc[] 只能使用标签索引，不能使用位置索引。当通过标签索引的切片方式来筛选数据时，它的取值前闭后闭，也就是只包括边界值标签（开始和结束）<br>.loc[] 具有多种访问方法，如下所示：</p><ul><li>一个标量标签 </li><li>标签列表 </li><li>切片对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df.loc[<span class="number">1</span>] <span class="comment">#标量标签，返回该行标签的Series数据</span></span><br><span class="line">df.loc[[<span class="number">1</span>,<span class="number">3</span>]] <span class="comment">#标签列表，返回标签列表的行DataFrame数据</span></span><br><span class="line">df.loc[<span class="number">0</span>:<span class="number">3</span>] <span class="comment">#切片对象，返回切片的行DataFrame数据</span></span><br><span class="line">df.loc[<span class="number">0</span>:<span class="number">3</span>,<span class="string">'staff_id'</span>:<span class="string">'staff_salary'</span>]  <span class="comment">#根据行切片，列切片检索数据</span></span><br><span class="line">df.loc[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="string">'staff_id'</span>,<span class="string">'staff_name'</span>,<span class="string">'staff_age'</span>]] <span class="comment">#根据行标签列表，列标签列表检索数据</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/6c0b79c29b3b4bd1a6813716ca98d82a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="loc"></p><p>.loc[] 除了标量标签，标签列表和切片对象都接受两个参数，并以’,’分隔。第一个位置表示行检索，第二个位置表示列检索<br><img src="https://img-blog.csdnimg.cn/6fbe652ce26d40fea646154cef558db7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="loc2"></p><h3 id="iloc"><a href="#iloc" class="headerlink" title="iloc"></a>iloc</h3><p>df.iloc[] 只能使用位置索引(用整数表示所在行或列的位置如第几行第几列)，不能使用标签索引，通过整数索引切片选择数据时，前闭后开(不包含边界结束值)。同 Python 和 NumPy 一样，它们的<strong>索引都是从 0 开始</strong><br>.iloc[] 提供了以下方式来选择数据：</p><ul><li>整数索引   </li><li>整数列表  </li><li>数值范围</li></ul><p>为了说明方便，我们把数据集的行索引重名为字母</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df=df.rename(index=&#123;<span class="number">0</span>:<span class="string">'A'</span>,<span class="number">1</span>:<span class="string">'B'</span>,<span class="number">2</span>:<span class="string">'C'</span>,<span class="number">3</span>:<span class="string">'D'</span>,<span class="number">4</span>:<span class="string">'E'</span>,<span class="number">5</span>:<span class="string">'F'</span>,<span class="number">6</span>:<span class="string">'G'</span>,<span class="number">7</span>:<span class="string">'H'</span>,<span class="number">8</span>:<span class="string">'I'</span>,<span class="number">9</span>:<span class="string">'J'</span>&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/6803048b73534cefb40d294d9d6745cb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="reanme"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df.iloc[<span class="number">1</span>]  <span class="comment">#整数标量选择，数据从0开始，为1的就是第二行的数据，返回的是Series</span></span><br><span class="line">df.iloc[[<span class="number">1</span>,<span class="number">3</span>]] <span class="comment">#整数列表选择，选择位置为1和3的数据，返回的是DataFrame</span></span><br><span class="line">df.iloc[<span class="number">1</span>:<span class="number">3</span>] <span class="comment">#切片选择，选择位置1至2的数据，不包含边界结束值，也就是不包含3的位置</span></span><br><span class="line">df.iloc[<span class="number">1</span>:<span class="number">3</span>,<span class="number">1</span>:<span class="number">4</span>] <span class="comment">#切片选择位置为1至3的行和1至4的列不含位置为3的行和位置为4的列</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/64187160c75f42a882300bb04b7df7e1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="iloc"></p><h2 id="3、at-iat"><a href="#3、at-iat" class="headerlink" title="3、at\iat"></a>3、at\iat</h2><p>at和iat和loc和iloc类似，不同的是at和iat仅取一个具体的值，结构为 at[&lt;索引&gt;,&lt;列名&gt;]，iat[&lt;行位置&gt;,&lt;列位置&gt;]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.at[<span class="string">'A'</span>,<span class="string">'staff_name'</span>]  <span class="comment">#检索第“A”行的列标签为"staff_name"的数据</span></span><br><span class="line">df.iat[<span class="number">0</span>,<span class="number">1</span>]  <span class="comment">#检索第1行第2列的数据</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8fb64f577fce473eacf05bdf8202215d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="at\iat"></p><h2 id="4、布尔条件检索"><a href="#4、布尔条件检索" class="headerlink" title="4、布尔条件检索"></a>4、布尔条件检索</h2><h3 id="1、-里用布尔条件进行检索"><a href="#1、-里用布尔条件进行检索" class="headerlink" title="1、[] 里用布尔条件进行检索"></a>1、[] 里用布尔条件进行检索</h3><p>如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df.staff_salary&gt;<span class="number">10000</span>)&amp;(df.staff_age&lt;<span class="number">40</span>)]  <span class="comment">#检索staff_age小于40且staff_salary&gt;10000的数据</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/01374b35c7244e23a70909fd04530e24.png#pic_center" alt="[] 里用布尔条件进行检索"></p><h3 id="2、loc索引部分用布尔条件检索"><a href="#2、loc索引部分用布尔条件检索" class="headerlink" title="2、loc索引部分用布尔条件检索"></a>2、loc索引部分用布尔条件检索</h3><p>如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.loc[(df.staff_salary&gt;<span class="number">10000</span>)&amp;(df.staff_age&lt;<span class="number">40</span>)]  <span class="comment">#检索staff_age小于40且staff_salary&gt;10000的数据</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/4d160148aaaf4e778767ece4a5065283.png#pic_center" alt="loc索引部分用布尔条件检索"></p><h3 id="3、query函数布尔条件检索"><a href="#3、query函数布尔条件检索" class="headerlink" title="3、query函数布尔条件检索"></a>3、query函数布尔条件检索</h3><p>如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.query(<span class="string">'staff_salary&gt;10000 &amp; staff_age&lt;40'</span>) <span class="comment">#通过函数检索staff_age小于40且staff_salary&gt;10000的数据</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/4894b9dc467044de9adb17e56e1d5801.png#pic_center" alt="query函数布尔条件检索"></p><p>至此，本文介绍了pandas常用的数据访问操作通过head()、tail()、sample()、describe()查看数据，通过[]、loc\iloc、at\iat、及布尔条件检索数据。通过灵活运用pandas的各种数据访问方法可以很方便的根据需要查看和检索数据。</p><p>数据集及源代码见：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对于数据分析来说，在构造或载入数据后最基本的操作应该就是对数据的访问了。看一看数据的结构、组成、分布等，根据需要从数据集中检索提取出相应的数据。pandas作为数据分析的利器，当然提供了多种查看和检索数据的方法。本文就来捋一捋pandas基本的数据访问。&lt;br&gt;&lt;img s
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据处理之数据转换(映射map、替换replace、重命名rename)</title>
    <link href="https://xiejava.gitee.io/posts/2c80aac2/"/>
    <id>https://xiejava.gitee.io/posts/2c80aac2/</id>
    <published>2022-02-04T14:07:01.000Z</published>
    <updated>2022-02-04T14:09:06.650Z</updated>
    
    <content type="html"><![CDATA[<p>我们在数据处理的过程中经常碰到需要对数据进行转换的工作，比如将原来数据里的字典值根据字典转义成有意义的说明，将某些数据转换成其他的数据，将空值转换成其他值，将数据字段名进行重命名等。pandas作为数据处理分析的利器当然为上述的这些数据转换提供了便捷的方法。我们可以利用pandas提供的映射、替换、重命名等操作方便的进行相应的数据转换操作。</p><p>本文通过实例重点介绍pandas常用的数据转换工具映射map()、替换replace()、重命名rename()</p><p><strong>映射</strong>：map()函数 对数据集Serice中的元素根据映射关系进行映射（作用于Serice或DataFrame对象的一列）<br><strong>替换</strong>：replace()函数 替换元素 (作用于DataFrame)<br><strong>重命名</strong>：rename()函数  替换索引 (作用于index或columns)</p><h1 id="一、映射-map"><a href="#一、映射-map" class="headerlink" title="一、映射 map()"></a>一、映射 map()</h1><p>在平时数据处理的过程中常常会碰到，某个字段（数据列）是数字表示的要根据映射表转换成有意思的字符。如性别在数据集里存的是1和2分别表示“男”和“女”，如何将数据集中“性别”列的1和2替换成“男”和“女”如何做？绝对不能用for循环一个个去替换。pandas也好、Numpy也好，都是针对数据集处理的，我们应该抛弃以前针对单个数据处理的思维去拥抱针对数据集来编程。使用pandas的map()方法，最少仅需一行代码就可以解决。<br>map() 函数是做用于 Series 或 DataFrame 对象的一列，它接收一个函数或表示映射关系的字典做为参数，它的基本语法格式以下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Series.map(arg,na_action=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>函数中的参数说明以下：</p><ul><li>arg：接收 function、dict 或 Series，表示映射关系；</li><li>na_action：类似R中的na.action，取值为None或ingore，用于控制遇到缺失值的处理方式，设置为ingore时串行运算过程中将忽略Nan值原样返回。</li></ul><p>下面通过实例来说明pandas的map()的使用，演示的student数据集如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">'D:\\Python\\study\\pythontest\\pandastest\\数据集\\student.xlsx'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b829442e9d9b402e9f241d04fc3d52ee.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="student数据集"></p><h2 id="1、通过数据字典映射"><a href="#1、通过数据字典映射" class="headerlink" title="1、通过数据字典映射"></a>1、通过数据字典映射</h2><p>map()方法接受数据字典参数，通过数据字典将数据进行映射。如我们需要将“性别”列的1和2替换成“男”和“女”，定义一个数据字典{1:’男’,2:’女’}，将1映射成“男”，将2映射成“女”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gender_map=&#123;<span class="number">1</span>:<span class="string">'男'</span>,<span class="number">2</span>:<span class="string">'女'</span>&#125;</span><br><span class="line">df[<span class="string">'性别'</span>]=df[<span class="string">'性别'</span>].map(gender_map)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/d564c69bd9294e9fbe783c521f913e9f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据字典映射"><br>可以看到通过map()将需要转换的列的值进行的转换，具体的转换过程如下图所示：<br><img src="https://img-blog.csdnimg.cn/fbc75117bc9145098d3a43d848ce76d3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="map转换过程"></p><h2 id="2、lambda函数映射"><a href="#2、lambda函数映射" class="headerlink" title="2、lambda函数映射"></a>2、lambda函数映射</h2><p>map()方法还接受lambda函数的方式进行值的映射，如我们现在要把数学分数为95分以上的映射数学等级为“优秀”，95及以下的映射为“良好”。可以通过lambda函数进行映射。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'数学等级'</span>]=df[<span class="string">'5-数学'</span>].map(<span class="keyword">lambda</span> x:<span class="string">'优秀'</span> <span class="keyword">if</span> x&gt;<span class="number">95</span> <span class="keyword">else</span> <span class="string">'良好'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ceea930a6c144766951c729461e4b67f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="lambda函数映射"></p><h2 id="3、通用函数映射"><a href="#3、通用函数映射" class="headerlink" title="3、通用函数映射"></a>3、通用函数映射</h2><p>map()方法可以接收自定义通用的函数进行值的映射，如我们现在要把语文分数为95以上的映射为语文等级为“优秀”，95及以下的映射为“良好”，也可以通过自定义函数来实现映射。<br>先定义一个函数score(x)用于接收需要映射的值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(x)</span>:</span></span><br><span class="line">    score_class=<span class="string">'良好'</span></span><br><span class="line">    <span class="keyword">if</span> x&gt;<span class="number">95</span>:</span><br><span class="line">        score_class=<span class="string">'优秀'</span></span><br><span class="line">    <span class="keyword">return</span> score_class</span><br><span class="line">    </span><br><span class="line">df[<span class="string">'语文等级'</span>]=df[<span class="string">'4-语文'</span>].map(score)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/1d8ab00c51404059bd2a3738d6a09822.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="函数映射"></p><h1 id="二、替换-replace"><a href="#二、替换-replace" class="headerlink" title="二、替换 replace()"></a>二、替换 replace()</h1><p>如果要对全DataFrame数据集中的数据进行某种替换，map()可能需要对数据集中的每个列都进行map()操作才可以，但是通过pandas的替换方法replace可以一次性替换掉DataFrame中所有的数据。如：我们现在要将数据集中所有的“良好”替换成“良”，所有的“优秀”替换成“优”<br>可以直接通过 <code>df.replace([&#39;优秀&#39;,&#39;良好&#39;],[&#39;优&#39;,&#39;良&#39;])</code> 一句代码搞定。<br><img src="https://img-blog.csdnimg.cn/2dfc6617e129434dba02868ac172d15e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="替换"></p><p>以前文章中介绍了处理缺失值用fillna的方式来填充缺失值，用replace则提供了一种更加简单、灵活的处理缺失值或异常值的方式。<br>如在数据集中有一个数据列“是否接种”，这里的值有“已”、“是”、“否”、NaN，实际是在收集统计表格的时候大家填的数据不一致，不标准。现在需要将“已”的全部改成“是”，NaN没有填的改成“否”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.replace([<span class="string">'已'</span>,np.nan],[<span class="string">'是'</span>,<span class="string">'否'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/6d5a4ba993ea4540840d22c79204f7c0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="填充缺失值"></p><h1 id="三、重命名-rename"><a href="#三、重命名-rename" class="headerlink" title="三、重命名 rename()"></a>三、重命名 rename()</h1><p>在数据处理的过程有时候需要对列索引进行重命名，一个典型的例子就是对于数据的检索或其他操作df[column]对于任意列名均有效，但是df.column只在列名是有效的Python变量名时才有效。<br>我们在检索英语大于95分的数据时可以用<code>df[df[&#39;6-英语&#39;]&gt;95]</code><br><img src="https://img-blog.csdnimg.cn/3dbf9c7775484138b24860fffa065918.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="英语大于95分的数据"></p><p> 但是用<code>df.query(&#39;6-英语 &gt;95&#39;)</code> 就会报列名没有定义的错，因为’6-英语’列名不是有效的Python变量名。<br><img src="https://img-blog.csdnimg.cn/3e48e91116f94ee28d52a00fd49878ad.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="报列名没有定义的错"></p><p>这时候就需要将列名重命名为有效的Python变量名，有效的Python变量名应该是只能_，数字，字母组成，不可以是空格或者特殊字符(!@#$%^&amp;*~)，不能是数字开头，不能有中文。我们将“6-英语”的列名重命名为“english”。注意带上inplace=True参数用于更新作用于本数据集，而不是返回一个新的数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.rename(columns=&#123;<span class="string">'6-英语'</span>:<span class="string">'english'</span>&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line">df.query(<span class="string">'english &gt; 95'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/42e0aec53edb418c9844fda59025384f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="重命名"><br>可以看到“6-英语”列名改成了“english”，并且df.query(‘english &gt; 95’)不报错，可以正常检索出数据了。<br>更多的，如果要重命名多个列，可以传入一个需要重命名的多个字典值，进行多个列的重命名。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[[<span class="string">'1-学号'</span>,<span class="string">'2-姓名'</span>,<span class="string">'3-年龄'</span>]].rename(columns=&#123;<span class="string">'1-学号'</span>:<span class="string">'ID'</span>,<span class="string">'2-姓名'</span>:<span class="string">'name'</span>,<span class="string">'3-年龄'</span>:<span class="string">'age'</span>&#125;)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/128baee4f1a14f3b9ebdce0d57f5cb27.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="多个列重命名"></p><p>如果需要重命名行索引，可以通过df.rename(index={‘原索引’:’重命名索引’})的方式进行重命名。</p><p>至此，本文通过几个实例介绍了pandas常用的数据转换工具映射map()、替换replace()、重命名rename()</p><p>数据集及源代码见：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我们在数据处理的过程中经常碰到需要对数据进行转换的工作，比如将原来数据里的字典值根据字典转义成有意义的说明，将某些数据转换成其他的数据，将空值转换成其他值，将数据字段名进行重命名等。pandas作为数据处理分析的利器当然为上述的这些数据转换提供了便捷的方法。我们可以利用pa
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据分析之数据运算(逻辑运算、算术运算、统计运算、自定义运算)</title>
    <link href="https://xiejava.gitee.io/posts/f44191db/"/>
    <id>https://xiejava.gitee.io/posts/f44191db/</id>
    <published>2022-02-03T05:05:46.000Z</published>
    <updated>2022-02-03T05:07:21.447Z</updated>
    
    <content type="html"><![CDATA[<p>数据分析离不开数据运算，在介绍完pandas的数据加载、排序和排名、数据清洗之后，本文通过实例来介绍pandas的常用数据运算，包括逻辑运算、算术运算、统计运算及自定义运算。</p><h1 id="一、逻辑运算"><a href="#一、逻辑运算" class="headerlink" title="一、逻辑运算"></a>一、逻辑运算</h1><p>逻辑运算是程序代码中经常用到的一种运算。pandas的逻辑运算与Python基础语法中的逻辑运算存在一些差异。pandas的逻辑运算主要用于条件过滤根据条件逻辑运算得出的结果过滤检索出相应的数据。<br>我们来看一些例子：<br>数据集为学生数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df = pd.read_excel(<span class="string">'D:\\Python\\study\\pythontest\\pandastest\\数据集\\student.xlsx'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/165443b3e5184f3f8bec6762a3b15c0a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="学生数据集"><br>我们要过滤检索出语文成绩大于95分的数据，通过<code>df[&#39;4-语文&#39;]&gt;95</code>的条件语句，可以得到一个结果为bool值的Series，True表示满足语文成绩&gt;95分的，False表示不满足语文成绩&gt;95的。<br>在pandas中，将Series与数值进行比较，会得到一个与自身形状相同且全为布尔值的Series，每个位置的布尔值对应该位置的比较结果。<br>这种进行比较的代码，返回值是布尔值，是一种布尔表达式，也可以被称为逻辑语句，只要代码返回的结果是布尔值，都可以把代码当成逻辑语句。<br><img src="https://img-blog.csdnimg.cn/e69800e180c14afaa4e8ad091047c63b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="语文大于95的逻辑运算"><br>根据逻辑语句的布尔值，可以用来对数据进行筛选，按我们的需要从大量数据中过滤出目标数据。如我们要过滤出语文成绩大于95的数据，就可以用上述逻辑语句的布尔值进行筛选。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df[<span class="string">'4-语文'</span>]&gt;<span class="number">95</span>]</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b6f335ea42a84b36a9ae1f658a905ffe.png#pic_center" alt="语文大于95的结果"></p><p>除了直接的比较，pandas中有很多函数都会返回布尔值，如all()，any()，isna()等对整个DataFrame或Series的判断结果，eq()，ne()，lt()，gt()等比较函数的结果，都是布尔值。<br>逻辑语句是为逻辑运算服务的，可以直接作为判断条件。在复杂的逻辑关系中，需要使用复合逻辑运算，用逻辑运算符来连接多个逻辑语句，复合逻辑运算包含：逻辑与&amp;、逻辑或|、逻辑非~。</p><h2 id="逻辑与-amp"><a href="#逻辑与-amp" class="headerlink" title="逻辑与&amp;"></a>逻辑与&amp;</h2><p>pandas中用符号 &amp; 表示逻辑与，连接两个逻辑语句，同时为真才为真。在Python基本语法中，使用 and 表示逻辑与，但是Pandas中只能用 &amp; ，不能用and，会报模糊错误。<br>如我们要检索出一班并且语文成绩大于95的数据。可以用 <code>df[(df[&#39;4-语文&#39;]&gt;95) &amp; (df[&#39;班级&#39;]==&#39;一班&#39;)]</code><br>注意两个条件逻辑语句要分别用()括起来然后再用逻辑运算符进行运算。<br><img src="https://img-blog.csdnimg.cn/12811a4b89ac45b4868e756228183915.png#pic_center" alt="逻辑与&amp;"></p><h2 id="逻辑或"><a href="#逻辑或" class="headerlink" title="逻辑或|"></a>逻辑或|</h2><p>pandas中用符号 | 表示逻辑或，连接两个逻辑语句，只要其中一个为真就为真。<br>在Python基本语法中，使用 or 表示逻辑或，但是Pandas中只能用 | ，不能用or。<br>如我们要检索出语文成绩大于95或英语成绩大于96的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">'4-语文'</span>]&gt;<span class="number">95</span>)|(df[<span class="string">'6-英语'</span>]&gt;<span class="number">96</span>)]</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/10e77ba0b0b44aceb3681be3c930f045.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="逻辑或|"></p><h2 id="逻辑非"><a href="#逻辑非" class="headerlink" title="逻辑非~"></a>逻辑非~</h2><p>pandas中用符号 ~ 表示逻辑非，对逻辑语句取反。<br>在Python基本语法中，使用 not 表示逻辑非，但是Pandas中只能用 ~ ，不能用not。<br>如我们要检索出数据成绩&gt;98并且不是一班的同学</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">'5-数学'</span>]&gt;<span class="number">98</span>) &amp; ~(df[<span class="string">'班级'</span>]==<span class="string">'一班'</span>)]</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/f2591c50f3d747b58e7e4750c6e993aa.png#pic_center" alt="逻辑非~"></p><p>当然也可以用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[(df[<span class="string">'5-数学'</span>]&gt;<span class="number">98</span>) &amp; (df[<span class="string">'班级'</span>]!=<span class="string">'一班'</span>)]</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/eae9e964b0b7436486165af022d3084c.png#pic_center" alt="逻辑不等于"></p><h1 id="二、算术运算"><a href="#二、算术运算" class="headerlink" title="二、算术运算"></a>二、算术运算</h1><p>pandas最重要的一个功能是，它可以对不同索引的对象进行算术运算也就是（+、-、*、\）。<br>常见的算术云算是加法+运算，如果相加的对象是标量，则数据对象通过广播机制，每个数据值都+标量。如果相加的对象是数据对象则按索引进行算术运算。<br>通过一个数据集来看一下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data1=pd.DataFrame(np.arange(<span class="number">16</span>).reshape((<span class="number">4</span>,<span class="number">4</span>)),columns=[<span class="string">'列1'</span>,<span class="string">'列2'</span>,<span class="string">'列3'</span>,<span class="string">'列4'</span>])</span><br><span class="line">data1</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/78e20073ab2b4efbb2aa11947b0a3ddf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据运算数据集"></p><h2 id="1、使用算术运算符"><a href="#1、使用算术运算符" class="headerlink" title="1、使用算术运算符"></a>1、使用算术运算符</h2><p>和标量计算，标量运算会在算术运算过程中传播。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data2=data1+<span class="number">1</span></span><br><span class="line">data2</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/6b1aa153243a4f1eb9341bd508470dc0.png#pic_center" alt="加标量"><br>可以看到数据集中每个值都+1了<br>和索引相同的数据对象运算，对每个数据值进行算术运算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data3=pd.DataFrame(np.arange(<span class="number">16</span>).reshape((<span class="number">4</span>,<span class="number">4</span>)),columns=[<span class="string">'列1'</span>,<span class="string">'列2'</span>,<span class="string">'列3'</span>,<span class="string">'列4'</span>])</span><br><span class="line">data4=data2+data3</span><br><span class="line">data4</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/d0fbbb4f8e39444cad7c58013b6d7862.png#pic_center" alt="DataFrame相加"></p><p>在将对象相加时，如果存在不同的索引就是该索引对的并集。自动的数据对齐操作在不重叠的索引引入NA值。缺失值会在算术运算过程中传播。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data5=pd.DataFrame(np.ones([<span class="number">3</span>,<span class="number">3</span>]),columns=[<span class="string">'列1'</span>,<span class="string">'列2'</span>,<span class="string">'列3'</span>])</span><br><span class="line">data5</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ee24e1fd53b34fc390af6e04093ed363.png#pic_center" alt="全为1的数据集"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data6=data4+data5</span><br><span class="line">data6</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/9231187b1e724d4bbc2c56c7da8e91d3.png#pic_center" alt="形状不同的数据集相加"></p><h2 id="2、使用算数运算函数"><a href="#2、使用算数运算函数" class="headerlink" title="2、使用算数运算函数"></a>2、使用算数运算函数</h2><p>算数运算函数包括add、sub、div、mul等对应于算术运算符如下：</p><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>add,radd</td><td>用于加法（+）的方法</td></tr><tr><td>sub,rsub</td><td>用于减法（- ）的方法</td></tr><tr><td>div,rdiv</td><td>用于除法（/）的方法</td></tr><tr><td>floordiv,rfloordiv</td><td>用于底除（//）的方法</td></tr><tr><td>mul,rmul</td><td>用于乘法（* ）的方法</td></tr><tr><td>pow,rpow</td><td>用于指数（**）的方法</td></tr></tbody></table><h3 id="加法："><a href="#加法：" class="headerlink" title="加法："></a>加法：</h3><p>在对不同索引的对象进行算术运算时，如果希望当一个对象中某个轴标签在另一个对象中找不到时填充一个特殊值比如0，可以通过算术方法进行填充，然后再相加。<br><img src="https://img-blog.csdnimg.cn/948706b73b834294b8ea720e9eaa434c.png#pic_center" alt="加法函数"><br>上面的例子展示了，因为data5的行索引为3和列索引为列4用0填充后再相加所以行索引为3和列索引为列4的值是data4的值+0</p><h3 id="减法："><a href="#减法：" class="headerlink" title="减法："></a>减法：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data4.sub(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/45161a0068d54041a02e414c27e0deb7.png#pic_center" alt="sub函数"></p><h3 id="乘法："><a href="#乘法：" class="headerlink" title="乘法："></a>乘法：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data4.mul(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8e656f5db7204caba4b634dc59fbbc93.png#pic_center" alt="mul函数"></p><h3 id="除法："><a href="#除法：" class="headerlink" title="除法："></a>除法：</h3><p><img src="https://img-blog.csdnimg.cn/eff946f3fcbb47ab9feea24d9357b095.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="div函数"></p><h1 id="三、统计运算"><a href="#三、统计运算" class="headerlink" title="三、统计运算"></a>三、统计运算</h1><p>统计运算就是我们常用的数据集的求和、算平均值、最大值、最小值、绝对值、标准差等统计数据。在pandas中提供了丰富的统计函数可以方便的进行统计运算。</p><h2 id="1、describe汇总描述统计"><a href="#1、describe汇总描述统计" class="headerlink" title="1、describe汇总描述统计"></a>1、describe汇总描述统计</h2><p>通过np.random.randn(1000,4)生成1000个正态分布的随机数据集看一下describe的汇总描叙统计。<br>包含了数据个数count、均值mean、标准差std、最小值min、最大值等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1000个正态分布的随机数统计信息</span></span><br><span class="line">data=pd.DataFrame(np.random.randn(<span class="number">1000</span>,<span class="number">4</span>))</span><br><span class="line">data.describe()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/6ef0a223ba2c49cea4f7386839c1998f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="describe汇总描述统计"></p><h2 id="2、统计函数"><a href="#2、统计函数" class="headerlink" title="2、统计函数"></a>2、统计函数</h2><p>pandas常用统计函数如下：<br><img src="https://img-blog.csdnimg.cn/80b3d851a7294c44b7523a9eb9a22bd3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="常用统计函数"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.max()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/fa0ca68d2277473586de6ec2e089e47a.png#pic_center" alt="max函数"></p><p>可以算出DataFrame中每一列的最大值</p><p>如果只需要计算某一列的最大值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="number">1</span>].max()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/4e11735cfe58470f91b72a915de7886b.png#pic_center" alt="计算某一列的最大值"></p><p>对单个函数进行统计的时候，坐标轴还是按照这些默认为columns(axis=0, default)，如果要对index进行统计，则要指明(axis=1) 这里的axis取值与axis=0对应index，axis=1对应columns不同</p><ul><li>使用0值表示沿着每一列或行标签\索引值向下执行方法</li><li>使用1值表示沿着每一行或者列标签模向执行对应的方法<br><img src="https://img-blog.csdnimg.cn/3827ea96c8724e879da33ce993bb1240.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="axis=1"></li></ul><p>如果要计算某一行的最大值<br>用<code>data.loc[0].max()</code>，通过loc[]检索出需要统计的行，再用统计函数进行统计<br><img src="https://img-blog.csdnimg.cn/f8c7621c31d14cfc8fca280df90e9081.png#pic_center" alt="计算某一行的最大值"><br>累计统计cumsum,计算前n个数的和<br><img src="https://img-blog.csdnimg.cn/3fe08e6ee5b64162bbfc25f6f5ab44ec.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="计算前n个数的和"></p><h1 id="四、自定义运算"><a href="#四、自定义运算" class="headerlink" title="四、自定义运算"></a>四、自定义运算</h1><p>如果常用的统计运算还不能满足，pandas提供了方法可以进行自定义运算。</p><p> apply(func, axis=0)</p><ul><li>func – 自定义函数 axis=0 – 默认是列（按行标签方向执行方法）</li><li>axis=1为对行进行运算（按列标签方向执行方法）</li></ul><p>如：自定义一个对列求max-min的函数<br><img src="https://img-blog.csdnimg.cn/9c3f83e3362e4fbd98ca97692a2c730a.png#pic_center" alt="head()"><br>通过lambda匿名函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.apply(<span class="keyword">lambda</span> x: x.max() - x.min()) <span class="comment"># lambda为匿名函数，x为自变量，冒号后面为函数表达式</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/5faf44ec89af43068ad3524f46fd1ee3.png#pic_center" alt="lambda匿名函数"></p><p>通过自定义函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#自定义函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxdivmin</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x.max()-x.min()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/0c8d377e7cfb47189c03ee52257fc215.png#pic_center" alt="自定义函数"><br>至此，本文通过实例简单介绍了pandas数据分析的数据运算包括逻辑运算、算术运算、统计运算、自定义运算，也是平时在实际应用中常用的运算。</p><p>数据集及源代码见：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据分析离不开数据运算，在介绍完pandas的数据加载、排序和排名、数据清洗之后，本文通过实例来介绍pandas的常用数据运算，包括逻辑运算、算术运算、统计运算及自定义运算。&lt;/p&gt;
&lt;h1 id=&quot;一、逻辑运算&quot;&gt;&lt;a href=&quot;#一、逻辑运算&quot; class=&quot;head
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据清洗之处理缺失、重复、异常数据</title>
    <link href="https://xiejava.gitee.io/posts/a87a78e2/"/>
    <id>https://xiejava.gitee.io/posts/a87a78e2/</id>
    <published>2022-02-02T01:55:55.000Z</published>
    <updated>2022-02-02T01:58:21.527Z</updated>
    
    <content type="html"><![CDATA[<p>在数据分析和建模的过程中，有相当多的时间要用在数据准备上：加载、清理、转换以及重塑。这些工作会占到分析师时间的80%或更多。幸运的是pandas和内置的Python标准库提供了高效、灵活的工具可以帮助我们轻松的做这些事情。</p><p>本文重点介绍通过pandas进行数据的清洗。数据处理中的清洗工作主要包括对需要分析的数据集中的缺失值（空值）、重复值、异常值的处理。对于数据清洗一般也是分两个步骤，第一步就是要很方便快速的找到需要处理的数据，如何快速找到数据中的缺失值（空值）、重复数据或异常的数据，第二步是对找到的数据根据自己的实际使用需求进行处理，如删除还是替换成其他的数据。<br><img src="https://img-blog.csdnimg.cn/1013415fe61e4504be7a584b42f12daf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_8,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="pandas数据清洗"></p><h1 id="一、处理缺失值"><a href="#一、处理缺失值" class="headerlink" title="一、处理缺失值"></a>一、处理缺失值</h1><p>在许多数据分析工作过程中，由于对数据质量问题，缺失数据是经常发生的。对于数值数据，pandas使用浮点值NaN(Not a Number)表示缺失数据。在pandas中，还采用了R语言中惯用的缺失值表示法NA，它表示不可用not available。在统计应用中，NA数据可能是不存在的数据或虽然存在但是看不到。进行数据清洗对缺失数据进行分析，以判断数据采集的问题或缺失数据导致的偏差。</p><h2 id="1、判断缺失值（空值）"><a href="#1、判断缺失值（空值）" class="headerlink" title="1、判断缺失值（空值）"></a>1、判断缺失值（空值）</h2><p>在pandas中通过isna()或isnull()方法判断空值，二者等价，用于判断一个series或dataframe各元素值是否为空的bool结果。需注意对空值的界定：即None或numpy.nan才算空值，而空字符串、空列表等则不属于空值；类似地，notna()和notnull()则用于判断是否非空。<br>看下实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">stud_data=pd.Series([<span class="string">'张三'</span>,<span class="string">'李四'</span>,np.nan,[],<span class="string">''</span>,<span class="literal">None</span>,<span class="string">'王五'</span>])</span><br><span class="line">stud_data</span><br></pre></td></tr></table></figure><p>通过stud_data.isnull()和stud_data.isna()分别来判断空值<br><img src="https://img-blog.csdnimg.cn/5e5303378e084de8b8326c3a55d61d4a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="判断空值"></p><p>类似地，notna()和notnull()则用于判断是否非空<br><img src="https://img-blog.csdnimg.cn/24a955afccac4e9199e31fb91e3eb3d1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_10,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="判断是否非空"><br>同样的对于DataFrame中的缺失数据判断也是一样的。<br>构建DataFrame</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stud_df=pd.DataFrame(stud_data,columns=[<span class="string">'student_name'</span>])</span><br><span class="line">stud_df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/aa151caaefd54026927b43521b3e89af.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="DataFrame中的缺失数据判断"></p><p>对于缺失值的处理有两种常用的方式，一是用按一定的策略对空值进行填充，二是对于缺失值干脆进行删除。</p><h2 id="2、填充缺失值（空值）"><a href="#2、填充缺失值（空值）" class="headerlink" title="2、填充缺失值（空值）"></a>2、填充缺失值（空值）</h2><p>pandas中用户填充缺失值的方法是fillna()，可以按一定的策略对空值进行填充，如常数填充、向前/向后填充等，也可通过inplace参数确定是否本地更改。</p><h3 id="1-常量填充"><a href="#1-常量填充" class="headerlink" title="1.常量填充"></a>1.常量填充</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stud_df[[<span class="string">'student_name'</span>]].fillna(<span class="string">'某某'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8b7c06b63b544d7698ceba74dd2cfe24.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="常量填充"></p><p>可以看到判断为缺失值的地方都填充了”某某”，因为空字符串和空列表都不是缺失值，所以没有填充。</p><h3 id="2-向前和向后填充NA"><a href="#2-向前和向后填充NA" class="headerlink" title="2.向前和向后填充NA"></a>2.向前和向后填充NA</h3><p>通过fillna(mathod=’ffill’)，mathod=’ffill’ 向前填充和 mathod=’bfill’ 向后填充，也就是说用前面的值来填充NA或用后面的值来填充NA<br>我们来增加一列性别列gender来看一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stud_gender_data=pd.Series([<span class="number">1</span>,<span class="number">0</span>,np.nan,<span class="string">'女'</span>,<span class="number">1</span>,<span class="literal">None</span>,<span class="string">'男'</span>])</span><br><span class="line">stud_df[<span class="string">'gender'</span>]=stud_gender_data</span><br><span class="line">stud_df</span><br><span class="line">stud_df[[<span class="string">'gender'</span>]].fillna(method=<span class="string">'ffill'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/4347d66cbf6145e284457cf6dd72baf0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="向前和向后填充NA"></p><p>可以看到通过method=’ffill’，将NaN和None前面的值填充端到了NaN和None。<br>用fillna()进行填充会返回一个填充好的数据集的副本，并没有对原始数据进行操作，如果要修改原始数据可以通过inplace参数确定是否本地更改。<br><img src="https://img-blog.csdnimg.cn/57011ee8f66a472a94ce0af4fa5f3ee4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="通过inplace参数确定是否本地更改"></p><h2 id="3、删除缺失值（空值）"><a href="#3、删除缺失值（空值）" class="headerlink" title="3、删除缺失值（空值）"></a>3、删除缺失值（空值）</h2><p>如果想删除缺失值，那么使用 dropna() 函数与参数 axis 可以实现。在默认情况下，按照 axis=0 来按行处理，这意味着如果某一行中存在 NaN 值将会删除整行数据。如果在dropna()中传入<code>how=&#39;all&#39;</code>将只会删除全为NA或NaN的行。示例如下：<br><img src="https://img-blog.csdnimg.cn/0eed969515fe431e86b7a17cb7c6ec05.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="删除缺失值（空值）"></p><h1 id="二、处理重复值"><a href="#二、处理重复值" class="headerlink" title="二、处理重复值"></a>二、处理重复值</h1><p>重复数据也是在实际数据处理过程中碰到比较多的，处理重复数据就是在数据集中找出重复数据然后将其删除保留一个唯一不重复的数据。</p><h2 id="1、检测重复值"><a href="#1、检测重复值" class="headerlink" title="1、检测重复值"></a>1、检测重复值</h2><p>pandas通过duplicated()方法检测各行是否重复，返回一个行索引的bool结果，可通过keep参数设置保留第一行、最后一行、无保留，例如keep=first意味着在存在重复的多行时，首行被认为是合法的而可以保留。<br>构造一个DataFrame来看一个实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data=pd.DataFrame(&#123;<span class="string">'key1'</span>:[<span class="string">'A'</span>,<span class="string">'B'</span>]*<span class="number">3</span>+[<span class="string">'B'</span>],<span class="string">'key2'</span>:[<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>]&#125;)</span><br><span class="line">data</span><br><span class="line">data.duplicated()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e4e8559ffcf14f718f72f6a93f7d4c86.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="检测重复值"></p><h2 id="2、删除重复值"><a href="#2、删除重复值" class="headerlink" title="2、删除重复值"></a>2、删除重复值</h2><p>pandas通过drop_duplicates()方法按行检测并删除重复的记录，也可通过keep参数设置保留项。由于该方法默认是按行进行检测，如果存在某个需要需要按列删除，则可以先转置再执行该方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.drop_duplicates()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/0b23707f00c84944a6eb1b417eb51e95.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_9,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="删除重复值"><br>可以看到第7行也就是index为6的重复行被删除了。<br>当带了<code>keep=&#39;last&#39;</code>参数时，保留最后一个重复项，前面的重复项将被丢弃。可以看到保留的是索引为6的，索引为5的重复项被丢弃了。<br><img src="https://img-blog.csdnimg.cn/16068ab867b04514b64a628d8b69f7e4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="保留最后一个重复项"></p><h1 id="三、处理异常值"><a href="#三、处理异常值" class="headerlink" title="三、处理异常值"></a>三、处理异常值</h1><h2 id="1、判断异常值"><a href="#1、判断异常值" class="headerlink" title="1、判断异常值"></a>1、判断异常值</h2><p>判断异常值的标准依赖具体分析数据，如大于或小于某个基线范围的值。<br>我们来看一个含有正态分布的DataFrame数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data=pd.DataFrame(np.random.randn(<span class="number">1000</span>,<span class="number">4</span>))</span><br><span class="line">data.describe()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/035abbd8a84e464da0b9a3c26e9db1df.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="含有正态分布的DataFrame数据集"></p><p>假设我们认为某列中绝对值大小超过3的是异常值，那么判断异常值就是要找出某列中大小超过3的值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[np.abs(col)&gt;<span class="number">3</span>]</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/632fe5b430da4aeabf8ce886d9e833e5.png#pic_center" alt="找出某列中大小超过3的值"></p><p>要选出全部含有绝对值大小超过3的行，可以在布尔型DataFrame中使用any()方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[(np.abs(data)&gt;<span class="number">3</span>).any(<span class="number">1</span>)]</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/4e076b66d0be430689a36f0ae2568742.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="全部含有绝对值大小超过3的行"></p><h2 id="2、替换异常值"><a href="#2、替换异常值" class="headerlink" title="2、替换异常值"></a>2、替换异常值</h2><p>对于异常值，可以直接替换。<br>如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[np.abs(data)&gt;<span class="number">3</span>]=np.sign(data)*<span class="number">3</span></span><br></pre></td></tr></table></figure><p>这样就可以将异常值替换为绝对值不大于3的<br><img src="https://img-blog.csdnimg.cn/db6fd6434ca948fd8485a2aafe8f031c.png#pic_center" alt="替换异常值"></p><h2 id="3、删除异常值"><a href="#3、删除异常值" class="headerlink" title="3、删除异常值"></a>3、删除异常值</h2><p>删除异常值，可以用pandas的drop()方法，接受参数在特定轴线执行删除一条或多条记录，可通过axis参数设置是按行删除还是按列删除<br>如删除第3列，列索引为2的列中绝对值&gt;3的行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">col=data[<span class="number">2</span>]</span><br><span class="line">data.drop(data[np.abs(col)&gt;<span class="number">3</span>].index,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ab8dbd69ba3d4da2a94d77d280c36dcb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="删除异常值"></p><p>可以看到本来有1000行的，删除了3行，再用data[np.abs(col)&gt;3]验证，已经找不到数据了。</p><p>至此，本文通过实例介绍了pandas进行数据清洗包括缺失值、重复值及异常值的处理。数据清洗是数据分析前面的准备工作，数据质量的好坏将直接影响数据分析的结果。</p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在数据分析和建模的过程中，有相当多的时间要用在数据准备上：加载、清理、转换以及重塑。这些工作会占到分析师时间的80%或更多。幸运的是pandas和内置的Python标准库提供了高效、灵活的工具可以帮助我们轻松的做这些事情。&lt;/p&gt;
&lt;p&gt;本文重点介绍通过pandas进行数据
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据分析之排序和排名(sort和rank)</title>
    <link href="https://xiejava.gitee.io/posts/16c9fc17/"/>
    <id>https://xiejava.gitee.io/posts/16c9fc17/</id>
    <published>2022-01-30T01:14:37.000Z</published>
    <updated>2022-01-30T01:55:55.089Z</updated>
    
    <content type="html"><![CDATA[<p>对数据集进行排序和排名的是常用最基础的数据分析手段，pandas提供了方便的排序和排名的方法，通过简单的语句和参数就可以实现常用的排序和排名。</p><p>本文以student数据集的DataFrame为例来演示和介绍pandas数据分析之排序和排名(sort和rank)。<br>数据集内容如下，包括学生的学号、姓名、年龄及语文、数学、英语的成绩：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df = pd.read_excel(<span class="string">'D:\\Python\\study\\pythontest\\pandastest\\数据集\\student.xlsx'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/50b98632593d4d96bc9d95d0914ba377.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="student数据集"><br>数据集及源代码见：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><h1 id="一、排序"><a href="#一、排序" class="headerlink" title="一、排序"></a>一、排序</h1><p>对数据集进行排序是是常用的数据分析需求之一。pandas提供了按 索引标签排序sort_index()和按值排序sort_values()两种排序方法。对于DataFrame，可以根据任意一个轴上的索引标签进行排序。默认顺序排序，也可以设置按倒序排序。</p><h2 id="1、按标签排序"><a href="#1、按标签排序" class="headerlink" title="1、按标签排序"></a>1、按标签排序</h2><h3 id="1）按行标签索引排序"><a href="#1）按行标签索引排序" class="headerlink" title="1）按行标签索引排序"></a>1）按行标签索引排序</h3><p>pandas默认按行标签索引顺序排序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按行索引排序</span></span><br><span class="line">df.sort_index()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/7f59ca64cf504f0a81269276187a4ae9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="按行索引排序"><br>可以通过设置<code>ascending=False</code>参数进行倒序排序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按行索引倒序排序</span></span><br><span class="line">df.sort_index(ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/62cc7ea3d992450ea8c69e1552605427.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="按行索引倒序排序"></p><h3 id="2）按列标签索引排序"><a href="#2）按列标签索引排序" class="headerlink" title="2）按列标签索引排序"></a>2）按列标签索引排序</h3><p>通过给 axis 轴参数传递 0 或 1，可以对列标签进行排序。默认情况下，axis=0 表示按行排序；而 axis=1 则表示按列排序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按列索引排序</span></span><br><span class="line">df.sort_index(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/555275e9780b4b9d911350ebf691b561.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="按列索引排序"><br>同样可以设置ascending=False参数进行倒序排序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按列索引倒序排序</span></span><br><span class="line">df.sort_index(axis=<span class="number">1</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/2b8e879e51f94dfa8ed66013d5b46ebf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="按列索引倒序排序"></p><h2 id="2、按值排序"><a href="#2、按值排序" class="headerlink" title="2、按值排序"></a>2、按值排序</h2><p>在实际应用中用得最多的应该是根据某一列的值进行排序。在pandas中可以通过sort_value()，在sort_value中可以设定按某个列排序，也可以通过sort_value(by=[])，通过设置by=[‘a’,’b’]列表来指定多个需要排序的列。</p><h3 id="1）对单个列的值排序"><a href="#1）对单个列的值排序" class="headerlink" title="1）对单个列的值排序"></a>1）对单个列的值排序</h3><p>如在数据集中对语文成绩进行排序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按语文成绩排序</span></span><br><span class="line">df.sort_values(<span class="string">'4-语文'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20590ee5b8ed45e69ec3f8936dadaba7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="对语文成绩进行排序"></p><h3 id="2）对多个列的值进行排序"><a href="#2）对多个列的值进行排序" class="headerlink" title="2）对多个列的值进行排序"></a>2）对多个列的值进行排序</h3><p>通过设置by=[‘a’,’b’]列表来指定多个需要排序的列。<br>如对数据集中的语文和数学进行排序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按语文、数学排序</span></span><br><span class="line">df.sort_values(by=[<span class="string">'4-语文'</span>,<span class="string">'5-数学'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/4137cab46c284d499f180dae9f32bdc2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="对数据集中的语文和数学进行排序"></p><h2 id="3、排序算法"><a href="#3、排序算法" class="headerlink" title="3、排序算法"></a>3、排序算法</h2><p>sort_values() 提供了参数kind用来指定排序算法。这里有三种排序算法：</p><ul><li>mergesort（归并排序） </li><li>heapsort（堆排序） </li><li>quicksort（快速排序）</li></ul><p>默认为 quicksort(快速排序) ，其中 mergesort归并排序是最稳定的算法。<br>具体用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按语文、数学用mergesort归并排序算法排序</span></span><br><span class="line">df.sort_values(by=[<span class="string">'4-语文'</span>,<span class="string">'5-数学'</span>],kind=<span class="string">'mergesort'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8def3ea3da0048298166f0fff482ccca.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="排序算法"></p><h1 id="二、排名"><a href="#二、排名" class="headerlink" title="二、排名"></a>二、排名</h1><p>排名和排序的区别在于排序一定是有顺序，而排名分先后并列。如在现实生活中相同的分数存在排名并列的情况。<br>在《使用python进行数据分析》一书中对rank排名的描述为：排名是指对数组从1到有效数据点总数分配名次的操作。Series和DataFrame的rank方法是实现排名的方法，默认情况下，rank是通过“为各组分配一个平均排名”的方式破坏平级关系。这段话讲得是什么鬼？其实就是在存在并列排名的时候采用一定的策略来打破这种关系。<br>排名中的平级关系打破方法有如下几种：</p><table><thead><tr><th>method</th><th>说明</th></tr></thead><tbody><tr><td>average</td><td>默认：在每个组中分配平均排名</td></tr><tr><td>min</td><td>对整个组使用最小排名</td></tr><tr><td>max</td><td>对整个组使用最大排名</td></tr><tr><td>first</td><td>按照值在数据中出现的次序分配排名</td></tr><tr><td>dense</td><td>类似于method=’min’,但组件排名总是加1，而不是一个组中的相等元素的数量</td></tr></tbody></table><p><strong>rank()函数原型：</strong><code>rank(axis=0, method: str = &#39;average&#39;, numeric_only: Union[bool, NoneType] = None, na_option: str = &#39;keep&#39;, ascending: bool = True, pct: bool = False)</code><br>这里method取值可以为’average’，’first’，’min’， ‘max’，’dense’，用来打破排名中的平级关系的。<br>光看这些说明还是比较难理解。下面通过实例来说明：</p><h2 id="1、默认average-排名"><a href="#1、默认average-排名" class="headerlink" title="1、默认average 排名"></a>1、默认average 排名</h2><p>在数据集中我们只取“学号”、“姓名”、“语文”，然后取“语文”的排名，默认average</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df_rank=df[[<span class="string">'1-学号'</span>,<span class="string">'2-姓名'</span>,<span class="string">'4-语文'</span>]].copy()</span><br><span class="line"><span class="comment">#按语文成绩进行rank的默认排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(ascending=<span class="literal">False</span>)</span><br><span class="line">df_rank.sort_values(by=<span class="string">'语文排名'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/213aa6cf088d48b69f48ac64845f4581.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="默认average 排名"></p><p>这个排名很奇怪，97分排名第一没有问题，居然没有第二名，三个96分排名均为3，还有两个90分排名为9.5。这是什么鬼？<br>原来这就是默认的“average”规则,成绩相同时，取顺序排名中所有名次之和除以该成绩的个数，如两个90分的名次为最后两名分别为9名和10名，即(9+10)/2=9.5，三个96分的名次分别为2、3、4 那么排名为（2+3+4)/3=9/3=3</p><h2 id="2、mothod-’min’的排名"><a href="#2、mothod-’min’的排名" class="headerlink" title="2、mothod=’min’的排名"></a>2、mothod=’min’的排名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按语文成绩进行min排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(method=<span class="string">'min'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line">df_rank.sort_values(by=<span class="string">'语文排名'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b289018016d448c6a59b03c6641ed06f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="按语文成绩进行min排名"></p><p>在这个排名中看到有3个并列为2的排名，但没有排名为3、4的，有两个排名为9的，但没有排名为10的。可以看出当method=“min”时，成绩相同的同学，取在顺序排名中最小的那个排名作为该值的排名，张三、王五、顾十三个同学都是96分排名分别为2、3、4，那么当method为min时，取2、3、4的最小的那个作为成绩为96的整体排名即第2名。因为有了三个2名，接下来就从5名开始，5、6、7、8，到了第9名又有两个同分数的取9、10的最小排名为9，所以有两个9名。</p><h2 id="3、mothod-’max’的排名"><a href="#3、mothod-’max’的排名" class="headerlink" title="3、mothod=’max’的排名"></a>3、mothod=’max’的排名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按语文成绩进行max排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(method=<span class="string">'max'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line">df_rank.sort_values(by=<span class="string">'语文排名'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/397162df3494435c9acde13fc286eee5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="按语文成绩进行max排名"><br>与min相反，成绩相同的同学，排名相同取顺序最大的排名，张三、王五、顾十三个同学都是96分排名分别为2、3、4，那么当method为min时，取2、3、4的最小的那个作为成绩为96的整体排名即第2名。当method为max时，取最大的4作为96分的整体排名，同理90分的取10为90分的整体排名。</p><h2 id="4、mothod-’first’的排名"><a href="#4、mothod-’first’的排名" class="headerlink" title="4、mothod=’first’的排名"></a>4、mothod=’first’的排名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按语文成绩进行first排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(method=<span class="string">'first'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line">df_rank.sort_values(by=<span class="string">'语文排名'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/dfda709d0192404abf719ca156906758.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="按语文成绩进行first排名"></p><p>first排名很好理解了，有点先到先得的意思，成绩相同，谁的索引排前，谁的排名就靠前，比如张三、王五、顾十 这三个同学都是96分，按理应该是并列第2，但张三的索引比王五和顾十的都靠前，王五的索引比顾十靠前，所以他们的顺序分别为2、3、4，同理陈一、钱七的分数都是90分，但陈一的索引比钱七靠前所以陈一排名为9、钱七排名第10</p><h2 id="5、mothod-’dense’的排名"><a href="#5、mothod-’dense’的排名" class="headerlink" title="5、mothod=’dense’的排名"></a>5、mothod=’dense’的排名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按语文成绩进行dense排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(method=<span class="string">'dense'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line">df_rank.sort_values(by=<span class="string">'语文排名'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/2156d32683ea43da8294df5329869bef.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="按语文成绩进行dense排名"><br>“dense”: 是密集的意思，也比较好理解，即相同成绩的同学排名相同，其他依次加1即可。可以看到张三、王五、顾十这三位同学都是96分，并列排名第2，后面的加1，即比他们分数稍低的赵六95分排名第3，后面依次。</p><h2 id="6、不同method的排名对比"><a href="#6、不同method的排名对比" class="headerlink" title="6、不同method的排名对比"></a>6、不同method的排名对比</h2><p>最后不同method的排名对比：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按语文成绩进行rank的默认排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名-average'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#按语文成绩进行min排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名-min'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(method=<span class="string">'min'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#按语文成绩进行max排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名-max'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(method=<span class="string">'max'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#按语文成绩进行first排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名-first'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(method=<span class="string">'first'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#按语文成绩进行dense排名</span></span><br><span class="line">df_rank[<span class="string">'语文排名-dense'</span>]=df_rank[<span class="string">'4-语文'</span>].rank(method=<span class="string">'dense'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line">df_rank.sort_values(by=<span class="string">'4-语文'</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c082acec2ed9426aa5af7cee47d3ac30.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="按语文成绩进行rank的默认排名"></p><p>数据集及源代码见：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对数据集进行排序和排名的是常用最基础的数据分析手段，pandas提供了方便的排序和排名的方法，通过简单的语句和参数就可以实现常用的排序和排名。&lt;/p&gt;
&lt;p&gt;本文以student数据集的DataFrame为例来演示和介绍pandas数据分析之排序和排名(sort和rank)
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据结构(Series和DataFrame)</title>
    <link href="https://xiejava.gitee.io/posts/531458d5/"/>
    <id>https://xiejava.gitee.io/posts/531458d5/</id>
    <published>2022-01-23T13:07:57.000Z</published>
    <updated>2022-02-02T01:57:57.437Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>无可非议，pandas是Python最强大的数据分析和探索工具之一，因金融数据分析工具而开发，支持类似于SQL语句的模型，可以对数据进行增删改查等操作，支持时间序列分析，也能够灵活的处理缺失的数据。它含有使数据分析工作变得更快更简单的高级数据结构和操作工具。pandas是基于NumPy构建的，让以NumPy为中心的应用变得更加简单。</p><p>这里所说的让pandas变得更快更简单的高级数据结构就是Series和DataFrame。要熟练使用pandas，首先得要熟悉它的这两个主要的数据结构：<strong>Series</strong>和<strong>DateFrame</strong>。</p><p>本文将针对Series和DateFrame，介绍Series和DataFrame数据对象的创建及基于数据对象的基础上对数据进行选择、增加、删除等数据操作。</p><h1 id="一、Series"><a href="#一、Series" class="headerlink" title="一、Series"></a>一、Series</h1><p>Series是一种类似于一维数组对象，它是由一组的数据值value（各种NumPy数据类型）以及一组与之相关的数据标签index（即索引）组成，其中标签与数据值之间是一一对应的关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">obj = pd.Series([<span class="string">'陈一'</span>,<span class="string">'周二'</span>,<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>,<span class="string">'赵六'</span>,<span class="string">'钱七'</span>,<span class="string">'孙八'</span>,<span class="string">'何九'</span>,<span class="string">'顾十'</span>])</span><br><span class="line">obj</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>    陈一</span><br><span class="line"><span class="number">1</span>    周二</span><br><span class="line"><span class="number">2</span>    张三</span><br><span class="line"><span class="number">3</span>    李四</span><br><span class="line"><span class="number">4</span>    王五</span><br><span class="line"><span class="number">5</span>    赵六</span><br><span class="line"><span class="number">6</span>    钱七</span><br><span class="line"><span class="number">7</span>    孙八</span><br><span class="line"><span class="number">8</span>    何九</span><br><span class="line"><span class="number">9</span>    顾十</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><p>Series的字符串表现形式为：索引在左边，值在右边。由于没有为数据指定索引，于是会自动创建一个0到N-1（N为数据的长度）的整数型索引。<br><img src="https://img-blog.csdnimg.cn/1a4a56b01582403abdfa33f45b1ba496.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="Serires数据结构"></p><p>可以通过Series的values和index属性获取其数组表示形式和索引对象。<br><img src="https://img-blog.csdnimg.cn/7430b9ace9584288a9495cb835f19b9e.png#pic_center" alt="通过Series的values和index属性获取其数组表示形式和索引对象"></p><p><strong>可以将Series看成一个定长的有序字典，因为它是索引值到数据值的一个映射。</strong></p><h2 id="1、Series对象创建"><a href="#1、Series对象创建" class="headerlink" title="1、Series对象创建"></a>1、Series对象创建</h2><p>pandas 使用 Series()  函数来创建 Series 对象，通过这个对象可以调用相应的方法和属性，从而达到处理数据的目的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">obj=pd.Series( data, index, dtype, copy)</span><br></pre></td></tr></table></figure><p>参数说明如下：</p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>data</td><td>输入的数据，可以是列表、常量、ndarray 数组等。</td></tr><tr><td>index</td><td>索引值必须是惟一的，如果没有传递索引，则默认为 np.arrange(n)。</td></tr><tr><td>dtype</td><td>dtype表示数据类型，如果没有提供，则会自动判断得出。</td></tr><tr><td>copy</td><td>表示对 data 进行拷贝，默认为 False。</td></tr></tbody></table><p>data可以是列表、常量、ndarray数组等，如果数据被存放在一个Python字典dict中，也可以直接通过这个dict来创建Series，如果没有传入索引时会按照字典的键来构造索引；反之，当传递了索引时需要将索引标签与字典中的值一一对应。<br>前面的列子是通过列表来创建的Series，接下来看下通过ndarray和dic来创建Series。</p><h3 id="通过ndarray创建Series"><a href="#通过ndarray创建Series" class="headerlink" title="通过ndarray创建Series"></a>通过ndarray创建Series</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ndarray创建Series</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data=np.array([<span class="string">'陈一'</span>,<span class="string">'周二'</span>,<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>,<span class="string">'赵六'</span>,<span class="string">'钱七'</span>,<span class="string">'孙八'</span>,<span class="string">'何九'</span>,<span class="string">'顾十'</span>])</span><br><span class="line">obj= pd.Series(data)</span><br><span class="line">print(obj)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>    陈一</span><br><span class="line"><span class="number">1</span>    周二</span><br><span class="line"><span class="number">2</span>    张三</span><br><span class="line"><span class="number">3</span>    李四</span><br><span class="line"><span class="number">4</span>    王五</span><br><span class="line"><span class="number">5</span>    赵六</span><br><span class="line"><span class="number">6</span>    钱七</span><br><span class="line"><span class="number">7</span>    孙八</span><br><span class="line"><span class="number">8</span>    何九</span><br><span class="line"><span class="number">9</span>    顾十</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h3 id="通过dict创建Series"><a href="#通过dict创建Series" class="headerlink" title="通过dict创建Series"></a>通过dict创建Series</h3><p>#通过dict创建Series,没有设置indx</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = &#123;<span class="string">'1'</span> :<span class="string">'张三'</span>, <span class="string">'2'</span> :<span class="string">'李四'</span>, <span class="string">'3'</span> : <span class="string">'王五'</span>&#125;</span><br><span class="line">obj=pd.Series(data)</span><br><span class="line">print(obj)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>    张三</span><br><span class="line"><span class="number">2</span>    李四</span><br><span class="line"><span class="number">3</span>    王五</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><p>当传递的索引值无法找到与其对应的值时，使用 NaN（非数字）填充。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过dict创建Series,设置indx</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = &#123;<span class="string">'1'</span> :<span class="string">'张三'</span>, <span class="string">'2'</span> :<span class="string">'李四'</span>, <span class="string">'3'</span> : <span class="string">'王五'</span>&#125;</span><br><span class="line">obj=pd.Series(data,index=[<span class="string">'1'</span>,<span class="string">'2'</span>,<span class="string">'4'</span>])</span><br><span class="line"><span class="comment">#索引4没有在dict的对应的key，所以使用NaN（非数字）填充</span></span><br><span class="line">print(obj)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>     张三</span><br><span class="line"><span class="number">2</span>     李四</span><br><span class="line"><span class="number">4</span>    NaN</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h2 id="2、Series操作"><a href="#2、Series操作" class="headerlink" title="2、Series操作"></a>2、Series操作</h2><h3 id="Series数据访问"><a href="#Series数据访问" class="headerlink" title="Series数据访问"></a>Series数据访问</h3><p>Series提供了多种数据访问的方式，可以通过位置下标及索引来访问数据，可以访问单个数据也可以访问多个数据。</p><h4 id="通过位置下标及索引来访问数据"><a href="#通过位置下标及索引来访问数据" class="headerlink" title="通过位置下标及索引来访问数据"></a>通过位置下标及索引来访问数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data=np.array([<span class="string">'陈一'</span>,<span class="string">'周二'</span>,<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>,<span class="string">'赵六'</span>])</span><br><span class="line">obj= pd.Series(data,index=[<span class="string">'一'</span>,<span class="string">'二'</span>,<span class="string">'三'</span>,<span class="string">'四'</span>,<span class="string">'五'</span>,<span class="string">'六'</span>])</span><br><span class="line">print(<span class="string">'obj的Series数据'</span>)</span><br><span class="line">print(obj)</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br><span class="line"><span class="comment">#位置下标访问</span></span><br><span class="line">print(<span class="string">'位置下标访问:obj[0]'</span>)</span><br><span class="line">print(obj[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br><span class="line"><span class="comment">#切片访问</span></span><br><span class="line">print(<span class="string">'位置切片访问多个元素值:obj[1:3]'</span>)</span><br><span class="line">print(obj[<span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br><span class="line"><span class="comment">#索引访问</span></span><br><span class="line">print(<span class="string">'索引访问:obj[obj.index==\'三\']'</span>)</span><br><span class="line">print(obj[obj.index==<span class="string">'三'</span>])</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br><span class="line"><span class="comment">#索引访问</span></span><br><span class="line">print(<span class="string">'索引访问:obj[\'一\']'</span>)</span><br><span class="line">print(obj[<span class="string">'一'</span>])</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br><span class="line"><span class="comment">#索引列表访问</span></span><br><span class="line">print(<span class="string">'索引列表访问多个元素值:obj[[\'二\',\'三\']]'</span>)</span><br><span class="line">print(obj[[<span class="string">'二'</span>,<span class="string">'三'</span>]])</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">obj的Series数据</span><br><span class="line">一    陈一</span><br><span class="line">二    周二</span><br><span class="line">三    张三</span><br><span class="line">四    李四</span><br><span class="line">五    王五</span><br><span class="line">六    赵六</span><br><span class="line">dtype: object</span><br><span class="line"></span><br><span class="line">位置下标访问:obj[<span class="number">0</span>]</span><br><span class="line">陈一</span><br><span class="line"></span><br><span class="line">位置切片访问多个元素值:obj[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">二    周二</span><br><span class="line">三    张三</span><br><span class="line">dtype: object</span><br><span class="line"></span><br><span class="line">索引访问:obj[obj.index==<span class="string">'三'</span>]</span><br><span class="line">三    张三</span><br><span class="line">dtype: object</span><br><span class="line"></span><br><span class="line">索引访问:obj[<span class="string">'一'</span>]</span><br><span class="line">陈一</span><br><span class="line"></span><br><span class="line">索引列表访问多个元素值:obj[[<span class="string">'二'</span>,<span class="string">'三'</span>]]</span><br><span class="line">二    周二</span><br><span class="line">三    张三</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h4 id="head-amp-tail-查看数据"><a href="#head-amp-tail-查看数据" class="headerlink" title="head()&amp;tail()查看数据"></a>head()&amp;tail()查看数据</h4><p>如果想要查看 Series 的某一部分数据，可以使用 head() 或者 tail() 方法。其中 head() 返回前 n 行数据，默认显示前 5 行数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data=np.array([<span class="string">'陈一'</span>,<span class="string">'周二'</span>,<span class="string">'张三'</span>,<span class="string">'李四'</span>,<span class="string">'王五'</span>,<span class="string">'赵六'</span>])</span><br><span class="line">obj= pd.Series(data,index=[<span class="string">'一'</span>,<span class="string">'二'</span>,<span class="string">'三'</span>,<span class="string">'四'</span>,<span class="string">'五'</span>,<span class="string">'六'</span>])</span><br><span class="line"><span class="comment">#输出前三行数据</span></span><br><span class="line">print(<span class="string">'输出前三行数据'</span>)</span><br><span class="line">print(obj.head(<span class="number">3</span>))</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br><span class="line"><span class="comment">#输出后两行数据</span></span><br><span class="line">print(<span class="string">'输出后两行数据'</span>)</span><br><span class="line">print(obj.tail(<span class="number">2</span>))</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输出前三行数据</span><br><span class="line">一    陈一</span><br><span class="line">二    周二</span><br><span class="line">三    张三</span><br><span class="line">dtype: object</span><br><span class="line"></span><br><span class="line">输出后两行数据</span><br><span class="line">五    王五</span><br><span class="line">六    赵六</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h3 id="Series数据增加"><a href="#Series数据增加" class="headerlink" title="Series数据增加"></a>Series数据增加</h3><h4 id="1-直接通过索引增加"><a href="#1-直接通过索引增加" class="headerlink" title="1.直接通过索引增加"></a>1.直接通过索引增加</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过索引增加数据</span></span><br><span class="line">obj[<span class="string">'十一'</span>]=<span class="string">'肖十一'</span></span><br><span class="line">print(obj)</span><br><span class="line"></span><br><span class="line">一      陈一</span><br><span class="line">二      周二</span><br><span class="line">三      张三</span><br><span class="line">四      李四</span><br><span class="line">五      王五</span><br><span class="line">六      赵六</span><br><span class="line">十一    肖十一</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h4 id="2-通过append-增加"><a href="#2-通过append-增加" class="headerlink" title="2.通过append()增加"></a>2.通过append()增加</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过append()增加多个数据</span></span><br><span class="line">obj2=pd.Series([<span class="string">'郭芙蓉'</span>,<span class="string">'杨过'</span>],index=[<span class="string">'十二'</span>,<span class="string">'十三'</span>])</span><br><span class="line">obj=obj.append(obj2)</span><br><span class="line">print(obj)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">一      陈一</span><br><span class="line">二      周二</span><br><span class="line">三      张三</span><br><span class="line">四      李四</span><br><span class="line">五      王五</span><br><span class="line">六      赵六</span><br><span class="line">十一    肖十一</span><br><span class="line">十二    郭芙蓉</span><br><span class="line">十三     杨过</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h3 id="Series数据修改"><a href="#Series数据修改" class="headerlink" title="Series数据修改"></a>Series数据修改</h3><p>Series数据可以通过制定索引直接修改<br>如：修改索引为十一的数据，直接obj[‘十一’]=’肖XX’，就可以进行修改。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改Series数据</span></span><br><span class="line">obj[<span class="string">'十一'</span>]=<span class="string">'肖XX'</span></span><br><span class="line">print(obj)</span><br><span class="line"></span><br><span class="line">一      陈一</span><br><span class="line">二      周二</span><br><span class="line">三      张三</span><br><span class="line">四      李四</span><br><span class="line">五      王五</span><br><span class="line">六      赵六</span><br><span class="line">十一    肖XX</span><br><span class="line">十二    郭芙蓉</span><br><span class="line">十三     杨过</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h3 id="Series数据删除"><a href="#Series数据删除" class="headerlink" title="Series数据删除"></a>Series数据删除</h3><p>通过drop()删除，<code>注意如果没有带inplace=True，会返回一个新的Series对象。如果要修改本对象，注意要带上inplace=True</code>。</p><h4 id="1-删除单个数据"><a href="#1-删除单个数据" class="headerlink" title="1.删除单个数据"></a>1.删除单个数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">obj.drop(<span class="string">'十一'</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">print(obj)</span><br><span class="line"></span><br><span class="line">一      陈一</span><br><span class="line">二      周二</span><br><span class="line">三      张三</span><br><span class="line">四      李四</span><br><span class="line">五      王五</span><br><span class="line">六      赵六</span><br><span class="line">十二    郭芙蓉</span><br><span class="line">十三     杨过</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h4 id="2-删除多个数据"><a href="#2-删除多个数据" class="headerlink" title="2.删除多个数据"></a>2.删除多个数据</h4><p>参数为索引列表，即可以删除索引为列表中的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">obj.drop([<span class="string">'十二'</span>,<span class="string">'十三'</span>],inplace=<span class="literal">True</span>)</span><br><span class="line">print(obj)</span><br><span class="line"></span><br><span class="line">一    陈一</span><br><span class="line">二    周二</span><br><span class="line">三    张三</span><br><span class="line">四    李四</span><br><span class="line">五    王五</span><br><span class="line">六    赵六</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h1 id="二、DataFrame"><a href="#二、DataFrame" class="headerlink" title="二、DataFrame"></a>二、DataFrame</h1><p>DataFrame 是 Pandas 的重要数据结构之一，也是在使用 Pandas 进行数据分析过程中最常用的结构之一。DataFrame 一个表格型的数据结构，既有行标签（index），又有列标签（columns），它也被称异构数据表，所谓异构，指的是表格中每列的数据类型可以不同，比如可以是字符串、整型或者浮点型等。DataFrame 的每一行数据都可以看成一个 Series 结构，只不过，DataFrame 为这些行中每个数据值增加了一个列标签。因此 DataFrame 其实是从 Series 的基础上演变而来。<strong>可以把DataFrame看做是关系型数据库里或Excel里的一张表格来理解</strong>。<br><img src="https://img-blog.csdnimg.cn/5d6b34b82d554bc2bfe87d9ccd9eee92.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="DataFrame数据结构"><br><strong>DataFrame 数据结构的特点：</strong><br>DataFrame 每一列的标签值允许使用不同的数据类型；<br>DataFrame 是表格型的数据结构，具有行和列；<br>DataFrame 中的每个数据值都可以被修改。<br>DataFrame 结构的行数、列数允许增加或者删除；<br>DataFrame 有两个方向的标签轴，分别是行标签和列标签；<br>DataFrame 可以对行和列执行算术运算。</p><h2 id="1、DataFrame对象的创建"><a href="#1、DataFrame对象的创建" class="headerlink" title="1、DataFrame对象的创建"></a>1、DataFrame对象的创建</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df=pd.DataFrame( data, index, columns, dtype, copy)</span><br></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th>参数名称</th><th>说明</th></tr></thead><tbody><tr><td>data</td><td>输入的数据，可以是 ndarray，series，list，dict，标量以及一个 DataFrame。</td></tr><tr><td>index</td><td>行标签，如果没有传递 index 值，则默认行标签是 np.arange(n)，n 代表 data 的元素个数。</td></tr><tr><td>columns</td><td>列标签，如果没有传递 columns 值，则默认列标签是 np.arange(n)。</td></tr><tr><td>dtype</td><td>dtype表示每一列的数据类型。</td></tr><tr><td>copy</td><td>默认为 False，表示复制数据 data。</td></tr></tbody></table><p>Pandas 提供了多种创建 DataFrame 对象的方式可以看data的参数说明，包括列表、ndarray、series、dict等。<br>平时在数据分析过程中用得最多的应该是从其他数据源文件如cvs、excel、数据库、WEBAPI等方式加载数据到DataFrame中。<br>如：从Excel中加载数据。更多的数据加载方式见：<a href="http://xiejava.ishareread.com/posts/4864590d/" target="_blank" rel="noopener">http://xiejava.ishareread.com/posts/4864590d/</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">'D:\\Python\\study\\pythontest\\pandastest\\数据集\\staff.xlsx'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/21aad8114af64eb8b845861d9567a6ee.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="staff数据集"></p><h2 id="2、DataFrame数据操作"><a href="#2、DataFrame数据操作" class="headerlink" title="2、DataFrame数据操作"></a>2、DataFrame数据操作</h2><p>DataFrame 可以使用行索引(index )来选取 DataFrame 中的数据并进行操作。也可以使用列索（columns ）引来完成数据的选取、添加和删除操作。</p><h3 id="1-行索引操作DataFrame"><a href="#1-行索引操作DataFrame" class="headerlink" title="1) 行索引操作DataFrame"></a>1) 行索引操作DataFrame</h3><h4 id="选取数据"><a href="#选取数据" class="headerlink" title="选取数据"></a>选取数据</h4><p>行标签选取数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#选取行标签为2的行</span></span><br><span class="line">df.loc[[<span class="number">2</span>]]</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8611f4d65f5e4c54ba9e0bc364b025cd.png#pic_center" alt="选取行标签为2的行"><br>注意：如果是df.loc[2]，同样是选择行标签为2的行，但现实效果为<br><img src="https://img-blog.csdnimg.cn/32903861c623425a926448af4b661aca.png#pic_center" alt="选取行标签为2的行"><br>因为df.loc[2]返回是Series对象，而df.loc[[2]]返回的是DataFrame对象</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">type(df.iloc[<span class="number">2</span>])</span><br><span class="line">pandas.core.series.Series</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">type(df.loc[[<span class="number">2</span>]])</span><br><span class="line">pandas.core.frame.DataFrame</span><br></pre></td></tr></table></figure><p>切片选取数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#切片选取数据（左闭右开）</span></span><br><span class="line">df[<span class="number">2</span>:<span class="number">4</span>]</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c913ea3b04ed47d99bcc056e155e7580.png#pic_center" alt="切片选取数据"></p><h4 id="增加行"><a href="#增加行" class="headerlink" title="增加行"></a>增加行</h4><p> 添加数据行，使用 append() 函数，可以将新的数据行添加到 DataFrame 中，该函数会在行末追加数据行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_1 = pd.DataFrame([[<span class="number">11</span>,<span class="string">'肖十一'</span>,<span class="string">'30'</span>,<span class="string">'女'</span>,<span class="string">'7000'</span>,<span class="string">'1'</span>],[<span class="number">12</span>,<span class="string">'郭芙蓉'</span>,<span class="string">'30'</span>,<span class="string">'女'</span>,<span class="string">'7400'</span>,<span class="string">'1'</span>]],index=[<span class="number">11</span>,<span class="number">12</span>],columns = [<span class="string">'staff_id'</span>,<span class="string">'staff_name'</span>,<span class="string">'staff_age'</span>,<span class="string">'staff_gender'</span>,<span class="string">'staff_salary'</span>,<span class="string">'staff_depatment_id'</span>])</span><br><span class="line">df=df.append(df_1)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a54e2f6025bc4b4f9edfa5000b30c5a6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt=" 添加数据行"></p><p>注意新增加的DataFrame如果没有指定行索引，将会默认从0开始，添加数据行后将会有行重复的行索引。如没有指定index=[11,12]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_1 = pd.DataFrame([[<span class="number">11</span>,<span class="string">'肖十一'</span>,<span class="string">'30'</span>,<span class="string">'女'</span>,<span class="string">'7000'</span>,<span class="string">'1'</span>],[<span class="number">12</span>,<span class="string">'郭芙蓉'</span>,<span class="string">'30'</span>,<span class="string">'女'</span>,<span class="string">'7400'</span>,<span class="string">'1'</span>]],columns = [<span class="string">'staff_id'</span>,<span class="string">'staff_name'</span>,<span class="string">'staff_age'</span>,<span class="string">'staff_gender'</span>,<span class="string">'staff_salary'</span>,<span class="string">'staff_depatment_id'</span>])</span><br><span class="line">df=df.append(df_1)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a9e83a1037144f4c8631dfeca1507b70.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="添加数据行有重复行索引"></p><h4 id="删除行"><a href="#删除行" class="headerlink" title="删除行"></a>删除行</h4><p>可以使用行索引标签，从 DataFrame 中删除某一行数据。如果索引标签存在重复，那么它们将被一起删除</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df=df.drop(<span class="number">0</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p>可以看到到行索引为0的两条记录被一起删除了。<br><img src="https://img-blog.csdnimg.cn/a6d8cb6d9e904199ac88f01adcab63ee.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="删除"></p><h3 id="2-列索引操作DataFrame"><a href="#2-列索引操作DataFrame" class="headerlink" title="2) 列索引操作DataFrame"></a>2) 列索引操作DataFrame</h3><h4 id="列索引选取数据列"><a href="#列索引选取数据列" class="headerlink" title="列索引选取数据列"></a>列索引选取数据列</h4><p>通过指定列索引来选取数据列，如选择只显示staff_id,staff_name,staff_gender三列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df2=df[[<span class="string">'staff_id'</span>,<span class="string">'staff_name'</span>,<span class="string">'staff_gender'</span>]]</span><br><span class="line">df2</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/13a54eedc4d04347bfbe055c9171842a.png#pic_center" alt="列索引选取数据列"></p><h4 id="列索引添加数据列"><a href="#列索引添加数据列" class="headerlink" title="列索引添加数据列"></a>列索引添加数据列</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df3=df[<span class="string">'staff_salary'</span>]+<span class="number">500</span></span><br><span class="line"><span class="comment">#在df的基础上增加append_cloume列，新增的append_cloume列为df['staff_salary']+500，即薪水加了500的列</span></span><br><span class="line">df[<span class="string">'append_cloume'</span>]=df3</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/2f978dd2838f4bd0b0e7f7dff654ec46.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="列索引添加数据列"></p><h4 id="列索引删除数据列"><a href="#列索引删除数据列" class="headerlink" title="列索引删除数据列"></a>列索引删除数据列</h4><p>通过del 来删除指定的数据列，如删除staff_depatment_id列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> df[<span class="string">'staff_depatment_id'</span>]</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b8de684aa6f8410b83b182ddfc29f294.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="列索引删除数据列"></p><p>本文介绍了pandas的两大核心数据结构Series和DataFrame，分别介绍了Series和DataFrame数据对象的创建及基于数据对象的基础上对数据进行选择、增加、删除等数据操作，可以加深对Series和DataFrame的理解，并可以将创建，增、删、改、查等应用于实际的数据处理应用中。</p><hr><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;无可非议，pandas是Python最强大的数据分析和探索工具之一，因金融数据分析工具而开发，支持类似于SQL语句的模型，可以对数据进行增删
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>pandas数据加载(csv、excel、json、mysql、webAPI)</title>
    <link href="https://xiejava.gitee.io/posts/4864590d/"/>
    <id>https://xiejava.gitee.io/posts/4864590d/</id>
    <published>2022-01-22T09:35:55.000Z</published>
    <updated>2022-02-02T01:58:09.925Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/f5fc706f84454eb49d5457d751025441.png#pic_center" alt="pandas"><br>pandas 是基于NumPy 的一种工具，该工具是为解决数据分析任务而创建的。Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。Pandas的名称来自于面板数据（panel data）和python数据分析（data analysis）。pandas提供了大量能使我们快速便捷地处理数据的函数和方法。它是使Python成为强大而高效的数据分析环境的重要因素之一。</p><p>数据的输入是数据分析的第一步，如果不能将数据快速方便的导入导出python，那么pandas不可能成为强大而高效的数据分析环境，本文重点介绍pandas的数据输入加载。pandas的数据输入可以划分为几个大类：读取文本文件和其他更高效的磁盘存储格式，加载数据库中的数据，利用Web API获取网络资源。<br><img src="https://img-blog.csdnimg.cn/27deba5956b842dda6f845149b98d426.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="pandas数据处理"><br>pandas的IO工具支持非常多的数据输入输出方式。包括csv、json、Excel、数据库等。</p><table><thead><tr><th>Format Type</th><th>Data Description</th><th>Reader</th><th>Writer</th></tr></thead><tbody><tr><td>text</td><td>CSV</td><td>read_csv</td><td>to_csv</td></tr><tr><td>text</td><td>JSON</td><td>read_json</td><td>to_json</td></tr><tr><td>text</td><td>HTML</td><td>read_html</td><td>to_html</td></tr><tr><td>text</td><td>Local clipboard</td><td>read_clipboard</td><td>to_clipboard</td></tr><tr><td>binary</td><td>MS Excel</td><td>read_excel</td><td>to_excel</td></tr><tr><td>binary</td><td>OpenDocument</td><td>read_excel</td><td></td></tr><tr><td>binary</td><td>HDF5 Format</td><td>read_hdf</td><td>to_hdf</td></tr><tr><td>binary</td><td>Feather Format</td><td>read_feather</td><td>to_feather</td></tr><tr><td>binary</td><td>Parquet Format</td><td>read_parquet</td><td>to_parquet</td></tr><tr><td>binary</td><td>Msgpack</td><td>read_msgpack</td><td>to_msgpack</td></tr><tr><td>binary</td><td>Stata</td><td>read_stata</td><td>to_stata</td></tr><tr><td>binary</td><td>SAS</td><td>read_sas</td><td></td></tr><tr><td>binary</td><td>Python Pickle Format</td><td>read_pickle</td><td>to_pickle</td></tr><tr><td>SQL</td><td>SQL</td><td>read_sql</td><td>to_sql</td></tr><tr><td>SQL</td><td>Google Big Query</td><td>read_gbq</td><td>to_gbq</td></tr></tbody></table><p>本文通过几个实例，介绍几种常用的数据加载方式，包括从csv文件、excel文件、关系型数据库如mysql、API接口加载json数据，来初步体验一下pandas加载数据的便捷性。</p><p>见上表pandas 提供了多种数据源读取数据的方法：<br>read_csv() 用于读取文本文件<br>read_json() 用于读取 json 文件<br>read_sql_query() 读取 sql 语句查询的表记录</p><h1 id="一、读取CSV文件"><a href="#一、读取CSV文件" class="headerlink" title="一、读取CSV文件"></a>一、读取CSV文件</h1><p>CSV 又称逗号分隔值文件，是一种简单的文件格式，以特定的结构来排列表格数据。 CSV 文件能够以纯文本形式存储表格数据，比如电子表格、数据库文件，并具有数据交换的通用格式。CSV 文件会在 Excel 文件中被打开，其行和列都定义了标准的数据格式。<br>将 CSV 中的数据转换为 DataFrame 对象是非常便捷的。和一般文件读写不一样，它不需要你做打开文件、读取文件、关闭文件等操作。相反，只需要一行代码就可以完成上述所有步骤，并将数据存储在 DataFrame 中。<br>pandas通过read_csv()从 CSV 文件中读取数据，并创建 DataFrame 对象。<br>下面通过一个实例来说明。一个用于测试的员工数据集csv的数据如下，文件为staff.csv。</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"staff_id"</span>,<span class="string">"staff_name"</span>,<span class="string">"staff_age"</span>,<span class="string">"staff_gender"</span>,<span class="string">"staff_salary"</span>,<span class="string">"staff_depatment_id"</span></span><br><span class="line"><span class="string">"1"</span>,<span class="string">"陈一"</span>,<span class="string">"30"</span>,<span class="string">"男"</span>,<span class="string">"7000"</span>,<span class="string">"1"</span></span><br><span class="line"><span class="string">"2"</span>,<span class="string">"周二"</span>,<span class="string">"31"</span>,<span class="string">"男"</span>,<span class="string">"12000"</span>,<span class="string">"2"</span></span><br><span class="line"><span class="string">"3"</span>,<span class="string">"张三"</span>,<span class="string">"30"</span>,<span class="string">"女"</span>,<span class="string">"13000"</span>,<span class="string">"3"</span></span><br><span class="line"><span class="string">"4"</span>,<span class="string">"李四"</span>,<span class="string">"29"</span>,<span class="string">"女"</span>,<span class="string">"15000"</span>,<span class="string">"1"</span></span><br><span class="line"><span class="string">"5"</span>,<span class="string">"王五"</span>,<span class="string">"29"</span>,<span class="string">"男"</span>,<span class="string">"9000"</span>,<span class="string">"2"</span></span><br><span class="line"><span class="string">"6"</span>,<span class="string">"赵六"</span>,<span class="string">"35"</span>,<span class="string">"男"</span>,<span class="string">"8600"</span>,<span class="string">"1"</span></span><br><span class="line"><span class="string">"7"</span>,<span class="string">"钱七"</span>,<span class="string">"36"</span>,<span class="string">"女"</span>,<span class="string">"9700"</span>,<span class="string">"3"</span></span><br><span class="line"><span class="string">"8"</span>,<span class="string">"孙八"</span>,<span class="string">"40"</span>,<span class="string">"女"</span>,<span class="string">"10000"</span>,<span class="string">"3"</span></span><br><span class="line"><span class="string">"9"</span>,<span class="string">"何九"</span>,<span class="string">"40"</span>,<span class="string">"男"</span>,<span class="string">"11000"</span>,<span class="string">"1"</span></span><br><span class="line"><span class="string">"10"</span>,<span class="string">"顾十"</span>,<span class="string">"37"</span>,<span class="string">"女"</span>,<span class="string">"15000"</span>,<span class="string">"2"</span></span><br></pre></td></tr></table></figure><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">'C:\\Users\\xiejava\\Desktop\\staff.csv'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p>输出：<br><img src="https://img-blog.csdnimg.cn/edaf91317adb42a7b479ebec9aa56bb7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="通过csv加载"></p><h1 id="二、读取EXCEL文件"><a href="#二、读取EXCEL文件" class="headerlink" title="二、读取EXCEL文件"></a>二、读取EXCEL文件</h1><p>Excel 是由微软公司开发的办公软件之一，它在日常工作中得到了广泛的应用。在数据量较少的情况下，Excel 对于数据的处理、分析、可视化有其独特的优势，因此可以显著提升您的工作效率。但是，当数据量非常大时，Excel 的劣势就暴露出来了，比如，操作重复、数据分析难等问题。Pandas 提供了操作 Excel 文件的函数，可以很方便地处理 Excel 表格。<br>pandas提供了 read_excel() 方法，从 Excel文件中读取数据，并创建 DataFrame 对象。<br>staff数据集excel文件staff.xlsx如下图：<br><img src="https://img-blog.csdnimg.cn/96c125c34da24204ae9799f5c444c574.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="staff.xlsx"><br>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">'C:\\Users\\xiejava\\Desktop\\staff.xlsx'</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p>输出：<br><img src="https://img-blog.csdnimg.cn/b46a651c81a74b119ad25e297d9c0d95.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="通过Excel加载数据"></p><h1 id="三、读取MySQL数据库表"><a href="#三、读取MySQL数据库表" class="headerlink" title="三、读取MySQL数据库表"></a>三、读取MySQL数据库表</h1><p>在许多应用中，数据很少取自文本文件，因为这种方式存储数据量有限且比较低效。最常见的是基于SQL的关系型数据库如MySQL、MS-SQL、PostgreSQL等。pandas将关系型数据库加载到DataFrame的过程很简单，通过read_sql_query()方法就可以快速的将数据加载。<br>同样是staff的数据集，在mysql中的表结构如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`staff`</span> (</span><br><span class="line">  <span class="string">`staff_id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`staff_name`</span> <span class="built_in">varchar</span>(<span class="number">64</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`staff_age`</span> <span class="built_in">int</span>(<span class="number">2</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'年龄'</span>,</span><br><span class="line">  <span class="string">`staff_gender`</span> <span class="built_in">varchar</span>(<span class="number">2</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'性别'</span>,</span><br><span class="line">  <span class="string">`staff_salary`</span> <span class="keyword">double</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'薪水'</span>,</span><br><span class="line">  <span class="string">`staff_depatment_id`</span> <span class="built_in">int</span>(<span class="number">2</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'部门ID'</span></span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br></pre></td></tr></table></figure><p>数据如下：<br><img src="https://img-blog.csdnimg.cn/ed23c05b550d4f0da81e2d7d84455447.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="staff数据集MySQL记录"><br>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line">engine = create_engine(<span class="string">'mysql+pymysql://root:yourpassword@localhost:3306/pandastest'</span>)</span><br><span class="line">sql_query_staff = <span class="string">'select * from staff;'</span></span><br><span class="line">df_staff = pd.read_sql_query(sql_query_staff, engine)</span><br><span class="line">df_staff</span><br></pre></td></tr></table></figure><p>输出：<br><img src="https://img-blog.csdnimg.cn/ecdf46a8e02f4a70a490d9cdf89ce6f3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="加载mysql数据"></p><h1 id="四、读取Web-API的数据"><a href="#四、读取Web-API的数据" class="headerlink" title="四、读取Web API的数据"></a>四、读取Web API的数据</h1><p>除了本地文件和数据库外，许多网站和web应用都有一些通过JSON或其他格式提供数据的公共API。可以通过Python的requests包来访问这些API获得相应的数据，经过解析处理后加载到pandas的DataFrame中。<br>为了演示方便，本文通过Flask做了一个staff数据集的API，效果如下：<br><img src="https://img-blog.csdnimg.cn/2c962a4235794e95b2545605e44f7192.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="staff数据集API"><br>通过requests包来访问API，通过json包来解析json，然后加载到pandas的DataFrame中。<br>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">url=<span class="string">'http://127.0.0.1:5000/getstaff'</span></span><br><span class="line">resp=requests.get(url)</span><br><span class="line">data=json.loads(resp.text)</span><br><span class="line">staff=pd.DataFrame(data)</span><br><span class="line">staff</span><br></pre></td></tr></table></figure><p>输出：<br><img src="https://img-blog.csdnimg.cn/6ff9136048d7484e961e822826fb805f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeGllamF2YTEwMTg=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="加载WEBAPI数据"></p><p>至此，通过staff测试数据集介绍了pandas的常用多种类型数据源的加载，包括csv、excel、mysql、web API。可以看出pandas对于数据加载非常的方便高效。</p><p>全部数据集及源代码：<a href="https://github.com/xiejava1018/pandastest.git" target="_blank" rel="noopener">https://github.com/xiejava1018/pandastest.git</a></p><p>作者博客：<a href="http://xiejava.ishareread.com/" target="_blank" rel="noopener">http://xiejava.ishareread.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/f5fc706f84454eb49d5457d751025441.png#pic_center&quot; alt=&quot;pandas&quot;&gt;&lt;br&gt;pandas 是基于NumPy 的一种工具，该工具是为解决数据分析
      
    
    </summary>
    
    
      <category term="技术" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="开发" scheme="https://xiejava.gitee.io/categories/%E6%8A%80%E6%9C%AF/%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Python" scheme="https://xiejava.gitee.io/tags/Python/"/>
    
  </entry>
  
</feed>
